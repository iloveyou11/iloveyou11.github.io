<!DOCTYPE html><html><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><link rel="stylesheet" href="/js/fancybox/dist/jquery.fancybox.min.css"><title>blog</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="keywords" content="YP's Blog"><meta name="description" content="一个专注前端智能化开发技术的网站"><meta name="keywords" content="web"><meta property="og:type" content="website"><meta property="og:title" content="blog"><meta property="og:url" content="http://localhost:4000/index.html"><meta property="og:site_name" content="blog"><meta property="og:description" content="一个专注前端智能化开发技术的网站"><meta property="og:locale" content="default"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="blog"><meta name="twitter:description" content="一个专注前端智能化开发技术的网站"><link rel="icon" href="/favicon.ico"><link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"><link rel="stylesheet" href="/css/style.css"><script src="/js/pace.min.js"></script></head><script src="https://cdn.bootcdn.net/ajax/libs/jquery/3.5.1/jquery.min.js"></script><script src="/js/fancybox/dist/jquery.fancybox.min.js"></script><script src="/js/wrapimg.js"></script></html><body><div id="container"><header id="header"><div id="banner"></div><div id="header-outer"><div id="header-menu" class="header-menu-pos animated"><div class="header-menu-container"><a href="/" class="left"><span class="site-title">YP&#39;s Blog</span></a><nav id="header-menu-nav" class="right"><a href="/"><i class="fa fa-home"></i> <span>主页</span> </a><a href="/categories/前端/"><i class="fa fa-前端"></i> <span>前端</span> </a><a href="/categories/源码/"><i class="fa fa-源码"></i> <span>源码</span> </a><a href="/categories/ML/"><i class="fa fa-ML"></i> <span>ML</span> </a><a href="/categories/CV/"><i class="fa fa-CV"></i> <span>CV</span> </a><a href="/categories/NLP/"><i class="fa fa-NLP"></i> <span>NLP</span> </a><a href="/categories/计算机/"><i class="fa fa-计算机"></i> <span>计算机</span> </a><a href="/categories/专题/"><i class="fa fa-专题"></i> <span>专题</span> </a><a href="/categories/感想/"><i class="fa fa-感想"></i> <span>感想</span> </a><a href="/categories/语言/"><i class="fa fa-语言"></i> <span>语言</span></a></nav><a class="mobile-header-menu-button"><i class="fa fa-bars"></i></a></div></div><div id="header-row"><div id="logo"><a href="/"><img src="/images/logo.png" alt="logo"></a></div><div class="header-info"><div id="header-title"><h2>YP&#39;s Blog</h2></div><div id="header-description"><h3>一个专注前端智能化领域的技术博客</h3></div></div><nav class="header-nav"><div class="social"><a title="Blog" target="_blank" href="https://iloveyou11.github.io/"><i class="fa fa-home fa-2x"></i></a> <a title="Github" target="_blank" href="https://github.com/iloveyou11"><i class="fa fa-github fa-2x"></i></a></div></nav></div></div></header><div class="outer"><section id="main" class="body-wrap"><article id="post-koa2源码解读" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/08/22/koa2源码解读/" target="_blank">koa2源码解读</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">7.1k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">33分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/源码/">源码</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>关于如何读源码曾经，我去阅读源码时，总是喜欢一句不漏的从上到下阅读，怕漏掉什么核心代码导致不理解程序的详细流程，遇到一个函数或类就跳过去看，然后……花费了很多的时间而且效果相当不理想。不仅对整体的框架没有大体了解，也让自己像只无头苍蝇，不知道如何抓住重点去深入研究背后的原理。后来看了不少大佬阅读的方式，对我也是收获颇多：不要采用DFS（深度遍历）的方式阅读源码，而是应该先...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-08-22</li></ul><a href="/2020/08/22/koa2源码解读/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-前端智能化方向思考与解读" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/07/03/前端智能化方向思考与解读/" target="_blank">前端智能化方向思考与解读</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">1.7k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">5分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/前端/">前端</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>为了更深入地理解和思考前端和智能化两个方向的结合，首先需要了解这两个概念：前端：最接近用户的那一层，开发网站、开机端web应用和移动端应用程序等智能化：指人工智能，主要包括机器学习，其中涉及到深度学习、计算机视觉、自然语言处理等领域，也是近些年发展较快且前景较好的方向前端结合AI的必要性前端开发者为什么要学习人工智能呢？未来的前端工作，将大量使用AI自动生成UI代码，从而...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-07-03</li></ul><a href="/2020/07/03/前端智能化方向思考与解读/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-jquery源码解读" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/06/29/jquery源码解读/" target="_blank">jquery源码解读</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">8.3k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">39分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/源码/">源码</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>jquery诞生于2006年1月，至今已经存在14年多的时间了，相信前端开发者都对他有所听闻。虽然现在涌现了很多优秀的前端框架，如vue、react等等，也逐渐取代了传统的jquery开发模式，但是jq作为一款曾风靡前端圈的框架，其优秀的设计思想还是值得开发者好好学习一下的。下面，我们来看jquery具体的源码内容：关于如何读源码曾经，我去阅读源码时，总是喜欢一句不漏的从...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-06-29</li></ul><a href="/2020/06/29/jquery源码解读/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-git基础与进阶" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/06/15/git基础与进阶/" target="_blank">git基础与进阶</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">2.4k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">9分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/前端/">前端</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p></p><p>对于git做深入地了解，总结了在实际工作过程中git进行版本管理和团队协作的基本操作方法。</p><p></p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-06-15</li></ul><a href="/2020/06/15/git基础与进阶/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-NLP模型-11-attention" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/06/12/NLP模型-11-attention/" target="_blank">NLP模型-11-attention</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">1.6k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">5分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/NLP/">NLP</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>何为AttentionAttention是一种用于提升基于RNN（LSTM或GRU）的Encoder + Decoder模型的效果的的机制。Attention目前非常流行，广泛应用于机器翻译、语音识别、图像标注等很多领域，之所以它这么受欢迎，是因为Attention给模型赋予了区分辨别的能力，例如，在机器翻译、语音识别应用中，为句子中的每个词赋予不同的权重，使神经网络模型...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-06-12</li></ul><a href="/2020/06/12/NLP模型-11-attention/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-NLP模型-10-seq2seq" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/06/05/NLP模型-10-seq2seq/" target="_blank">NLP模型-10-seq2seq</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">1.9k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">9分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/NLP/">NLP</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>seq2seq初识当输入和输出都是不定长序列时，则可以使用编码器-解码器或seq2seq模型解决。seq2seq属于encoder-decoder结构的一种，常见是encoder-decoder结构，基本思想就是利用两个RNN，一个RNN作为encoder，另一个RNN作为decoder，两个RNN网络是共同训练的。encoder负责将输入序列压缩成指定长度的向量，这个向...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-06-05</li></ul><a href="/2020/06/05/NLP模型-10-seq2seq/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-NLP模型-09-textRNN &amp; textCNN" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/06/01/NLP模型-09-textRNN & textCNN/" target="_blank">NLP模型-09-textRNN&amp;textCNN</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">2.8k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">13分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/NLP/">NLP</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>TextRNN模型结构TextRNN是利用RNN网络来解决文本分类问题，当然，也可以采用RNN的变种LSTM、GRU来实现……文本分类的任务有：垃圾邮件分类情感分析新闻/报道主题分析问答系统中的问句分类……结构1流程：embedding—&gt;BiLSTM—&gt;concat final output/average all output—–&gt;softmax l...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-06-01</li></ul><a href="/2020/06/01/NLP模型-09-textRNN & textCNN/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-NLP模型-08-fastText" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/05/21/NLP模型-08-fastText/" target="_blank">NLP模型-08-fastText</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">924字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">3分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/NLP/">NLP</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>fastText初始fastText是一个快速文本分类算法，FastText 算法能获得和深度模型相同的精度，但是计算时间却要远远小于深度学习模型。fastText 可以作为一个文本分类的 baseline 模型。fastText不需要训练好的词向量模型，它会自己训练词向量模型。fastText两个重要的优化：Hierarchical Softmax、N-gram。fas...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-05-21</li></ul><a href="/2020/05/21/NLP模型-08-fastText/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-NLP模型-07-LDA" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/05/15/NLP模型-07-LDA/" target="_blank">NLP模型-07-LDA</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">1.1k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">3分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/NLP/">NLP</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>什么是LDA？LDA（Latent Dirichlet Allocation）是一种文档主题生成模型，也称为一个三层贝叶斯概率模型，包含词、主题和文档三层结构。LDA的目的就是要识别主题，即把文档—词汇矩阵变成文档—主题矩阵（分布）和主题—词汇矩阵（分布）生成过程LDA 的产生过程描述了文档以及文档中文字的生成过程。在原始的 LDA 论文中，作者们描述了对于每一个文档而言...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-05-15</li></ul><a href="/2020/05/15/NLP模型-07-LDA/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><article id="post-NLP模型-06-Bert" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><h1 itemprop="name"><a class="article-title" href="/2020/05/08/NLP模型-06-Bert/" target="_blank">NLP模型-06-Bert</a></h1><div style="margin-top:10px"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i> <span class="post-meta-item-text">字数统计: </span><span class="post-count">3.2k字</span> </span></span><span class="post-time">&nbsp; | &nbsp; <span class="post-meta-item-icon"><i class="fa fa-hourglass-half"></i> <span class="post-meta-item-text">阅读时长: </span><span class="post-count">11分</span></span></span></div><span class="header-cate"><i class="fa fa-map-marker"></i> <a href="/categories/NLP/">NLP</a></span></header><div class="article-entry" itemprop="articleBody"><div class="article-feed"><p>Bert（Bidirectional Encoder Representations from Transformers）说白了就是transformer中的encoder部分，就是怎么将transformer模型中的特征学习出来，是Word2Vec的替代者。使用了Transformer作为算法的主要框架，能更彻底的捕捉语句中的双向关系；使用了Mask Language ...</p></div></div><footer class="article-footer"><ul class="article-footer-menu"><li><i class="fa fa-calendar"></i> 2020-05-08</li></ul><a href="/2020/05/08/NLP模型-06-Bert/#more" class="article-more-link" target="_blank">more&gt;&gt;</a></footer></div></article><nav id="page-nav"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/2/">Next >></a></nav></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner"><p><span id="busuanzi_container_site_uv" style="display:none">总访客数：<span id="busuanzi_value_site_uv"></span> </span><span id="busuanzi_container_site_pv" style="display:none">总访问量：<span id="busuanzi_value_site_pv"></span></span></p><p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a> &copy; 2020 Yang Pei<br></p></div></div></footer><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><script>var mihoConfig={root:"http://localhost:4000",animate:"true",isHome:"true",share:"true"}</script><div class="sidebar"><div id="sidebar-top"><span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span></div></div><div class="sidebar-menu-box" id="sidebar-menu-box"><div class="sidebar-menu-box-container"><div id="sidebar-menu-box-categories"><a class="category-link" href="/categories/AI/">AI</a><a class="category-link" href="/categories/CV/">CV</a><a class="category-link" href="/categories/ML/">ML</a><a class="category-link" href="/categories/NLP/">NLP</a><a class="category-link" href="/categories/专题/">专题</a><a class="category-link" href="/categories/前端/">前端</a><a class="category-link" href="/categories/感想/">感想</a><a class="category-link" href="/categories/源码/">源码</a><a class="category-link" href="/categories/计算机/">计算机</a><a class="category-link" href="/categories/语言/">语言</a></div><div id="sidebar-menu-box-tags"></div></div><a href="javascript:;" class="sidebar-menu-box-close">&times;</a></div>ß<div class="mobile-header-menu-nav" id="mobile-header-menu-nav"><div class="mobile-header-menu-container"><span class="title">Menus</span><ul class="mobile-header-menu-navbar"><li><a href="/"><i class="fa fa-home"></i><span>主页</span></a></li><li><a href="/categories/前端/"><i class="fa fa-前端"></i><span>前端</span></a></li><li><a href="/categories/源码/"><i class="fa fa-源码"></i><span>源码</span></a></li><li><a href="/categories/ML/"><i class="fa fa-ML"></i><span>ML</span></a></li><li><a href="/categories/CV/"><i class="fa fa-CV"></i><span>CV</span></a></li><li><a href="/categories/NLP/"><i class="fa fa-NLP"></i><span>NLP</span></a></li><li><a href="/categories/计算机/"><i class="fa fa-计算机"></i><span>计算机</span></a></li><li><a href="/categories/专题/"><i class="fa fa-专题"></i><span>专题</span></a></li><li><a href="/categories/感想/"><i class="fa fa-感想"></i><span>感想</span></a></li><li><a href="/categories/语言/"><i class="fa fa-语言"></i><span>语言</span></a></li></ul></div><div class="mobile-header-tag-container"><span class="title">Tags</span><div id="mobile-header-container-tags"></div></div></div><div class="search-wrap"><span class="search-close">&times;</span> <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back"><i class="icon icon-lg icon-chevron-left"></i> </a><input class="search-field" placeholder="Search..." id="keywords"> <a id="search-submit" href="javascript:;"><i class="fa fa-search"></i></a><div class="search-container" id="search-container"><ul class="search-result" id="search-result"></ul></div></div><div id="search-tpl"><li class="search-result-item"><a href="{url}" class="search-item-li"><span class="search-item-li-title" title="{title}">{title}</span></a></li></div><script src="/js/search.js"></script><script src="/js/main.js"></script><script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script><div id="particles"></div><script src="/js/particles.js"></script><link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css"><script src="//cdn.bootcss.com/scrollReveal.js/3.0.5/scrollreveal.js"></script><script src="/js/animate.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({model:{jsonPath:"/live2dw/assets/Epsilon2.1.model.json"},display:{position:"right",width:150,height:300},mobile:{show:!1},log:!1,pluginJsPath:"lib/",pluginModelPath:"assets/",pluginRootPath:"live2dw/",tagMode:!1})</script></body>