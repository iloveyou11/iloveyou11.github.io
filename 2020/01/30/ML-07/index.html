<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>ML系列7：tensorflow项目实战 | blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="YP's Blog">
  
  <meta name="description" content="利用tensorflow框架写一些小项目，多多熟悉一下吧~github项目地址">
<meta name="keywords" content="web">
<meta property="og:type" content="article">
<meta property="og:title" content="ML系列7：tensorflow项目实战">
<meta property="og:url" content="http://localhost:4000/2020/01/30/ML-07/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="利用tensorflow框架写一些小项目，多多熟悉一下吧~github项目地址">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://i.loli.net/2019/12/04/pS4qj1zguRPa7lY.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/04/TSDOhWt62yqJG79.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/04/isW5zX1EYHSpnw7.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/04/Kf2Wnlhwq1uXaQd.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/04/9WyiPqcbEkVTmrl.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/04/2eY6HaTyqbkKZOr.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/04/xtWKq3zBeJHVr98.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/04/cmGYqsn6NyEuL3r.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/06/c4yFqEJgYQPSaGZ.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/05/JH9ISij5pf3s4c7.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/uULNjfAvbi1Qzog.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/6cnprdOQqC1Hg9y.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/tL2DrkwCBfImVjX.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/rtBYgubj2FHWRax.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/CPoBbah9xpc8vQw.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/gM61KJWk2CfFbtP.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/NR35QBMyviqaPLE.png">
<meta property="og:image" content="https://i.loli.net/2019/12/05/3QJc5DhoREsryuz.png">
<meta property="og:image" content="https://i.loli.net/2019/12/06/7Kb6U1MCRWBnhto.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/06/jF5SXZAWdVzf1HM.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/06/Nl3fRZ9b7viKWPV.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/06/pGhBjnA2Z8V6Cfy.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/06/Kd8aIAczRDxqitO.jpg">
<meta property="og:image" content="https://i.loli.net/2019/12/06/o1SbOdCWfzRrM5P.png">
<meta property="og:image" content="https://i.loli.net/2019/12/06/HorfvGPthVemqK1.gif">
<meta property="og:image" content="https://i.loli.net/2019/12/06/o2V9uhQRzCvDOj7.png">
<meta property="og:updated_time" content="2020-07-07T09:59:52.534Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ML系列7：tensorflow项目实战">
<meta name="twitter:description" content="利用tensorflow框架写一些小项目，多多熟悉一下吧~github项目地址">
<meta name="twitter:image" content="https://i.loli.net/2019/12/04/pS4qj1zguRPa7lY.jpg">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>
</html>
<body>
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">YP Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        YP Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        一个专注 WEB 开发的技术博客
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="Blog" target="_blank" href="https://iloveyou11.github.io/">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="https://github.com/iloveyou11">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-ML-07" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="post-title" itemprop="name">
      ML系列7：tensorflow项目实战
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/AI/">AI</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2020-01-30
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

                    
            </header>
            
                <div class="article-entry post-content" itemprop="articleBody">
                    
                            
                                
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-4"><a class="toc-link" href="#房价预测线性回归"><span class="toc-text">房价预测线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#手写数字识别"><span class="toc-text">手写数字识别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#验证码识别"><span class="toc-text">验证码识别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实现词云"><span class="toc-text">实现词云</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#自编码器图像去噪AE"><span class="toc-text">自编码器图像去噪AE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#变分自编码器VAE"><span class="toc-text">变分自编码器VAE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#生成式对抗网络GAN"><span class="toc-text">生成式对抗网络GAN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#人脸图片生成DCGAN"><span class="toc-text">人脸图片生成DCGAN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Inception-v3图片分类"><span class="toc-text">Inception-v3图片分类</span></a></li></ol>
    </div>
    
                                    <p>利用tensorflow框架写一些小项目，多多熟悉一下吧~<a href="https://github.com/iloveyou11/tensorflow-exercise" target="_blank" rel="noopener">github项目地址</a></p>
<a id="more"></a>


<p><a href="https://iloveyou11.github.io/2019/12/04/ML-01/" target="_blank" rel="noopener">ML系列1：AI学习资源与知识点</a><br><a href="https://iloveyou11.github.io/2019/12/10/ML-02/" target="_blank" rel="noopener">ML系列2：机器学习必会算法</a><br><a href="https://iloveyou11.github.io/2019/12/15/ML-03/" target="_blank" rel="noopener">ML系列3：传统机器学习算法-语雀</a><br><a href="https://iloveyou11.github.io/2019/12/29/ML-04/" target="_blank" rel="noopener">ML系列4：深度学习中的问题解答</a><br><a href="https://iloveyou11.github.io/2020/01/02/ML-05/" target="_blank" rel="noopener">ML系列5：tensorflow入门-1</a><br><a href="https://iloveyou11.github.io/2020/01/10/ML-06/" target="_blank" rel="noopener">ML系列6：tensorflow入门-2</a><br><a href="https://iloveyou11.github.io/2020/01/30/ML-07/" target="_blank" rel="noopener">ML系列7：tensorflow项目实战</a></p>
<h4 id="房价预测线性回归"><a href="#房价预测线性回归" class="headerlink" title="房价预测线性回归"></a>房价预测线性回归</h4><p><strong>第1步：进行数据处理</strong></p>
<p>首先读取csv数据，再对x1 x2 … xn y数据进行归一化处理，接下来添加单独的一列x0(值均为1，常数项)<br><img alt="回归模型1" src="https://i.loli.net/2019/12/04/pS4qj1zguRPa7lY.jpg" width="40%"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits <span class="keyword">import</span> mplot3d</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据</span></span><br><span class="line">sns.set(context=<span class="string">"notebook"</span>， style=<span class="string">"whitegrid"</span>， palette=<span class="string">"dark"</span>)</span><br><span class="line">df0 = pd.read_csv(<span class="string">'房价预测线性回归/data0.csv'</span>， names=[<span class="string">'square'</span>， <span class="string">'price'</span>])</span><br><span class="line">sns.lmplot(<span class="string">'square'</span>， <span class="string">'price'</span>， df0， height=<span class="number">6</span>， fit_reg=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">df1 = pd.read_csv(<span class="string">'房价预测线性回归/data1.csv'</span>， names=[<span class="string">'square'</span>， <span class="string">'bedrooms'</span>， <span class="string">'price'</span>])</span><br><span class="line">print(df1.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制3d散点图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = plt.axes(projection=<span class="string">'3d'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'square'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'bedrooms'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'price'</span>)</span><br><span class="line">ax.scatter3D(df1[<span class="string">'square'</span>]， df1[<span class="string">'bedrooms'</span>]，</span><br><span class="line">             df1[<span class="string">'price'</span>]， c=df1[<span class="string">'price'</span>]， cmap=<span class="string">'Greens'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据规范化</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> df.apply(<span class="keyword">lambda</span> col: (col-col.mean())/col.std())</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">df = normalize(df1)</span><br><span class="line">print(df.head())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制规范化数据后的3d散点图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = plt.axes(projection=<span class="string">'3d'</span>)</span><br><span class="line">ax.set_xlabel(<span class="string">'square'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'bedrooms'</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">'price'</span>)</span><br><span class="line">ax.scatter3D(df[<span class="string">'square'</span>]， df[<span class="string">'bedrooms'</span>]，</span><br><span class="line">             df[<span class="string">'price'</span>]， c=df[<span class="string">'price'</span>]， cmap=<span class="string">'Reds'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加列</span></span><br><span class="line">ones = pd.DataFrame(&#123;<span class="string">'ones'</span>: np.ones(len(df))&#125;)</span><br><span class="line">df = pd.concat([ones， df]， axis=<span class="number">1</span>)</span><br><span class="line">print(df.head())</span><br></pre></td></tr></table></figure>

<img alt="回归模型2" src="https://i.loli.net/2019/12/04/TSDOhWt62yqJG79.jpg" width="40%">
<img alt="回归模型3" src="https://i.loli.net/2019/12/04/isW5zX1EYHSpnw7.jpg" width="40%">

<p>经过归一化处理后的数据结构如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">   ones    square  bedrooms     price</span><br><span class="line">0   1.0  0.130010 -0.223675  0.475747</span><br><span class="line">1   1.0 -0.504190 -0.223675 -0.084074</span><br><span class="line">2   1.0  0.502476 -0.223675  0.228626</span><br><span class="line">3   1.0 -0.735723 -1.537767 -0.867025</span><br><span class="line">4   1.0  1.257476  1.090417  1.595389</span><br></pre></td></tr></table></figure>

<p><strong>第2步：训练模型</strong></p>
<p>在第1步得到的数据基础上进行处理. 首先，需要拿到x y的数据，定义学习率<code>learning_rate</code>和训练次数<code>epoch</code>，分别输入x y，计算损失loss值，使用梯度下降优化器进行优化操作.<code>GradientDescentOptimizer</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> df.apply(<span class="keyword">lambda</span> col: (col-col.mean())/col.std())</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'房价预测线性回归/data1.csv'</span>， names=[<span class="string">'square'</span>， <span class="string">'bedrooms'</span>， <span class="string">'price'</span>])</span><br><span class="line">df = normalize(df)</span><br><span class="line">ones = pd.DataFrame(&#123;<span class="string">'ones'</span>: np.ones(len(df))&#125;)</span><br><span class="line">df = pd.concat([ones， df]， axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line">X_data = np.array(df[df.columns[<span class="number">0</span>:<span class="number">3</span>]])</span><br><span class="line">y_data = np.array(df[df.columns[<span class="number">-1</span>]]).reshape(len(df)， <span class="number">1</span>)</span><br><span class="line">print(X_data.shape， type(X_data))</span><br><span class="line">print(y_data.shape， type(y_data))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建显性回归模型</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">epoch = <span class="number">500</span></span><br><span class="line"><span class="comment"># 输入x y</span></span><br><span class="line">X = tf.compat.v1.placeholder(tf.float32， X_data.shape)</span><br><span class="line">y = tf.compat.v1.placeholder(tf.float32， y_data.shape)</span><br><span class="line">W = tf.compat.v1.get_variable(</span><br><span class="line">    <span class="string">"weights"</span>， (X_data.shape[<span class="number">1</span>]， <span class="number">1</span>)， initializer=tf.constant_initializer())</span><br><span class="line">y_pred = tf.matmul(X， W)</span><br><span class="line">loss_op = <span class="number">1</span> / (<span class="number">2</span> * len(X_data)) * tf.matmul((y_pred - y)，</span><br><span class="line">                                            (y_pred - y)， transpose_a=<span class="literal">True</span>)</span><br><span class="line">opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)</span><br><span class="line">train_op = opt.minimize(loss_op)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话</span></span><br><span class="line"><span class="keyword">with</span> tf.compat.v1.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.compat.v1.global_variables_initializer())</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(<span class="number">1</span>， epoch+<span class="number">1</span>):</span><br><span class="line">        sess.run(train_op， feed_dict=&#123;X: X_data， y: y_data&#125;)</span><br><span class="line">        <span class="keyword">if</span> e % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            loss， w = sess.run([loss_op， W]， feed_dict=&#123;X: X_data， y: y_data&#125;)</span><br><span class="line">            print(<span class="string">"Epoch %d \t Loss=%.4g \t Model: y = %.4gx1 + %.4gx2 + %.4g"</span> %</span><br><span class="line">                  (e， loss， w[<span class="number">1</span>]， w[<span class="number">2</span>]， w[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure>

<p>模型训练好后的数据如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Epoch 10         Loss=0.4116     Model: y = 0.0791x1 + 0.03948x2 + 3.353e-10</span><br><span class="line">Epoch 20         Loss=0.353      Model: y = 0.1489x1 + 0.07135x2 + -5.588e-11</span><br><span class="line">Epoch 30         Loss=0.3087     Model: y = 0.2107x1 + 0.09676x2 + 3.912e-10</span><br><span class="line">Epoch 40         Loss=0.2748     Model: y = 0.2655x1 + 0.1167x2 + -1.863e-11</span><br><span class="line">Epoch 50         Loss=0.2489     Model: y = 0.3142x1 + 0.1321x2 + 1.77e-10</span><br><span class="line">Epoch 60         Loss=0.2288     Model: y = 0.3576x1 + 0.1436x2 + -4.47e-10</span><br><span class="line">Epoch 70         Loss=0.2131     Model: y = 0.3965x1 + 0.1519x2 + -8.103e-10</span><br><span class="line">Epoch 80         Loss=0.2007     Model: y = 0.4313x1 + 0.1574x2 + -6.985e-10</span><br><span class="line">Epoch 90         Loss=0.1908     Model: y = 0.4626x1 + 0.1607x2 + -4.936e-10</span><br><span class="line">......</span><br><span class="line">......</span><br><span class="line">Epoch 420        Loss=0.1332     Model: y = 0.8076x1 + 0.02271x2 + 2.125e-09</span><br><span class="line">Epoch 430        Loss=0.133      Model: y = 0.8109x1 + 0.01957x2 + 2.292e-09</span><br><span class="line">Epoch 440        Loss=0.1328     Model: y = 0.8141x1 + 0.01655x2 + 2.913e-09</span><br><span class="line">Epoch 450        Loss=0.1326     Model: y = 0.8171x1 + 0.01366x2 + 3.412e-09</span><br><span class="line">Epoch 460        Loss=0.1325     Model: y = 0.82x1 + 0.01087x2 + 3.749e-09</span><br><span class="line">Epoch 470        Loss=0.1323     Model: y = 0.8228x1 + 0.008204x2 + 3.499e-09</span><br><span class="line">Epoch 480        Loss=0.1322     Model: y = 0.8254x1 + 0.005641x2 + 3.663e-09</span><br><span class="line">Epoch 490        Loss=0.1321     Model: y = 0.828x1 + 0.003183x2 + 4.2e-09</span><br><span class="line">Epoch 500        Loss=0.132      Model: y = 0.8304x1 + 0.0008239x2 + 4.138e-09</span><br></pre></td></tr></table></figure>

<p><strong>第3步：可视化流图</strong></p>
<p>使用tensorboard可以可视化数据流图，可以方便我们查看训练的过程</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> df.apply(<span class="keyword">lambda</span> col: (col-col.mean())/col.std())</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'房价预测线性回归/data1.csv'</span>， names=[<span class="string">'square'</span>， <span class="string">'bedrooms'</span>， <span class="string">'price'</span>])</span><br><span class="line">df = normalize(df)</span><br><span class="line">ones = pd.DataFrame(&#123;<span class="string">'ones'</span>: np.ones(len(df))&#125;)</span><br><span class="line">df = pd.concat([ones， df]， axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line">X_data = np.array(df[df.columns[<span class="number">0</span>:<span class="number">3</span>]])</span><br><span class="line">y_data = np.array(df[df.columns[<span class="number">-1</span>]]).reshape(len(df)， <span class="number">1</span>)</span><br><span class="line">print(X_data.shape， type(X_data))</span><br><span class="line">print(y_data.shape， type(y_data))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建显性回归模型</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">epoch = <span class="number">500</span></span><br><span class="line"><span class="comment"># 输入x y</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    X = tf.compat.v1.placeholder(tf.float32， X_data.shape)</span><br><span class="line">    y = tf.compat.v1.placeholder(tf.float32， y_data.shape)</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'hypothesis'</span>):</span><br><span class="line">    W = tf.compat.v1.get_variable(</span><br><span class="line">        <span class="string">"weights"</span>， (X_data.shape[<span class="number">1</span>]， <span class="number">1</span>)， initializer=tf.constant_initializer())</span><br><span class="line">    y_pred = tf.matmul(X， W)</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss_op = <span class="number">1</span> / (<span class="number">2</span> * len(X_data)) * tf.matmul((y_pred - y)，</span><br><span class="line">                                                (y_pred - y)， transpose_a=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</span><br><span class="line">    train_op = tf.train.GradientDescentOptimizer(</span><br><span class="line">        learning_rate=learning_rate).minimize(loss_op)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话</span></span><br><span class="line"><span class="keyword">with</span> tf.compat.v1.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.compat.v1.global_variables_initializer())</span><br><span class="line">    writer = tf.compat.v1.summary.FileWriter(<span class="string">'./summary'</span>， sess.graph)</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(<span class="number">1</span>， epoch+<span class="number">1</span>):</span><br><span class="line">        sess.run(train_op， feed_dict=&#123;X: X_data， y: y_data&#125;)</span><br><span class="line">        <span class="keyword">if</span> e % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">            loss， w = sess.run([loss_op， W]， feed_dict=&#123;X: X_data， y: y_data&#125;)</span><br><span class="line">            print(<span class="string">"Epoch %d \t Loss=%.4g \t Model: y = %.4gx1 + %.4gx2 + %.4g"</span> %</span><br><span class="line">                  (e， loss， w[<span class="number">1</span>]， w[<span class="number">2</span>]， w[<span class="number">0</span>]))</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>

<p>其中，定义的<code>with tf.name_scope(&#39;xxx&#39;):</code>是为了将相关的部分视为整体展示在tensorboard中，可以更加方便地展开和隐藏，能够更有效地展示模型的结构.</p>
<p><strong>第4步：可视化损失loss</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span><span class="params">(df)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> df.apply(<span class="keyword">lambda</span> col: (col-col.mean())/col.std())</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">'房价预测线性回归/data1.csv'</span>， names=[<span class="string">'square'</span>， <span class="string">'bedrooms'</span>， <span class="string">'price'</span>])</span><br><span class="line">df = normalize(df)</span><br><span class="line">ones = pd.DataFrame(&#123;<span class="string">'ones'</span>: np.ones(len(df))&#125;)</span><br><span class="line">df = pd.concat([ones， df]， axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># print(df.head())</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据处理</span></span><br><span class="line">X_data = np.array(df[df.columns[<span class="number">0</span>:<span class="number">3</span>]])</span><br><span class="line">y_data = np.array(df[df.columns[<span class="number">-1</span>]]).reshape(len(df)， <span class="number">1</span>)</span><br><span class="line">print(X_data.shape， type(X_data))</span><br><span class="line">print(y_data.shape， type(y_data))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建显性回归模型</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line">epoch = <span class="number">500</span></span><br><span class="line"><span class="comment"># 输入x y</span></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'input'</span>):</span><br><span class="line">    X = tf.compat.v1.placeholder(tf.float32， X_data.shape)</span><br><span class="line">    y = tf.compat.v1.placeholder(tf.float32， y_data.shape)</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'hypothesis'</span>):</span><br><span class="line">    W = tf.compat.v1.get_variable(</span><br><span class="line">        <span class="string">"weights"</span>， (X_data.shape[<span class="number">1</span>]， <span class="number">1</span>)， initializer=tf.constant_initializer())</span><br><span class="line">    y_pred = tf.matmul(X， W)</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'loss'</span>):</span><br><span class="line">    loss_op = <span class="number">1</span> / (<span class="number">2</span> * len(X_data)) * tf.matmul((y_pred - y)，</span><br><span class="line">                                                (y_pred - y)， transpose_a=<span class="literal">True</span>)</span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'train'</span>):</span><br><span class="line">    train_op = tf.train.GradientDescentOptimizer(</span><br><span class="line">        learning_rate=learning_rate).minimize(loss_op)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话</span></span><br><span class="line"><span class="keyword">with</span> tf.compat.v1.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.compat.v1.global_variables_initializer())</span><br><span class="line">    writer = tf.compat.v1.summary.FileWriter(<span class="string">'./summary'</span>， sess.graph)</span><br><span class="line">    <span class="comment"># 记录所有损失值</span></span><br><span class="line">    loss_data = []</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> range(<span class="number">1</span>， epoch+<span class="number">1</span>):</span><br><span class="line">        _， loss， w = sess.run([train_op， loss_op， W]，</span><br><span class="line">                              feed_dict=&#123;X: X_data， y: y_data&#125;)</span><br><span class="line">        loss_data.append(float(loss))</span><br><span class="line">        <span class="keyword">if</span> e % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            log_str = <span class="string">"Epoch %d \t Loss=%.4g \t Model: y = %.4gx1 + %.4gx2 + %.4g"</span></span><br><span class="line">            print(log_str % (e， loss， w[<span class="number">1</span>]， w[<span class="number">2</span>]， w[<span class="number">0</span>]))</span><br><span class="line">writer.close()</span><br><span class="line"><span class="comment"># print(len(loss_data))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化损失值</span></span><br><span class="line">sns.set(context=<span class="string">"notebook"</span>， style=<span class="string">"whitegrid"</span>， palette=<span class="string">"dark"</span>)</span><br><span class="line">ax = sns.lineplot(x=<span class="string">'epoch'</span>， y=<span class="string">'loss'</span>， data=pd.DataFrame(</span><br><span class="line">    &#123;<span class="string">'loss'</span>: loss_data， <span class="string">'epoch'</span>: np.arange(epoch)&#125;))</span><br><span class="line">ax.set_xlabel(<span class="string">'epoch'</span>)</span><br><span class="line">ax.set_ylabel(<span class="string">'loss'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>每次迭代过程中，损失值的变化趋势如下:<br><img alt="回归模型4" src="https://i.loli.net/2019/12/04/Kf2Wnlhwq1uXaQd.jpg" width="40%"><br>由此可见，随着迭代次数的增多，损失值越来越小，最后趋于平稳，模型越来越优.</p>
<h4 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h4><p><strong>第1步：加载数据集mnist</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取mnist数据集</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"></span><br><span class="line">(train_x， train_y)， (test_x， test_y) = mnist.load_data()</span><br><span class="line">print(train_x.shape， train_y.shape)</span><br><span class="line">print(test_x.shape， test_y.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化数据集</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">15</span>):</span><br><span class="line">    plt.subplot(<span class="number">3</span>， <span class="number">5</span>， i+<span class="number">1</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.imshow(train_x[i]， cmap=<span class="string">'Greys'</span>)</span><br><span class="line">    plt.title(<span class="string">'label:&#123;&#125;'</span>.format(train_y[i]))</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>最后得到的数据集如下:<br><img alt="手写数字1" src="https://i.loli.net/2019/12/04/9WyiPqcbEkVTmrl.jpg" width="40%"></p>
<p><strong>第2步：利用softmax进行手写数字识别</strong></p>
<p>具体流程: </p>
<ol>
<li>统计训练数据中各标签数量，并可视化标签数量，保证各类数字数量差不多，这样可以保证接下来训练模型的可靠性</li>
<li>数据处理:one-hot 编码</li>
<li>使用 Keras sequential model 定义神经网络(在这里，简单地使用了<code>Dense-Activation(relu)-Dense-Activation(relu)-Dense-Activation(softmax)</code>的结构)，通过softmax计算的概率值大小判断是哪个数字的可能性最大</li>
<li>编译模型(利用<code>model.compile()</code>进行模型的编译)</li>
<li>训练模型，并将指标保存到 history 中</li>
<li>保存模型(利用<code>model.save()</code>将模型保存到本地，下次可以直接使用此模型)，官方解释如下:<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">You can use model.save(filepath) to save a Keras model into a single HDF5 file which will contain:</span><br><span class="line"></span><br><span class="line">the architecture of the model， allowing to re-create the model</span><br><span class="line">the weights of the model</span><br><span class="line">the training configuration (loss， optimizer)</span><br><span class="line">the state of the optimizer， allowing to resume training exactly where you left off.</span><br><span class="line">You can then use keras.models.load_model(filepath) to reinstantiate your model. load_model will also take care of compiling the model using the saved training configuration (unless the model was never compiled in the first place).</span><br></pre></td></tr></table></figure>

</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense， Activation</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line">(x_train， y_train)， (x_test， y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 规范化</span></span><br><span class="line">X_train = x_train.reshape(<span class="number">60000</span>， <span class="number">784</span>)</span><br><span class="line">X_test = x_test.reshape(<span class="number">10000</span>， <span class="number">784</span>)</span><br><span class="line">X_train = X_train.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_test = X_test.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_train /= <span class="number">255</span></span><br><span class="line">X_test /= <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计各标签数量</span></span><br><span class="line">label， count = np.unique(y_train， return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(label， count)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化标签数量</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.bar(label， count， width=<span class="number">0.7</span>， align=<span class="string">'center'</span>)</span><br><span class="line">plt.title(<span class="string">"Label Distribution"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Label"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Count"</span>)</span><br><span class="line">plt.xticks(label)</span><br><span class="line">plt.ylim(<span class="number">0</span>， <span class="number">7500</span>)</span><br><span class="line"><span class="keyword">for</span> label， count <span class="keyword">in</span> zip(label， count):</span><br><span class="line">    plt.text(label， count， <span class="string">'%d'</span> % count， ha=<span class="string">'center'</span>， va=<span class="string">'bottom'</span>， fontsize=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># one-hot编码</span></span><br><span class="line">n_classes = <span class="number">10</span></span><br><span class="line"><span class="comment"># print('before one-hot:'， y_train.shape)</span></span><br><span class="line">Y_train = np_utils.to_categorical(y_train， n_classes)</span><br><span class="line"><span class="comment"># print('after one-hot:'， Y_train.shape)</span></span><br><span class="line">Y_test = np_utils.to_categorical(y_test， n_classes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义神经网络</span></span><br><span class="line">model = Sequential()</span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">512</span>， input_shape=(<span class="number">784</span>，)))</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">512</span>))</span><br><span class="line">model.add(Activation(<span class="string">'relu'</span>))</span><br><span class="line"></span><br><span class="line">model.add(Dense(<span class="number">10</span>))</span><br><span class="line">model.add(Activation(<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>，</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>]， optimizer=<span class="string">'adam'</span>)</span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">history = model.fit(</span><br><span class="line">    X_train，</span><br><span class="line">    Y_train，</span><br><span class="line">    batch_size=<span class="number">128</span>，</span><br><span class="line">    epochs=<span class="number">5</span>，</span><br><span class="line">    verbose=<span class="number">2</span>，</span><br><span class="line">    validation_data=(X_test， Y_test)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化指标</span></span><br><span class="line"><span class="comment"># print(history.history)</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>， <span class="number">1</span>， <span class="number">1</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'accuracy'</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">'val_accuracy'</span>])</span><br><span class="line">plt.title(<span class="string">'Model Accuracy'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'epoch'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>， <span class="string">'test'</span>]， loc=<span class="string">'lower right'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>， <span class="number">1</span>， <span class="number">2</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'loss'</span>])  <span class="comment"># 损失</span></span><br><span class="line">plt.plot(history.history[<span class="string">'val_loss'</span>])  <span class="comment"># 测试集上的损失</span></span><br><span class="line">plt.title(<span class="string">'Model Loss'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'epoch'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>， <span class="string">'test'</span>]， loc=<span class="string">'upper right'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">save_dir = <span class="string">"./mnist/model/"</span></span><br><span class="line"><span class="keyword">if</span> tf.io.gfile.exists(save_dir):</span><br><span class="line">    tf.io.gfile.rmtree(save_dir)</span><br><span class="line">tf.io.gfile.makedirs(save_dir)</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">'keras_mnist.h5'</span></span><br><span class="line">model_path = os.path.join(save_dir， model_name)</span><br><span class="line">model.save(model_path)</span><br><span class="line">print(<span class="string">'Saved trained model at %s '</span> % model_path)</span><br></pre></td></tr></table></figure>

<p>训练的结果为:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Train on 60000 samples， validate on 10000 samples</span><br><span class="line">Epoch 1/5</span><br><span class="line"> - 10s - loss: 0.2186 - acc: 0.9353 - val_loss: 0.0935 - val_acc: 0.9709</span><br><span class="line">Epoch 2/5</span><br><span class="line"> - 11s - loss: 0.0788 - acc: 0.9754 - val_loss: 0.0757 - val_acc: 0.9749</span><br><span class="line">Epoch 3/5</span><br><span class="line"> - 11s - loss: 0.0494 - acc: 0.9837 - val_loss: 0.0636 - val_acc: 0.9807</span><br><span class="line">Epoch 4/5</span><br><span class="line"> - 12s - loss: 0.0353 - acc: 0.9888 - val_loss: 0.0762 - val_acc: 0.9769</span><br><span class="line">Epoch 5/5</span><br><span class="line"> - 11s - loss: 0.0265 - acc: 0.9910 - val_loss: 0.0724 - val_acc: 0.9786</span><br></pre></td></tr></table></figure>

<p>可视化指标效果如下:<br><img alt="手写数字2" src="https://i.loli.net/2019/12/04/2eY6HaTyqbkKZOr.jpg" width="40%"></p>
<p>保存模型后，如果要实现模型的加载，则可以使用<code>load_model</code>函数，其中<code>model_path</code>是模型的路径.使用训练好的此模型统计测试集上的分类结果，具体代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"></span><br><span class="line">(x_train， y_train)， (x_test， y_test) = mnist.load_data()</span><br><span class="line"><span class="comment"># 规范化</span></span><br><span class="line">X_test = x_test.reshape(<span class="number">10000</span>， <span class="number">784</span>)</span><br><span class="line">X_test = X_test.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_test /= <span class="number">255</span></span><br><span class="line"></span><br><span class="line">n_classes = <span class="number">10</span></span><br><span class="line">Y_test = np_utils.to_categorical(y_test， n_classes)</span><br><span class="line"></span><br><span class="line">save_dir = <span class="string">"./mnist/model/"</span></span><br><span class="line">model_name = <span class="string">'keras_mnist.h5'</span></span><br><span class="line">model_path = os.path.join(save_dir， model_name)</span><br><span class="line">mnist_model = load_model(model_path)</span><br><span class="line"></span><br><span class="line">loss_and_metrics = mnist_model.evaluate(X_test， Y_test， verbose=<span class="number">2</span>)</span><br><span class="line">print(<span class="string">"Test Loss: &#123;&#125;"</span>.format(loss_and_metrics[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">"Test Accuracy: &#123;&#125;%"</span>.format(loss_and_metrics[<span class="number">1</span>]*<span class="number">100</span>))</span><br><span class="line"></span><br><span class="line">predicted_classes = mnist_model.predict_classes(X_test)</span><br><span class="line"></span><br><span class="line">correct = np.nonzero(predicted_classes == y_test)[<span class="number">0</span>]</span><br><span class="line">incorrect = np.nonzero(predicted_classes != y_test)[<span class="number">0</span>]</span><br><span class="line">print(<span class="string">"Classified correctly count: &#123;&#125;"</span>.format(len(correct)))</span><br><span class="line">print(<span class="string">"Classified incorrectly count: &#123;&#125;"</span>.format(len(incorrect)))</span><br></pre></td></tr></table></figure>

<p>得到的结果如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Test Loss: 0.07241645678399945</span><br><span class="line">Test Accuracy: 97.86%</span><br><span class="line">Classified correctly count: 9786</span><br><span class="line">Classified incorrectly count: 214</span><br></pre></td></tr></table></figure>

<p>由此可见，训练结果还是相当不错的，准确率达到了97.86%.</p>
<p><strong>第3步：利用CNN进行手写数字识别</strong></p>
<p>整体的流程和第2步是非常类似的，只是在模型训练的过程中，采用的是CNN卷积神经网络，加入了更多的隐藏层，增加了模型的复杂度，也提高了模型的准确性.</p>
<p>具体的神经网络设计如下，分别为<code>卷积层-卷积层-池化层-dropout层-flatten层-全连接层-dropout层-softmax全连接层</code>，具体参数如下:</p>
<ol>
<li>第1层卷积，32个3x3的卷积核 ，激活函数使用 relu</li>
<li>第2层卷积，64个3x3的卷积核，激活函数使用 relu</li>
<li>最大池化层，池化窗口 2x2</li>
<li>Dropout 25% 的输入神经元</li>
<li>将 Pooled feature map 摊平后输入全连接网络</li>
<li>全联接层，激活函数使用 relu</li>
<li>Dropout 50% 的输入神经元</li>
<li>使用 softmax 激活函数做多分类，输出各数字的概率</li>
</ol>
<p>查看 MNIST CNN 模型网络结构:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Layer (type)                 Output Shape              Param #   </span><br><span class="line">=================================================================</span><br><span class="line">conv2d_1 (Conv2D)            (None， 26， 26， 32)        320       </span><br><span class="line">_________________________________________________________________</span><br><span class="line">conv2d_2 (Conv2D)            (None， 24， 24， 64)        18496     </span><br><span class="line">_________________________________________________________________</span><br><span class="line">max_pooling2d_1 (MaxPooling2 (None， 12， 12， 64)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_1 (Dropout)          (None， 12， 12， 64)        0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">flatten_1 (Flatten)          (None， 9216)              0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_1 (Dense)              (None， 128)               1179776   </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dropout_2 (Dropout)          (None， 128)               0         </span><br><span class="line">_________________________________________________________________</span><br><span class="line">dense_2 (Dense)              (None， 10)                1290      </span><br><span class="line">=================================================================</span><br><span class="line">Total params: 1，199，882</span><br><span class="line">Trainable params: 1，199，882</span><br><span class="line">Non-trainable params: 0</span><br></pre></td></tr></table></figure>

<p>具体代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense， Dropout， Flatten， Conv2D， MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> np_utils</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取数据集</span></span><br><span class="line">(x_train， y_train)， (x_test， y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 规范化</span></span><br><span class="line">img_rows， img_cols = <span class="number">28</span>， <span class="number">28</span></span><br><span class="line"><span class="keyword">if</span> K.image_data_format() == <span class="string">'channels_first'</span>:</span><br><span class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>]， <span class="number">1</span>， img_rows， img_cols)</span><br><span class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>]， <span class="number">1</span>， img_rows， img_cols)</span><br><span class="line">    input_shape = (<span class="number">1</span>， img_rows， img_cols)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>]， img_rows， img_cols， <span class="number">1</span>)</span><br><span class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>]， img_rows， img_cols， <span class="number">1</span>)</span><br><span class="line">    input_shape = (img_rows， img_cols， <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">X_train = x_train.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_test = x_test.astype(<span class="string">'float32'</span>)</span><br><span class="line">X_train /= <span class="number">255</span></span><br><span class="line">X_test /= <span class="number">255</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 统计各标签数量</span></span><br><span class="line">label， count = np.unique(y_train， return_counts=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># print(label， count)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化标签数量</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">plt.bar(label， count， width=<span class="number">0.7</span>， align=<span class="string">'center'</span>)</span><br><span class="line">plt.title(<span class="string">"Label Distribution"</span>)</span><br><span class="line">plt.xlabel(<span class="string">"Label"</span>)</span><br><span class="line">plt.ylabel(<span class="string">"Count"</span>)</span><br><span class="line">plt.xticks(label)</span><br><span class="line">plt.ylim(<span class="number">0</span>， <span class="number">7500</span>)</span><br><span class="line"><span class="keyword">for</span> label， count <span class="keyword">in</span> zip(label， count):</span><br><span class="line">    plt.text(label， count， <span class="string">'%d'</span> % count， ha=<span class="string">'center'</span>， va=<span class="string">'bottom'</span>， fontsize=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># one-hot编码</span></span><br><span class="line">n_classes = <span class="number">10</span></span><br><span class="line"><span class="comment"># print('before one-hot:'， y_train.shape)</span></span><br><span class="line">Y_train = np_utils.to_categorical(y_train， n_classes)</span><br><span class="line"><span class="comment"># print('after one-hot:'， Y_train.shape)</span></span><br><span class="line">Y_test = np_utils.to_categorical(y_test， n_classes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 Keras sequential model 定义 MNIST CNN 网络</span></span><br><span class="line">model = Sequential()</span><br><span class="line"><span class="comment"># 第1层卷积，32个3x3的卷积核 ，激活函数使用 relu</span></span><br><span class="line">model.add(Conv2D(filters=<span class="number">32</span>， kernel_size=(<span class="number">3</span>， <span class="number">3</span>)， activation=<span class="string">'relu'</span>，</span><br><span class="line">                 input_shape=input_shape))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第2层卷积，64个3x3的卷积核，激活函数使用 relu</span></span><br><span class="line">model.add(Conv2D(filters=<span class="number">64</span>， kernel_size=(<span class="number">3</span>， <span class="number">3</span>)， activation=<span class="string">'relu'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最大池化层，池化窗口 2x2</span></span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>， <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dropout 25% 的输入神经元</span></span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 Pooled feature map 摊平后输入全连接网络</span></span><br><span class="line">model.add(Flatten())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全联接层</span></span><br><span class="line">model.add(Dense(<span class="number">128</span>， activation=<span class="string">'relu'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dropout 50% 的输入神经元</span></span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 softmax 激活函数做多分类，输出各数字的概率</span></span><br><span class="line">model.add(Dense(n_classes， activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> model.layers:</span><br><span class="line">    print(layer.get_output_at(<span class="number">0</span>).get_shape().as_list())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 编译模型</span></span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>，</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>]， optimizer=<span class="string">'adam'</span>)</span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">history = model.fit(</span><br><span class="line">    X_train，</span><br><span class="line">    Y_train，</span><br><span class="line">    batch_size=<span class="number">128</span>，</span><br><span class="line">    epochs=<span class="number">5</span>，</span><br><span class="line">    verbose=<span class="number">2</span>，</span><br><span class="line">    validation_data=(X_test， Y_test)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化指标</span></span><br><span class="line"><span class="comment"># print(history.history)</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>， <span class="number">1</span>， <span class="number">1</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'accuracy'</span>])</span><br><span class="line">plt.plot(history.history[<span class="string">'val_accuracy'</span>])</span><br><span class="line">plt.title(<span class="string">'Model Accuracy'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'accuracy'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'epoch'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>， <span class="string">'test'</span>]， loc=<span class="string">'lower right'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">2</span>， <span class="number">1</span>， <span class="number">2</span>)</span><br><span class="line">plt.plot(history.history[<span class="string">'loss'</span>])  <span class="comment"># 损失</span></span><br><span class="line">plt.plot(history.history[<span class="string">'val_loss'</span>])  <span class="comment"># 测试集上的损失</span></span><br><span class="line">plt.title(<span class="string">'Model Loss'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'loss'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'epoch'</span>)</span><br><span class="line">plt.legend([<span class="string">'train'</span>， <span class="string">'test'</span>]， loc=<span class="string">'upper right'</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">save_dir = <span class="string">"./mnist/model/"</span></span><br><span class="line"><span class="keyword">if</span> tf.io.gfile.exists(save_dir):</span><br><span class="line">    tf.io.gfile.rmtree(save_dir)</span><br><span class="line">tf.io.gfile.makedirs(save_dir)</span><br><span class="line"></span><br><span class="line">model_name = <span class="string">'keras_mnist.h5'</span></span><br><span class="line">model_path = os.path.join(save_dir， model_name)</span><br><span class="line">model.save(model_path)</span><br><span class="line">print(<span class="string">'Saved trained model at %s '</span> % model_path)</span><br></pre></td></tr></table></figure>

<p>利用CNN卷积神经网络训练后，可视化指标如下:<br><img alt="手写数字3" src="https://i.loli.net/2019/12/04/xtWKq3zBeJHVr98.jpg" width="40%"></p>
<h4 id="验证码识别"><a href="#验证码识别" class="headerlink" title="验证码识别"></a>验证码识别</h4><p><strong>第1步：创建验证码数据集</strong></p>
<p>具体步骤如下:</p>
<ol>
<li>引入第三方包<code>ImageCaptcha</code></li>
<li>定义常量和字符集(验证码字符集(包括数字/大小字母/小写字母) 验证码参数(长度/高度/宽度) 数据集参数(训练数据集大小/测试数据集大小/训练数据集目录/测试数据集目录))</li>
<li>定义生成随机字符的方法</li>
<li>创建并保存验证码数据集的方法</li>
<li>创建并保存训练集</li>
<li>创建并保存测试集</li>
<li>生成并返回验证码数据集的方法</li>
<li>生成 100 张验证码图像和字符</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> captcha.image <span class="keyword">import</span> ImageCaptcha</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> PIL.Image <span class="keyword">as</span> Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义常量</span></span><br><span class="line">NUMBER = [<span class="string">'0'</span>， <span class="string">'1'</span>， <span class="string">'2'</span>， <span class="string">'3'</span>， <span class="string">'4'</span>， <span class="string">'5'</span>， <span class="string">'6'</span>， <span class="string">'7'</span>， <span class="string">'8'</span>， <span class="string">'9'</span>]</span><br><span class="line">LOWERCASE = [<span class="string">'a'</span>， <span class="string">'b'</span>， <span class="string">'c'</span>， <span class="string">'d'</span>， <span class="string">'e'</span>， <span class="string">'f'</span>， <span class="string">'g'</span>， <span class="string">'h'</span>， <span class="string">'i'</span>， <span class="string">'j'</span>， <span class="string">'k'</span>， <span class="string">'l'</span>， <span class="string">'m'</span>， <span class="string">'n'</span>， <span class="string">'o'</span>， <span class="string">'p'</span>， <span class="string">'q'</span>， <span class="string">'r'</span>， <span class="string">'s'</span>， <span class="string">'t'</span>， <span class="string">'u'</span>，</span><br><span class="line">             <span class="string">'v'</span>， <span class="string">'w'</span>， <span class="string">'x'</span>， <span class="string">'y'</span>， <span class="string">'z'</span>]</span><br><span class="line">UPPERCASE = [<span class="string">'A'</span>， <span class="string">'B'</span>， <span class="string">'C'</span>， <span class="string">'D'</span>， <span class="string">'E'</span>， <span class="string">'F'</span>， <span class="string">'G'</span>， <span class="string">'H'</span>， <span class="string">'I'</span>， <span class="string">'J'</span>， <span class="string">'K'</span>， <span class="string">'L'</span>， <span class="string">'M'</span>， <span class="string">'N'</span>， <span class="string">'O'</span>， <span class="string">'P'</span>， <span class="string">'Q'</span>， <span class="string">'R'</span>， <span class="string">'S'</span>， <span class="string">'T'</span>， <span class="string">'U'</span>，</span><br><span class="line">             <span class="string">'V'</span>， <span class="string">'W'</span>， <span class="string">'X'</span>， <span class="string">'Y'</span>， <span class="string">'Z'</span>]</span><br><span class="line"></span><br><span class="line">CAPTCHA_CHARSET = NUMBER   <span class="comment"># 验证码字符集</span></span><br><span class="line">CAPTCHA_LEN = <span class="number">4</span>            <span class="comment"># 验证码长度</span></span><br><span class="line">CAPTCHA_HEIGHT = <span class="number">60</span>        <span class="comment"># 验证码高度</span></span><br><span class="line">CAPTCHA_WIDTH = <span class="number">160</span>        <span class="comment"># 验证码宽度</span></span><br><span class="line"></span><br><span class="line">TRAIN_DATASET_SIZE = <span class="number">5000</span>     <span class="comment"># 验证码数据集大小</span></span><br><span class="line">TEST_DATASET_SIZE = <span class="number">1000</span></span><br><span class="line">TRAIN_DATA_DIR = <span class="string">'./train-data/'</span>  <span class="comment"># 验证码数据集目录</span></span><br><span class="line">TEST_DATA_DIR = <span class="string">'./test-data/'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成随机字符</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_random_text</span><span class="params">(charset=CAPTCHA_CHARSET， length=CAPTCHA_LEN)</span>:</span></span><br><span class="line">    text = [random.choice(charset) <span class="keyword">for</span> _ <span class="keyword">in</span> range(length)]</span><br><span class="line">    <span class="keyword">return</span> <span class="string">''</span>.join(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建并保存验证码数据集</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_captcha_dataset</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        size=<span class="number">100</span>，</span></span></span><br><span class="line"><span class="function"><span class="params">        data_dir=<span class="string">'./data/'</span>，</span></span></span><br><span class="line"><span class="function"><span class="params">        height=<span class="number">60</span>，</span></span></span><br><span class="line"><span class="function"><span class="params">        width=<span class="number">160</span>，</span></span></span><br><span class="line"><span class="function"><span class="params">        image_format=<span class="string">'.png'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> tf.io.gfile.exists(data_dir):</span><br><span class="line">        tf.io.gfile.rmtree(data_dir)</span><br><span class="line">    tf.io.gfile.makedirs(data_dir)</span><br><span class="line"></span><br><span class="line">    captcha = ImageCaptcha(width=width， height=height)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(size):</span><br><span class="line">        text = gen_random_text(CAPTCHA_CHARSET， CAPTCHA_LEN)</span><br><span class="line">        captcha.write(text， data_dir+text+image_format)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集</span></span><br><span class="line">create_captcha_dataset(TRAIN_DATASET_SIZE， TRAIN_DATA_DIR)</span><br><span class="line"><span class="comment"># 测试集</span></span><br><span class="line">create_captcha_dataset(TEST_DATASET_SIZE， TEST_DATA_DIR)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_captcha_dataset</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">        size=<span class="number">100</span>，</span></span></span><br><span class="line"><span class="function"><span class="params">        height=<span class="number">60</span>，</span></span></span><br><span class="line"><span class="function"><span class="params">        width=<span class="number">160</span>，</span></span></span><br><span class="line"><span class="function"><span class="params">        image_format=<span class="string">'.png'</span>)</span>:</span></span><br><span class="line">    captcha = ImageCaptcha(width=width， height=height)</span><br><span class="line">    images， texts = [<span class="literal">None</span>]*size， [<span class="literal">None</span>]*size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(size):</span><br><span class="line">        texts[i] = gen_random_text(CAPTCHA_CHARSET， CAPTCHA_LEN)</span><br><span class="line">        images[i] = np.array(Image.open(captcha.generate(texts[i])))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> images， texts</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成100张验证码图像</span></span><br><span class="line">images， texts = gen_captcha_dataset()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化验证码前20张图片</span></span><br><span class="line">plt.figure()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    plt.subplot(<span class="number">5</span>， <span class="number">4</span>， i+<span class="number">1</span>)</span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.imshow(images[i])</span><br><span class="line">    plt.title(<span class="string">"Label: &#123;&#125;"</span>.format(texts[i]))</span><br><span class="line">    plt.xticks([])</span><br><span class="line">    plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>最后生成 100 张验证码图像和字符如下:<br><img alt="验证码1" src="https://i.loli.net/2019/12/04/cmGYqsn6NyEuL3r.jpg" width="40%"></p>
<p><strong>第2步：数据处理</strong></p>
<p>具体步骤:</p>
<ol>
<li>读取训练集前 100 张图片，并通过文件名解析验证码（标签）</li>
<li>数据可视化</li>
<li>将 RGB 验证码图像转为灰度图</li>
<li>数据规范化</li>
<li>适配 Keras 图像数据格式</li>
<li>对验证码中每个字符进行 one-hot 编码</li>
<li>将验证码向量解码为对应字符</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">NUMBER = [<span class="string">'0'</span>， <span class="string">'1'</span>， <span class="string">'2'</span>， <span class="string">'3'</span>， <span class="string">'4'</span>， <span class="string">'5'</span>， <span class="string">'6'</span>， <span class="string">'7'</span>， <span class="string">'8'</span>， <span class="string">'9'</span>]</span><br><span class="line">LOWERCASE = [<span class="string">'a'</span>， <span class="string">'b'</span>， <span class="string">'c'</span>， <span class="string">'d'</span>， <span class="string">'e'</span>， <span class="string">'f'</span>， <span class="string">'g'</span>， <span class="string">'h'</span>， <span class="string">'i'</span>， <span class="string">'j'</span>， <span class="string">'k'</span>， <span class="string">'l'</span>， <span class="string">'m'</span>， <span class="string">'n'</span>， <span class="string">'o'</span>， <span class="string">'p'</span>， <span class="string">'q'</span>， <span class="string">'r'</span>， <span class="string">'s'</span>， <span class="string">'t'</span>， <span class="string">'u'</span>，</span><br><span class="line">             <span class="string">'v'</span>， <span class="string">'w'</span>， <span class="string">'x'</span>， <span class="string">'y'</span>， <span class="string">'z'</span>]</span><br><span class="line">UPPERCASE = [<span class="string">'A'</span>， <span class="string">'B'</span>， <span class="string">'C'</span>， <span class="string">'D'</span>， <span class="string">'E'</span>， <span class="string">'F'</span>， <span class="string">'G'</span>， <span class="string">'H'</span>， <span class="string">'I'</span>， <span class="string">'J'</span>， <span class="string">'K'</span>， <span class="string">'L'</span>， <span class="string">'M'</span>， <span class="string">'N'</span>， <span class="string">'O'</span>， <span class="string">'P'</span>， <span class="string">'Q'</span>， <span class="string">'R'</span>， <span class="string">'S'</span>， <span class="string">'T'</span>， <span class="string">'U'</span>，</span><br><span class="line">             <span class="string">'V'</span>， <span class="string">'W'</span>， <span class="string">'X'</span>， <span class="string">'Y'</span>， <span class="string">'Z'</span>]</span><br><span class="line"></span><br><span class="line">CAPTCHA_CHARSET = NUMBER   <span class="comment"># 验证码字符集</span></span><br><span class="line">CAPTCHA_LEN = <span class="number">4</span>            <span class="comment"># 验证码长度</span></span><br><span class="line">CAPTCHA_HEIGHT = <span class="number">60</span>        <span class="comment"># 验证码高度</span></span><br><span class="line">CAPTCHA_WIDTH = <span class="number">160</span>        <span class="comment"># 验证码宽度</span></span><br><span class="line"></span><br><span class="line">TRAIN_DATA_DIR = <span class="string">'./train-data/'</span>  <span class="comment"># 验证码数据集目录</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取训练集前100张图像</span></span><br><span class="line">image = []</span><br><span class="line">text = []</span><br><span class="line">count = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> glob.glob(TRAIN_DATA_DIR+<span class="string">'*.png'</span>):</span><br><span class="line">    image.append(np.array(Image.open(filename)))</span><br><span class="line">    text.append(filename.lstrip(TRAIN_DATA_DIR).rstrip(<span class="string">'.png'</span>)[<span class="number">1</span>:])</span><br><span class="line">    count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> count &gt;= <span class="number">100</span>:</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line"><span class="comment"># plt.figure()</span></span><br><span class="line"><span class="comment"># for i in range(20):</span></span><br><span class="line"><span class="comment">#     plt.subplot(5， 4， i+1)</span></span><br><span class="line"><span class="comment">#     plt.tight_layout()</span></span><br><span class="line"><span class="comment">#     plt.imshow(image[i])</span></span><br><span class="line"><span class="comment">#     plt.title("Label: &#123;&#125;".format(text[i]))</span></span><br><span class="line"><span class="comment">#     plt.xticks([])</span></span><br><span class="line"><span class="comment">#     plt.yticks([])</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line">image = np.array(image， dtype=np.float32)</span><br><span class="line"><span class="comment"># print(image.shape)  # (100， 60， 160， 3)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 将RGB转化为灰度图</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rgb2grey</span><span class="params">(img)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.dot(img[...， :<span class="number">3</span>]， [<span class="number">0.299</span>， <span class="number">0.587</span>， <span class="number">0.114</span>])</span><br><span class="line"></span><br><span class="line">image = rgb2grey(image)</span><br><span class="line"><span class="comment"># print(image.shape)  # (100， 60， 160)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据可视化</span></span><br><span class="line"><span class="comment"># plt.figure()</span></span><br><span class="line"><span class="comment"># for i in range(20):</span></span><br><span class="line"><span class="comment">#     plt.subplot(5， 4， i+1)</span></span><br><span class="line"><span class="comment">#     plt.tight_layout()</span></span><br><span class="line"><span class="comment">#     plt.imshow(image[i]， cmap='Greys')</span></span><br><span class="line"><span class="comment">#     plt.title("Label: &#123;&#125;".format(text[i]))</span></span><br><span class="line"><span class="comment">#     plt.xticks([])</span></span><br><span class="line"><span class="comment">#     plt.yticks([])</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据规范化</span></span><br><span class="line">image = image/<span class="number">255</span></span><br><span class="line"><span class="comment"># 适配keras图像数据格式</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_keras_channels</span><span class="params">(batch， rows=CAPTCHA_HEIGHT， cols=CAPTCHA_WIDTH)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> K.image_data_format() == <span class="string">'channels_first'</span>:</span><br><span class="line">        batch = batch.reshape(batch.shape[<span class="number">0</span>]， <span class="number">1</span>， rows， cols)</span><br><span class="line">        input_shape = (<span class="number">1</span>， rows， cols)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        batch = batch.reshape(batch.shape[<span class="number">0</span>]， rows， cols， <span class="number">1</span>)</span><br><span class="line">        input_shape = (rows， cols， <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> batch， input_shape</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">image， input_shape = fit_keras_channels(image)</span><br><span class="line"><span class="comment"># print(image.shape)  # (100， 60， 160， 1)</span></span><br><span class="line"><span class="comment"># print(input_shape)  # (60， 160， 1)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对验证码中每个字符进行 one-hot 编码</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text2vec</span><span class="params">(text， length=CAPTCHA_LEN， charset=CAPTCHA_CHARSET)</span>:</span></span><br><span class="line">    text_len = len(text)</span><br><span class="line">    <span class="comment"># 验证码长度校验</span></span><br><span class="line">    <span class="keyword">if</span> text_len != length:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">            <span class="string">'Error: length of captcha should be &#123;&#125;， but got &#123;&#125;'</span>.format(length， text_len))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成一个形如（CAPTCHA_LEN*CAPTHA_CHARSET，) 的一维向量</span></span><br><span class="line">    <span class="comment"># 例如，4个纯数字的验证码生成形如(4*10，)的一维向量</span></span><br><span class="line">    vec = np.zeros(length * len(charset))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length):</span><br><span class="line">        <span class="comment"># One-hot 编码验证码中的每个数字</span></span><br><span class="line">        <span class="comment"># 每个字符的热码 = 索引 + 偏移量</span></span><br><span class="line">        vec[charset.index(text[i]) + i*len(charset)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> vec</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">text = list(text)</span><br><span class="line">vec = [<span class="literal">None</span>]*len(text)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(vec)):</span><br><span class="line">    vec[i] = text2vec(text[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将验证码向量解码为对应字符</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vec2text</span><span class="params">(vector)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(vector， np.ndarray):</span><br><span class="line">        vector = np.asarray(vector)</span><br><span class="line">    vector = np.reshape(vector， [CAPTCHA_LEN， <span class="number">-1</span>])</span><br><span class="line">    text = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> vector:</span><br><span class="line">        text += CAPTCHA_CHARSET[np.argmax(item)]</span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></table></figure>

<p>最后生成的数字灰度图效果如下:<br><img alt="验证码2" src="https://i.loli.net/2019/12/06/c4yFqEJgYQPSaGZ.jpg" width="40%"></p>
<p><strong>第3步：训练模型</strong></p>
<p>具体步骤(前6步准备工作已经做过了，主要是要进行7-15步的模型训练过程，16-17步是做对应的保存工作):</p>
<ol>
<li>引入第三方包</li>
<li>定义超参数和字符集</li>
<li>将 RGB 验证码图像转为灰度图</li>
<li>对验证码中每个字符进行 one-hot 编码</li>
<li>将验证码向量解码为对应字符</li>
<li>适配 Keras 图像数据格式</li>
<li>读取训练集</li>
<li>处理训练集图像</li>
<li>处理训练集标签</li>
<li>读取测试集，处理对应图像和标签</li>
<li>创建验证码识别模型</li>
<li>查看模型摘要</li>
<li>模型可视化</li>
<li>训练模型</li>
<li>预测样例</li>
<li>保存模型</li>
<li>保存训练过程记录</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.utils.vis_utils <span class="keyword">import</span> plot_model</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">NUMBER = [<span class="string">'0'</span>， <span class="string">'1'</span>， <span class="string">'2'</span>， <span class="string">'3'</span>， <span class="string">'4'</span>， <span class="string">'5'</span>， <span class="string">'6'</span>， <span class="string">'7'</span>， <span class="string">'8'</span>， <span class="string">'9'</span>]</span><br><span class="line">LOWERCASE = [<span class="string">'a'</span>， <span class="string">'b'</span>， <span class="string">'c'</span>， <span class="string">'d'</span>， <span class="string">'e'</span>， <span class="string">'f'</span>， <span class="string">'g'</span>， <span class="string">'h'</span>， <span class="string">'i'</span>， <span class="string">'j'</span>， <span class="string">'k'</span>， <span class="string">'l'</span>， <span class="string">'m'</span>， <span class="string">'n'</span>， <span class="string">'o'</span>， <span class="string">'p'</span>， <span class="string">'q'</span>， <span class="string">'r'</span>， <span class="string">'s'</span>， <span class="string">'t'</span>， <span class="string">'u'</span>，</span><br><span class="line">             <span class="string">'v'</span>， <span class="string">'w'</span>， <span class="string">'x'</span>， <span class="string">'y'</span>， <span class="string">'z'</span>]</span><br><span class="line">UPPERCASE = [<span class="string">'A'</span>， <span class="string">'B'</span>， <span class="string">'C'</span>， <span class="string">'D'</span>， <span class="string">'E'</span>， <span class="string">'F'</span>， <span class="string">'G'</span>， <span class="string">'H'</span>， <span class="string">'I'</span>， <span class="string">'J'</span>， <span class="string">'K'</span>， <span class="string">'L'</span>， <span class="string">'M'</span>， <span class="string">'N'</span>， <span class="string">'O'</span>， <span class="string">'P'</span>， <span class="string">'Q'</span>， <span class="string">'R'</span>， <span class="string">'S'</span>， <span class="string">'T'</span>， <span class="string">'U'</span>，</span><br><span class="line">             <span class="string">'V'</span>， <span class="string">'W'</span>， <span class="string">'X'</span>， <span class="string">'Y'</span>， <span class="string">'Z'</span>]</span><br><span class="line"></span><br><span class="line">CAPTCHA_CHARSET = NUMBER   <span class="comment"># 验证码字符集</span></span><br><span class="line">CAPTCHA_LEN = <span class="number">4</span>            <span class="comment"># 验证码长度</span></span><br><span class="line">CAPTCHA_HEIGHT = <span class="number">60</span>        <span class="comment"># 验证码高度</span></span><br><span class="line">CAPTCHA_WIDTH = <span class="number">160</span>        <span class="comment"># 验证码宽度</span></span><br><span class="line"></span><br><span class="line">TRAIN_DATA_DIR = <span class="string">'./train-data/'</span>  <span class="comment"># 验证码数据集目录</span></span><br><span class="line">TEST_DATA_DIR = <span class="string">'./test-data/'</span></span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">100</span></span><br><span class="line">EPOCHS = <span class="number">10</span></span><br><span class="line">OPT = <span class="string">'adam'</span></span><br><span class="line">LOSS = <span class="string">'binary_crossentropy'</span></span><br><span class="line"></span><br><span class="line">MODEL_DIR = <span class="string">'./model/train_demo/'</span></span><br><span class="line">MODEL_FORMAT = <span class="string">'.h5'</span></span><br><span class="line">HISTORY_DIR = <span class="string">'./history/train_demo/'</span></span><br><span class="line">HISTORY_FORMAT = <span class="string">'.history'</span></span><br><span class="line"></span><br><span class="line">filename_str = <span class="string">"&#123;&#125;captcha_&#123;&#125;_&#123;&#125;_bs_&#123;&#125;_epochs_&#123;&#125;&#123;&#125;"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型网络结构文件</span></span><br><span class="line">MODEL_VIS_FILE = <span class="string">'captcha_classfication'</span> + <span class="string">'.png'</span></span><br><span class="line"><span class="comment"># 模型文件</span></span><br><span class="line">MODEL_FILE = filename_str.format(</span><br><span class="line">    MODEL_DIR， OPT， LOSS， str(BATCH_SIZE)， str(EPOCHS)， MODEL_FORMAT)</span><br><span class="line"><span class="comment"># 训练记录文件</span></span><br><span class="line">HISTORY_FILE = filename_str.format(</span><br><span class="line">    HISTORY_DIR， OPT， LOSS， str(BATCH_SIZE)， str(EPOCHS)， HISTORY_FORMAT)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rgb2gray</span><span class="params">(img)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> np.dot(img[...， :<span class="number">3</span>]， [<span class="number">0.299</span>， <span class="number">0.587</span>， <span class="number">0.114</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对验证码中每个字符进行 one-hot 编码</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">text2vec</span><span class="params">(text， length=CAPTCHA_LEN， charset=CAPTCHA_CHARSET)</span>:</span></span><br><span class="line">    text_len = len(text)</span><br><span class="line">    <span class="comment"># 验证码长度校验</span></span><br><span class="line">    <span class="keyword">if</span> text_len != length:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(</span><br><span class="line">            <span class="string">'Error: length of captcha should be &#123;&#125;， but got &#123;&#125;'</span>.format(length， text_len))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 生成一个形如（CAPTCHA_LEN*CAPTHA_CHARSET，) 的一维向量</span></span><br><span class="line">    <span class="comment"># 例如，4个纯数字的验证码生成形如(4*10，)的一维向量</span></span><br><span class="line">    vec = np.zeros(length * len(charset))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(length):</span><br><span class="line">        <span class="comment"># One-hot 编码验证码中的每个数字</span></span><br><span class="line">        <span class="comment"># 每个字符的热码 = 索引 + 偏移量</span></span><br><span class="line">        vec[charset.index(text[i]) + i*len(charset)] = <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> vec</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将验证码向量解码为对应字符</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vec2text</span><span class="params">(vector)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isinstance(vector， np.ndarray):</span><br><span class="line">        vector = np.asarray(vector)</span><br><span class="line">    vector = np.reshape(vector， [CAPTCHA_LEN， <span class="number">-1</span>])</span><br><span class="line">    text = <span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> vector:</span><br><span class="line">        text += CAPTCHA_CHARSET[np.argmax(item)]</span><br><span class="line">    <span class="keyword">return</span> text</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_keras_channels</span><span class="params">(batch， rows=CAPTCHA_HEIGHT， cols=CAPTCHA_WIDTH)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> K.image_data_format() == <span class="string">'channels_first'</span>:</span><br><span class="line">        batch = batch.reshape(batch.shape[<span class="number">0</span>]， <span class="number">1</span>， rows， cols)</span><br><span class="line">        input_shape = (<span class="number">1</span>， rows， cols)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        batch = batch.reshape(batch.shape[<span class="number">0</span>]， rows， cols， <span class="number">1</span>)</span><br><span class="line">        input_shape = (rows， cols， <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> batch， input_shape</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取训练集</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">X_train = []</span><br><span class="line">Y_train = []</span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> glob.glob(TRAIN_DATA_DIR + <span class="string">'*.png'</span>):</span><br><span class="line">    X_train.append(np.array(Image.open(filename)))</span><br><span class="line">    Y_train.append(filename.lstrip(TRAIN_DATA_DIR).rstrip(<span class="string">'.png'</span>)[<span class="number">1</span>:])</span><br><span class="line">X_train = np.array(X_train， dtype=np.float32)</span><br><span class="line">X_train = rgb2gray(X_train)</span><br><span class="line">X_train = X_train / <span class="number">255</span></span><br><span class="line">X_train， input_shape = fit_keras_channels(X_train)</span><br><span class="line"><span class="comment"># (3948， 60， 160， 1) &lt;class 'numpy.ndarray'&gt;</span></span><br><span class="line">print(X_train.shape， type(X_train))</span><br><span class="line">print(input_shape)  <span class="comment"># (60， 160， 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 处理训练集标签</span></span><br><span class="line">Y_train = list(Y_train)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y_train)):</span><br><span class="line">    Y_train[i] = text2vec(Y_train[i])</span><br><span class="line">Y_train = np.asarray(Y_train)</span><br><span class="line">print(Y_train.shape， type(Y_train))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取测试集，处理对应图像和标签</span></span><br><span class="line">X_test = []</span><br><span class="line">Y_test = []</span><br><span class="line"><span class="keyword">for</span> filename <span class="keyword">in</span> glob.glob(TEST_DATA_DIR + <span class="string">'*.png'</span>):</span><br><span class="line">    X_test.append(np.array(Image.open(filename)))</span><br><span class="line">    Y_test.append(filename.lstrip(TEST_DATA_DIR).rstrip(<span class="string">'.png'</span>)[<span class="number">1</span>:])</span><br><span class="line"><span class="comment"># list -&gt; rgb -&gt; gray -&gt; normalization -&gt; fit keras</span></span><br><span class="line">X_test = np.array(X_test， dtype=np.float32)</span><br><span class="line">X_test = rgb2gray(X_test)</span><br><span class="line">X_test = X_test / <span class="number">255</span></span><br><span class="line">X_test， _ = fit_keras_channels(X_test)</span><br><span class="line">Y_test = list(Y_test)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(len(Y_test)):</span><br><span class="line">    Y_test[i] = text2vec(Y_test[i])</span><br><span class="line">Y_test = np.asarray(Y_test)</span><br><span class="line">print(X_test.shape， type(X_test))</span><br><span class="line">print(Y_test.shape， type(Y_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建验证码识别模型</span></span><br><span class="line">inputs = Input(shape=input_shape， name=<span class="string">"inputs"</span>)</span><br><span class="line"><span class="comment"># 第1层卷积</span></span><br><span class="line">conv1 = Conv2D(<span class="number">32</span>， (<span class="number">3</span>， <span class="number">3</span>)， name=<span class="string">"conv1"</span>)(inputs)</span><br><span class="line">relu1 = Activation(<span class="string">'relu'</span>， name=<span class="string">"relu1"</span>)(conv1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第2层卷积</span></span><br><span class="line">conv2 = Conv2D(<span class="number">32</span>， (<span class="number">3</span>， <span class="number">3</span>)， name=<span class="string">"conv2"</span>)(relu1)</span><br><span class="line">relu2 = Activation(<span class="string">'relu'</span>， name=<span class="string">"relu2"</span>)(conv2)</span><br><span class="line">pool2 = MaxPooling2D(pool_size=(<span class="number">2</span>， <span class="number">2</span>)， padding=<span class="string">'same'</span>， name=<span class="string">"pool2"</span>)(relu2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第3层卷积</span></span><br><span class="line">conv3 = Conv2D(<span class="number">64</span>， (<span class="number">3</span>， <span class="number">3</span>)， name=<span class="string">"conv3"</span>)(pool2)</span><br><span class="line">relu3 = Activation(<span class="string">'relu'</span>， name=<span class="string">"relu3"</span>)(conv3)</span><br><span class="line">pool3 = MaxPooling2D(pool_size=(<span class="number">2</span>， <span class="number">2</span>)， padding=<span class="string">'same'</span>， name=<span class="string">"pool3"</span>)(relu3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 Pooled feature map 摊平后输入全连接网络</span></span><br><span class="line">x = Flatten()(pool3)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dropout</span></span><br><span class="line">x = Dropout(<span class="number">0.25</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4个全连接层分别做10分类，分别对应4个字符。</span></span><br><span class="line">x = [Dense(<span class="number">10</span>， activation=<span class="string">'softmax'</span>， name=<span class="string">'fc%d'</span> % (i+<span class="number">1</span>))(x) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4个字符向量拼接在一起，与标签向量形式一致，作为模型输出。</span></span><br><span class="line">outs = Concatenate()(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型的输入与输出</span></span><br><span class="line">model = Model(inputs=inputs， outputs=outs)</span><br><span class="line">model.compile(optimizer=OPT， loss=LOSS， metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line">plot_model(model， to_file=MODEL_VIS_FILE， show_shapes=<span class="literal">True</span>)</span><br><span class="line">history = model.fit(X_train，</span><br><span class="line">                    Y_train，</span><br><span class="line">                    batch_size=BATCH_SIZE，</span><br><span class="line">                    epochs=EPOCHS，</span><br><span class="line">                    verbose=<span class="number">2</span>，</span><br><span class="line">                    validation_data=(X_test， Y_test))</span><br><span class="line"></span><br><span class="line">print(vec2text(Y_test[<span class="number">9</span>]))</span><br><span class="line">yy = model.predict(X_test[<span class="number">9</span>].reshape(<span class="number">1</span>， <span class="number">60</span>， <span class="number">160</span>， <span class="number">1</span>))</span><br><span class="line">print(vec2text(yy))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> tf.io.gfile.exists(MODEL_DIR):</span><br><span class="line">    tf.io.gfile.makedirs(MODEL_DIR)</span><br><span class="line">model.save(MODEL_DIR)</span><br><span class="line">print(<span class="string">'Saved trained model at %s '</span> % MODEL_FILE)</span><br></pre></td></tr></table></figure>

<p>训练模型得到的参数如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Train on 3956 samples， validate on 954 samples</span><br><span class="line">Epoch 1/10</span><br><span class="line"> - 149s - loss: 0.3270 - acc: 0.9000 - val_loss: 0.3247 - val_acc: 0.9000</span><br><span class="line">Epoch 2/10</span><br><span class="line"> - 122s - loss: 0.3229 - acc: 0.9000 - val_loss: 0.3195 - val_acc: 0.9000</span><br><span class="line">Epoch 3/10</span><br><span class="line"> - 114s - loss: 0.2987 - acc: 0.9004 - val_loss: 0.2726 - val_acc: 0.9028</span><br><span class="line">Epoch 4/10</span><br><span class="line"> - 106s - loss: 0.2257 - acc: 0.9164 - val_loss: 0.2303 - val_acc: 0.9171</span><br><span class="line">Epoch 5/10</span><br><span class="line"> - 103s - loss: 0.1799 - acc: 0.9337 - val_loss: 0.2171 - val_acc: 0.9209</span><br><span class="line">Epoch 6/10</span><br><span class="line"> - 113s - loss: 0.1523 - acc: 0.9447 - val_loss: 0.2062 - val_acc: 0.9254</span><br><span class="line">Epoch 7/10</span><br><span class="line"> - 112s - loss: 0.1383 - acc: 0.9498 - val_loss: 0.2048 - val_acc: 0.9260</span><br><span class="line">Epoch 8/10</span><br><span class="line"> - 127s - loss: 0.1251 - acc: 0.9550 - val_loss: 0.2052 - val_acc: 0.9260</span><br><span class="line">Epoch 9/10</span><br><span class="line"> - 161s - loss: 0.1144 - acc: 0.9587 - val_loss: 0.2013 - val_acc: 0.9285</span><br><span class="line">Epoch 10/10</span><br><span class="line"> - 159s - loss: 0.1063 - acc: 0.9618 - val_loss: 0.2045 - val_acc: 0.9268</span><br></pre></td></tr></table></figure>

<h4 id="实现词云"><a href="#实现词云" class="headerlink" title="实现词云"></a>实现词云</h4><p>要实现词云效果，首先需要安装wordcloud库，<code>pip install wordcloud</code>进行安装即可。<br><strong>1. 英文词云</strong></p>
<p>实现基本的英文词云:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文本</span></span><br><span class="line">text = open(<span class="string">'./text/constitution.txt'</span>).read()</span><br><span class="line"><span class="comment"># 生成对象</span></span><br><span class="line">wc = WordCloud().generate(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示词云</span></span><br><span class="line">plt.imshow(wc， interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到文件</span></span><br><span class="line">wc.to_file(<span class="string">'./img/word1.png'</span>)</span><br></pre></td></tr></table></figure>

<p>效果展示:<br><img alt="word1" src="https://i.loli.net/2019/12/05/JH9ISij5pf3s4c7.png" width="40%"><br><strong>2. 中文词云</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文本</span></span><br><span class="line">text = open(<span class="string">'./text/xyj.txt'</span>，encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"><span class="comment"># 生成对象</span></span><br><span class="line">wc = WordCloud(font_path=<span class="string">'Hiragino.ttf'</span>， width=<span class="number">800</span>， height=<span class="number">600</span>， mode=<span class="string">'RGBA'</span>， background_color=<span class="literal">None</span>).generate(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示词云</span></span><br><span class="line">plt.imshow(wc， interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到文件</span></span><br><span class="line">wc.to_file(<span class="string">'./img/word2.png'</span>)</span><br></pre></td></tr></table></figure>

<p>其中读取文件使用<code>text = open(&#39;xxx.txt&#39;，encoding=&#39;UTF-8&#39;).read()</code>，注意这里要写<code>encoding=&#39;UTF-8&#39;</code>，否则无法正确读取内容。要额外引入字体文件，如上例引入了<code>Hiragino.ttf</code>字体。最后生成的效果如下，但是有个问题就是每个词并不是按照中文意思进行断开的，无实际意义，接下来我们处理中文分词问题。</p>
<img alt="word2" src="https://i.loli.net/2019/12/05/uULNjfAvbi1Qzog.png" width="40%">

<p><strong>3. 中文词云+分词</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文本</span></span><br><span class="line">text = open(<span class="string">'./text/xyj.txt'</span>，encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文分词</span></span><br><span class="line">text=<span class="string">' '</span>.join(jieba.cut(text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成对象</span></span><br><span class="line">wc = WordCloud(font_path=<span class="string">'Hiragino.ttf'</span>， width=<span class="number">800</span>， height=<span class="number">600</span>， mode=<span class="string">'RGBA'</span>， background_color=<span class="literal">None</span>).generate(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示词云</span></span><br><span class="line">plt.imshow(wc， interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到文件</span></span><br><span class="line">wc.to_file(<span class="string">'./img/word3.png'</span>)</span><br></pre></td></tr></table></figure>

<p>因为英文文章中每个单词都是使用空格隔开的，因此不需要手动分词，而中文文章每个词是连在一起的，需要引入第三方包jieba进行中文分词操作。核心代码是<code>text=&#39; &#39;.join(jieba.cut(text))</code>，这样可以使得每个独立的词用空格隔开。最后生成的效果如下:</p>
<img alt="word3" src="https://i.loli.net/2019/12/05/6cnprdOQqC1Hg9y.png" width="40%">

<p><strong>4. 中文词云+分词+黑白蒙版</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文本</span></span><br><span class="line">text = open(<span class="string">'./text/xyj.txt'</span>，encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文分词</span></span><br><span class="line">text=<span class="string">' '</span>.join(jieba.cut(text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用黑白蒙版</span></span><br><span class="line">mask=np.array(Image.open(<span class="string">'./mask/black_mask.png'</span>))</span><br><span class="line">wc = WordCloud(mask=mask，font_path=<span class="string">'Hiragino.ttf'</span>， width=<span class="number">800</span>， height=<span class="number">600</span>， mode=<span class="string">'RGBA'</span>， background_color=<span class="literal">None</span>).generate(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示词云</span></span><br><span class="line">plt.imshow(wc， interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到文件</span></span><br><span class="line">wc.to_file(<span class="string">'./img/word4.png'</span>)</span><br></pre></td></tr></table></figure>

<p>这里使用了黑白图片作为蒙版，WordCloud()函数中传入mask参数，则可以启用对应的蒙版，这样生成的词云会与蒙版的图形相同。效果如下:</p>
<img alt="black_mask" src="https://i.loli.net/2019/12/05/tL2DrkwCBfImVjX.png" width="40%">
<img alt="word4" src="https://i.loli.net/2019/12/05/rtBYgubj2FHWRax.png" width="40%">

<p><strong>5. 中文词云+分词+彩色蒙版</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud，ImageColorGenerator</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文本</span></span><br><span class="line">text = open(<span class="string">'./text/xyj.txt'</span>，encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文分词</span></span><br><span class="line">text=<span class="string">' '</span>.join(jieba.cut(text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用彩色蒙版</span></span><br><span class="line">mask=np.array(Image.open(<span class="string">'./mask/color_mask.png'</span>))</span><br><span class="line">wc = WordCloud(mask=mask，font_path=<span class="string">'Hiragino.ttf'</span>， width=<span class="number">800</span>， height=<span class="number">600</span>， mode=<span class="string">'RGBA'</span>， background_color=<span class="literal">None</span>).generate(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从图片中生成颜色</span></span><br><span class="line">image_colors=ImageColorGenerator(mask)</span><br><span class="line">wc.recolor(color_func=image_colors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示词云</span></span><br><span class="line">plt.imshow(wc， interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到文件</span></span><br><span class="line">wc.to_file(<span class="string">'./img/word5.png'</span>)</span><br></pre></td></tr></table></figure>

<p>这里使用了彩色图片作为蒙版，从<code>wordcloud</code>引入<code>ImageColorGenerator</code>函数，从图片中生成颜色，这样生成的词云颜色和蒙版的颜色是相同的（每个部分的颜色都是大致对应的），效果如下:</p>
<img alt="color_mask" src="https://i.loli.net/2019/12/05/CPoBbah9xpc8vQw.png" width="40%">
<img alt="word5" src="https://i.loli.net/2019/12/05/gM61KJWk2CfFbtP.png" width="40%">

<p><strong>6. 中文词云+分词+彩色蒙版+自定义颜色</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文本</span></span><br><span class="line">text = open(<span class="string">'./text/xyj.txt'</span>，encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文分词</span></span><br><span class="line">text=<span class="string">' '</span>.join(jieba.cut(text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义颜色函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">random_color</span><span class="params">(word， font_size， position， orientation， font_path， random_state)</span>:</span></span><br><span class="line">	s = <span class="string">'hsl(0， %d%%， %d%%)'</span> % (random.randint(<span class="number">60</span>， <span class="number">80</span>)， random.randint(<span class="number">60</span>， <span class="number">80</span>))</span><br><span class="line">	<span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用彩色蒙版</span></span><br><span class="line">mask=np.array(Image.open(<span class="string">'./mask/color_mask.png'</span>))</span><br><span class="line">wc = WordCloud(color_func=random_color，mask=mask，font_path=<span class="string">'Hiragino.ttf'</span>， width=<span class="number">800</span>， height=<span class="number">600</span>， mode=<span class="string">'RGBA'</span>， background_color=<span class="literal">None</span>).generate(text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示词云</span></span><br><span class="line">plt.imshow(wc， interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到文件</span></span><br><span class="line">wc.to_file(<span class="string">'./img/word6.png'</span>)</span><br></pre></td></tr></table></figure>

<p>为了实现为词云自定义颜色，我们可以单独实现一个上色函数random_color，在WordCloud()函数中传入color_func参数即可，效果如下:<br><img alt="word6" src="https://i.loli.net/2019/12/05/NR35QBMyviqaPLE.png" width="40%"></p>
<p><strong>7. 中文词云+分词+彩色蒙版+关键词权重</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud，ImageColorGenerator</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开文本</span></span><br><span class="line">text = open(<span class="string">'./text/xyj.txt'</span>，encoding=<span class="string">'UTF-8'</span>).read()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 提取关键词和权重</span></span><br><span class="line">freq=jieba.analyse.extract_tags(text，topK=<span class="number">200</span>，withWeight=<span class="literal">True</span>)</span><br><span class="line">freq = &#123;i[<span class="number">0</span>]: i[<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> freq&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文分词</span></span><br><span class="line">text=<span class="string">' '</span>.join(jieba.cut(text))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用彩色蒙版</span></span><br><span class="line">mask=np.array(Image.open(<span class="string">'./mask/color_mask.png'</span>))</span><br><span class="line">wc = WordCloud(mask=mask，font_path=<span class="string">'Hiragino.ttf'</span>， width=<span class="number">800</span>， height=<span class="number">600</span>， mode=<span class="string">'RGBA'</span>， background_color=<span class="literal">None</span>).generate_from_frequencies(freq)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从图片中生成颜色</span></span><br><span class="line">image_colors=ImageColorGenerator(mask)</span><br><span class="line">wc.recolor(color_func=image_colors)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示词云</span></span><br><span class="line">plt.imshow(wc， interpolation=<span class="string">'bilinear'</span>)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存到文件</span></span><br><span class="line">wc.to_file(<span class="string">'./img/word7.png'</span>)</span><br></pre></td></tr></table></figure>

<p>为了在词云中凸显词语出现的频率，我们可以采用根据频率上色的方法，频率出现越高则着色越深。先提取关键词和权重，再通过<code>WordCloud().generate_from_frequencies(freq)</code>生成词云即可，注意这里的freq是词与频次关系的字典。最后生成的效果如下:<br><img alt="word7" src="https://i.loli.net/2019/12/05/3QJc5DhoREsryuz.png" width="40%"></p>
<h4 id="自编码器图像去噪AE"><a href="#自编码器图像去噪AE" class="headerlink" title="自编码器图像去噪AE"></a>自编码器图像去噪AE</h4><p>自编码器深度学习中的一类无监督学习模型，由encoder和decoder两个部分组成</p>
<p>自编码器主要是一种思想，encoder和decoder可以由全连接层\CNN\RNN等模型实现</p>
<p>自编码器Auto-Encoder的原理：<br><img alt="自编码3" src="https://i.loli.net/2019/12/06/7Kb6U1MCRWBnhto.jpg" width="60%"></p>
<p><strong>第1步：完成模型训练，并保存模型</strong></p>
<p>具体步骤:</p>
<ol>
<li>获取训练集和测试集</li>
<li>随机添加噪声点</li>
<li>可视化噪声图</li>
<li>构建模型</li>
<li>训练模型</li>
<li>保存模型</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input， Dense， Conv2D， MaxPooling2D， UpSampling2D</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model， load_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取训练集和测试集</span></span><br><span class="line">(x_train， _)， (x_test， _) = mnist.load_data()</span><br><span class="line">x_train = x_train.astype(<span class="string">'float32'</span>) / <span class="number">255.</span></span><br><span class="line">x_test = x_test.astype(<span class="string">'float32'</span>) / <span class="number">255.</span></span><br><span class="line">x_train = np.reshape(x_train， (len(x_train)， <span class="number">28</span>， <span class="number">28</span>， <span class="number">1</span>))</span><br><span class="line">x_test = np.reshape(x_test， (len(x_test)， <span class="number">28</span>， <span class="number">28</span>， <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机添加噪声点</span></span><br><span class="line">noise_factor = <span class="number">0.5</span></span><br><span class="line">x_train_noisy = x_train + noise_factor * np.random.normal(loc=<span class="number">0.0</span>， scale=<span class="number">1.0</span>， size=x_train.shape) </span><br><span class="line">x_test_noisy = x_test + noise_factor * np.random.normal(loc=<span class="number">0.0</span>， scale=<span class="number">1.0</span>， size=x_test.shape) </span><br><span class="line">x_train_noisy = np.clip(x_train_noisy， <span class="number">0.</span>， <span class="number">1.</span>)</span><br><span class="line">x_test_noisy = np.clip(x_test_noisy， <span class="number">0.</span>， <span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化噪声图</span></span><br><span class="line">n = <span class="number">10</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>， <span class="number">2</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    ax = plt.subplot(<span class="number">1</span>， n， i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(x_test_noisy[i].reshape(<span class="number">28</span>， <span class="number">28</span>))</span><br><span class="line">    plt.gray()</span><br><span class="line">    ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建模型</span></span><br><span class="line">input_img = Input(shape=(<span class="number">28</span>， <span class="number">28</span>， <span class="number">1</span>，)) <span class="comment"># N * 28 * 28 * 1</span></span><br><span class="line">x = Conv2D(<span class="number">32</span>， (<span class="number">3</span>， <span class="number">3</span>)， padding=<span class="string">'same'</span>， activation=<span class="string">'relu'</span>)(input_img) <span class="comment"># 28 * 28 * 32</span></span><br><span class="line">x = MaxPooling2D((<span class="number">2</span>， <span class="number">2</span>)， padding=<span class="string">'same'</span>)(x) <span class="comment"># 14 * 14 * 32</span></span><br><span class="line">x = Conv2D(<span class="number">32</span>， (<span class="number">3</span>， <span class="number">3</span>)， padding=<span class="string">'same'</span>， activation=<span class="string">'relu'</span>)(x) <span class="comment"># 14 * 14 * 32</span></span><br><span class="line">encoded = MaxPooling2D((<span class="number">2</span>， <span class="number">2</span>)， padding=<span class="string">'same'</span>)(x) <span class="comment"># 7 * 7 * 32</span></span><br><span class="line">x = Conv2D(<span class="number">32</span>， (<span class="number">3</span>， <span class="number">3</span>)， padding=<span class="string">'same'</span>， activation=<span class="string">'relu'</span>)(encoded) <span class="comment"># 7 * 7 * 32</span></span><br><span class="line">x = UpSampling2D((<span class="number">2</span>， <span class="number">2</span>))(x) <span class="comment"># 14 * 14 * 32</span></span><br><span class="line">x = Conv2D(<span class="number">32</span>， (<span class="number">3</span>， <span class="number">3</span>)， padding=<span class="string">'same'</span>， activation=<span class="string">'relu'</span>)(x) <span class="comment"># 14 * 14 * 32</span></span><br><span class="line">x = UpSampling2D((<span class="number">2</span>， <span class="number">2</span>))(x) <span class="comment"># 28 * 28 * 32</span></span><br><span class="line">decoded = Conv2D(<span class="number">1</span>， (<span class="number">3</span>， <span class="number">3</span>)， padding=<span class="string">'same'</span>， activation=<span class="string">'sigmoid'</span>)(x) <span class="comment"># 28 * 28 * 1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练模型</span></span><br><span class="line">autoencoder = Model(input_img， decoded)</span><br><span class="line">autoencoder.compile(optimizer=<span class="string">'adadelta'</span>， loss=<span class="string">'binary_crossentropy'</span>)</span><br><span class="line">autoencoder.fit(x_train_noisy， x_train，</span><br><span class="line">                epochs=<span class="number">100</span>，</span><br><span class="line">                batch_size=<span class="number">128</span>，</span><br><span class="line">                shuffle=<span class="literal">True</span>，</span><br><span class="line">                validation_data=(x_test_noisy， x_test))</span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">autoencoder.save(<span class="string">'autoencoder.h5'</span>)</span><br></pre></td></tr></table></figure>

<p>可视化噪声图片效果如下:<br><img alt="自编码1" src="https://i.loli.net/2019/12/06/jF5SXZAWdVzf1HM.jpg" width="60%"></p>
<p><strong>第2步：加载训练好的模型，用来图像去噪</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model，load_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载训练好了的模型</span></span><br><span class="line">autoencoder = load_model(<span class="string">'autoencoder.h5'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取训练集和测试集</span></span><br><span class="line">(x_train， _)， (x_test， _) = mnist.load_data()</span><br><span class="line">x_train = x_train.astype(<span class="string">'float32'</span>) / <span class="number">255.</span></span><br><span class="line">x_test = x_test.astype(<span class="string">'float32'</span>) / <span class="number">255.</span></span><br><span class="line">x_train = np.reshape(x_train， (len(x_train)， <span class="number">28</span>， <span class="number">28</span>， <span class="number">1</span>))</span><br><span class="line">x_test = np.reshape(x_test， (len(x_test)， <span class="number">28</span>， <span class="number">28</span>， <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机添加噪声点</span></span><br><span class="line">noise_factor = <span class="number">0.5</span></span><br><span class="line">x_train_noisy = x_train + noise_factor * np.random.normal(loc=<span class="number">0.0</span>， scale=<span class="number">1.0</span>， size=x_train.shape) </span><br><span class="line">x_test_noisy = x_test + noise_factor * np.random.normal(loc=<span class="number">0.0</span>， scale=<span class="number">1.0</span>， size=x_test.shape) </span><br><span class="line">x_train_noisy = np.clip(x_train_noisy， <span class="number">0.</span>， <span class="number">1.</span>)</span><br><span class="line">x_test_noisy = np.clip(x_test_noisy， <span class="number">0.</span>， <span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line">decoded_imgs = autoencoder.predict(x_test_noisy)</span><br><span class="line">n = <span class="number">10</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>， <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">    <span class="comment"># 展示原始噪声图</span></span><br><span class="line">    ax = plt.subplot(<span class="number">2</span>， n， i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(x_test_noisy[i].reshape(<span class="number">28</span>， <span class="number">28</span>))</span><br><span class="line">    plt.gray()</span><br><span class="line">    ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line"> </span><br><span class="line">    <span class="comment"># 展示去噪后的图片</span></span><br><span class="line">    ax = plt.subplot(<span class="number">2</span>， n， i + <span class="number">1</span> + n)</span><br><span class="line">    plt.imshow(decoded_imgs[i].reshape(<span class="number">28</span>， <span class="number">28</span>))</span><br><span class="line">    plt.gray()</span><br><span class="line">    ax.get_xaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">    ax.get_yaxis().set_visible(<span class="literal">False</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>原始噪声图 vs 去噪后的图片 的效果如下:<br><img alt="自编码2" src="https://i.loli.net/2019/12/06/Nl3fRZ9b7viKWPV.jpg" width="60%"></p>
<h4 id="变分自编码器VAE"><a href="#变分自编码器VAE" class="headerlink" title="变分自编码器VAE"></a>变分自编码器VAE</h4><p>我们经常会有这样的需求:根据很多个样本，学会生成新的样本</p>
<p>以mnist为例，在看过成百上千张图片后，让计算机能够模仿生成一些类似的图片，这些图片在原始数据中并不存在，但是与原来图片看起来相似</p>
<p>简言之就是需要学会数据x的分布，根据数据分布产生新样本</p>
<p><strong>VAE(变分自编码器)和AE(自编码器)的区别:</strong></p>
<ol>
<li>AE中隐层表示的分布未知，而VAE中隐层变量服从高斯分布</li>
<li>AE中学习的是encoder和decoder，VAE中还学习隐变量的分布，包括高斯分布的均值和方差</li>
<li>AE只能从1个x得到对应的重构x</li>
<li>VAE可以产生新的z，从而得到新的x，即生成新的样本(VAE是一种常见的生成式模型)</li>
</ol>
<p>可以使用<code>keras.datasets</code>中的<code>mnist</code>或<code>fashion_mnist</code>进行测试:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input， Dense， Lambda</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> objectives</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="comment"># from keras.datasets import fashion_mnist</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义常数</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">original_dim = <span class="number">784</span> <span class="comment"># 28*28</span></span><br><span class="line">intermediate_dim = <span class="number">256</span></span><br><span class="line">latent_dim = <span class="number">2</span></span><br><span class="line">epochs = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">x = Input(shape=(original_dim，)) <span class="comment"># 维度28*28，数据数量不确定</span></span><br><span class="line">h = Dense(intermediate_dim， activation=<span class="string">'relu'</span>)(x) <span class="comment"># 输出维度是256</span></span><br><span class="line">z_mean = Dense(latent_dim)(h) <span class="comment"># 全连接层</span></span><br><span class="line">z_log_var = Dense(latent_dim)(h) <span class="comment"># 全连接层</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 根据均值和方差生成z</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sampling</span><span class="params">(args)</span>:</span></span><br><span class="line">    z_mean， z_log_var = args</span><br><span class="line">    epsilon = K.random_normal(shape=(batch_size， latent_dim)， mean=<span class="number">0.</span>)</span><br><span class="line">    <span class="keyword">return</span> z_mean + K.exp(z_log_var / <span class="number">2</span>) * epsilon</span><br><span class="line"><span class="comment"># Lambda层不参与训练，只参与计算，用于后面产生新的z</span></span><br><span class="line">z = Lambda(sampling， output_shape=(latent_dim，))([z_mean， z_log_var])</span><br><span class="line"></span><br><span class="line"><span class="comment"># decoder部分包含两个全连接层</span></span><br><span class="line">decoder_h = Dense(intermediate_dim， activation=<span class="string">'relu'</span>)</span><br><span class="line">decoder_mean = Dense(original_dim， activation=<span class="string">'sigmoid'</span>)</span><br><span class="line">h_decoded = decoder_h(z)</span><br><span class="line">x_decoded_mean = decoder_mean(h_decoded)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 总的损失函数，计算交叉熵</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">vae_loss</span><span class="params">(x， x_decoded_mean)</span>:</span></span><br><span class="line">    xent_loss = original_dim * objectives.binary_crossentropy(x， x_decoded_mean)</span><br><span class="line">    kl_loss = <span class="number">-0.5</span> * K.sum(<span class="number">1</span> + z_log_var - K.square(z_mean) - K.exp(z_log_var)， axis=<span class="number">-1</span>)</span><br><span class="line">    <span class="keyword">return</span> xent_loss + kl_loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里使用rmsprop优化算法和手写的loss函数vae_loss</span></span><br><span class="line">vae = Model(x， x_decoded_mean)</span><br><span class="line">vae.compile(optimizer=<span class="string">'rmsprop'</span>， loss=vae_loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载并训练数据</span></span><br><span class="line">(x_train， y_train)， (x_test， y_test) = mnist.load_data()</span><br><span class="line">x_train = x_train.astype(<span class="string">'float32'</span>) / <span class="number">255.</span></span><br><span class="line">x_test = x_test.astype(<span class="string">'float32'</span>) / <span class="number">255.</span></span><br><span class="line">x_train = x_train.reshape((len(x_train)， np.prod(x_train.shape[<span class="number">1</span>:])))</span><br><span class="line">x_test = x_test.reshape((len(x_test)， np.prod(x_test.shape[<span class="number">1</span>:])))</span><br><span class="line"></span><br><span class="line">vae.fit(x_train， x_train，</span><br><span class="line">        shuffle=<span class="literal">True</span>，</span><br><span class="line">        epochs=epochs，</span><br><span class="line">        batch_size=batch_size，</span><br><span class="line">        validation_data=(x_test， x_test))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个encoder，看看mnist中的数据在隐层中是怎么样的，前面将latent_dim定位为2，是为了输出二维平面化图</span></span><br><span class="line">encoder = Model(x， z_mean)</span><br><span class="line"></span><br><span class="line">x_test_encoded = encoder.predict(x_test， batch_size=batch_size)</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>， <span class="number">6</span>))</span><br><span class="line">plt.scatter(x_test_encoded[:， <span class="number">0</span>]， x_test_encoded[:， <span class="number">1</span>]， c=y_test)</span><br><span class="line">plt.colorbar()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义生成器</span></span><br><span class="line">decoder_input = Input(shape=(latent_dim，))</span><br><span class="line">_h_decoded = decoder_h(decoder_input)</span><br><span class="line">_x_decoded_mean = decoder_mean(_h_decoded)</span><br><span class="line">generator = Model(decoder_input， _x_decoded_mean)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证生成器能生成什么样的图片</span></span><br><span class="line">n = <span class="number">20</span></span><br><span class="line">digit_size = <span class="number">28</span></span><br><span class="line">figure = np.zeros((digit_size * n， digit_size * n))</span><br><span class="line">grid_x = np.linspace(<span class="number">-4</span>， <span class="number">4</span>， n)</span><br><span class="line">grid_y = np.linspace(<span class="number">-4</span>， <span class="number">4</span>， n)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i， xi <span class="keyword">in</span> enumerate(grid_x):</span><br><span class="line">    <span class="keyword">for</span> j， yi <span class="keyword">in</span> enumerate(grid_y):</span><br><span class="line">        z_sample = np.array([[yi， xi]])</span><br><span class="line">        x_decoded = generator.predict(z_sample)</span><br><span class="line">        digit = x_decoded[<span class="number">0</span>].reshape(digit_size， digit_size)</span><br><span class="line">        figure[(n - i - <span class="number">1</span>) * digit_size: (n - i) * digit_size，</span><br><span class="line">               j * digit_size: (j + <span class="number">1</span>) * digit_size] = digit</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>， <span class="number">10</span>))</span><br><span class="line">plt.imshow(figure)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>encoder的可视化效果(mnist中的数据在隐层中的形态):<br><img alt="变分自编码器1" src="https://i.loli.net/2019/12/06/pGhBjnA2Z8V6Cfy.jpg" width="40%"><br>验证生成器能生成什么样的图片:<br><img alt="变分自编码器2" src="https://i.loli.net/2019/12/06/Kd8aIAczRDxqitO.jpg" width="40%"></p>
<h4 id="生成式对抗网络GAN"><a href="#生成式对抗网络GAN" class="headerlink" title="生成式对抗网络GAN"></a>生成式对抗网络GAN</h4><p>除VAE以外，生成式对抗网络(GAN)也是一种非常流行的无监督生成式模型.</p>
<p>GAN中包括两个核心网络:</p>
<ol>
<li>生成器(generator):记作G，通过对大量样本的学习，能够生成一些以假乱真的样本，和VAE类似</li>
<li>判别器(discriminator):记作D，接受真实样本和G生成的样本，并进行判别和区分</li>
<li>G和D相互博弈，通过学习，G的生成能力和D的判别能力都逐渐增强并收敛</li>
</ol>
<p>GAN的训练非常困难，有很多需要注意的细节，才能生成质量较高的图片:</p>
<ol>
<li>恰当地使用BN(Batch Normalization) / LeakyReLU等</li>
<li>用strides为2的卷积代替池化</li>
<li>交替训练，避免一方过强</li>
</ol>
<p>完整代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os， imageio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载手写数据集</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'MNIST_data'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义参数</span></span><br><span class="line">batch_size = <span class="number">100</span> <span class="comment"># 每次训练的样本数</span></span><br><span class="line">z_dim = <span class="number">100</span> <span class="comment"># 输出大小</span></span><br><span class="line">OUTPUT_DIR = <span class="string">'samples'</span> <span class="comment"># 输出目录</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(OUTPUT_DIR):</span><br><span class="line">    os.mkdir(OUTPUT_DIR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义X、noise、is_training变量</span></span><br><span class="line">X = tf.placeholder(dtype=tf.float32， shape=[<span class="literal">None</span>， <span class="number">28</span>， <span class="number">28</span>， <span class="number">1</span>]， name=<span class="string">'X'</span>)</span><br><span class="line">noise = tf.placeholder(dtype=tf.float32， shape=[<span class="literal">None</span>， z_dim]， name=<span class="string">'noise'</span>)</span><br><span class="line">is_training = tf.placeholder(dtype=tf.bool， name=<span class="string">'is_training'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 激活函数leakyRelu</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lrelu</span><span class="params">(x， leak=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.maximum(x， leak * x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_cross_entropy_with_logits</span><span class="params">(x， y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.sigmoid_cross_entropy_with_logits(logits=x， labels=y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 关键点---判别器/生成器的定义</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 1 判别器</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(image， reuse=None， is_training=is_training)</span>:</span></span><br><span class="line">    momentum = <span class="number">0.9</span> <span class="comment"># 动量</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'discriminator'</span>， reuse=reuse):</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 卷积开始，filters越来越多，图片越来越小</span></span><br><span class="line">        <span class="comment"># h0: -1，28，28，1</span></span><br><span class="line">        <span class="comment"># h1: -1，24，24，64</span></span><br><span class="line">        <span class="comment"># h2: -1，12，12，128</span></span><br><span class="line">        <span class="comment"># h3: -1，6，6，256</span></span><br><span class="line">        <span class="comment"># h4: -1，3，3，512</span></span><br><span class="line">        <span class="comment"># h4作为判别器输出</span></span><br><span class="line">        </span><br><span class="line">        h0 = lrelu(tf.layers.conv2d(image， kernel_size=<span class="number">5</span>， filters=<span class="number">64</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>))</span><br><span class="line">        </span><br><span class="line">        h1 = tf.layers.conv2d(h0， kernel_size=<span class="number">5</span>， filters=<span class="number">128</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        <span class="comment"># batch_norm转化为标准的高斯分布，指数加权滑动平均算法，decay是衰减系数</span></span><br><span class="line">        h1 = lrelu(tf.contrib.layers.batch_norm(h1， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h2 = tf.layers.conv2d(h1， kernel_size=<span class="number">5</span>， filters=<span class="number">256</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h2 = lrelu(tf.contrib.layers.batch_norm(h2， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h3 = tf.layers.conv2d(h2， kernel_size=<span class="number">5</span>， filters=<span class="number">512</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h3 = lrelu(tf.contrib.layers.batch_norm(h3， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h4 = tf.contrib.layers.flatten(h3)</span><br><span class="line">        h4 = tf.layers.dense(h4， units=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 返回经过sigmoid处理后的h4和未被激活的h4</span></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(h4)， h4</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2 生成器(输入的z是噪音，为二维tensor)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(z， is_training=is_training)</span>:</span></span><br><span class="line">    momentum = <span class="number">0.9</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'generator'</span>， reuse=<span class="literal">None</span>):</span><br><span class="line">        d = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 逆卷积开始，filters越来越少</span></span><br><span class="line">        <span class="comment"># h0: -1，3，3，512</span></span><br><span class="line">        <span class="comment"># h1: -1，6，6，256</span></span><br><span class="line">        <span class="comment"># h2: -1，12，12，128</span></span><br><span class="line">        <span class="comment"># h3: -1，24，24，64</span></span><br><span class="line">        <span class="comment"># h4: -1，28，28，1</span></span><br><span class="line">        <span class="comment"># h4作为生成器的输出</span></span><br><span class="line"></span><br><span class="line">        h0 = tf.layers.dense(z， units=d * d * <span class="number">512</span>)</span><br><span class="line">        h0 = tf.reshape(h0， shape=[<span class="number">-1</span>， d， d， <span class="number">512</span>])</span><br><span class="line">        h0 = tf.nn.relu(tf.contrib.layers.batch_norm(h0， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h1 = tf.layers.conv2d_transpose(h0， kernel_size=<span class="number">5</span>， filters=<span class="number">256</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h1 = tf.nn.relu(tf.contrib.layers.batch_norm(h1， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h2 = tf.layers.conv2d_transpose(h1， kernel_size=<span class="number">5</span>， filters=<span class="number">128</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h2 = tf.nn.relu(tf.contrib.layers.batch_norm(h2， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h3 = tf.layers.conv2d_transpose(h2， kernel_size=<span class="number">5</span>， filters=<span class="number">64</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h3 = tf.nn.relu(tf.contrib.layers.batch_norm(h3， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h4 = tf.layers.conv2d_transpose(h3， kernel_size=<span class="number">5</span>， filters=<span class="number">1</span>， strides=<span class="number">1</span>， padding=<span class="string">'valid'</span>， activation=tf.nn.tanh， name=<span class="string">'g'</span>)</span><br><span class="line">        <span class="keyword">return</span> h4</span><br><span class="line"></span><br><span class="line">g = generator(noise) <span class="comment"># 生成的假图片</span></span><br><span class="line">d_real， d_real_logits = discriminator(X) <span class="comment"># 真图片激活后h4和未激活h4的值</span></span><br><span class="line">d_fake， d_fake_logits = discriminator(g， reuse=<span class="literal">True</span>) <span class="comment"># 假图片激活后h4和未激活h4的值</span></span><br><span class="line"></span><br><span class="line">vars_g = [var <span class="keyword">for</span> var <span class="keyword">in</span> tf.trainable_variables() <span class="keyword">if</span> var.name.startswith(<span class="string">'generator'</span>)] <span class="comment"># 和generator相关的参数</span></span><br><span class="line">vars_d = [var <span class="keyword">for</span> var <span class="keyword">in</span> tf.trainable_variables() <span class="keyword">if</span> var.name.startswith(<span class="string">'discriminator'</span>)] <span class="comment"># 和discriminator相关的参数</span></span><br><span class="line"></span><br><span class="line">loss_d_real = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_real_logits， tf.ones_like(d_real))) <span class="comment"># 真图片导致的判别器损失</span></span><br><span class="line">loss_d_fake = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_fake_logits， tf.zeros_like(d_fake))) <span class="comment"># 假图片导致的判别器损失</span></span><br><span class="line">loss_g = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_fake_logits， tf.ones_like(d_fake))) <span class="comment"># 生成器损失</span></span><br><span class="line">loss_d = loss_d_real + loss_d_fake <span class="comment"># 判别器损失(真图片+假图片)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 优化函数</span></span><br><span class="line"><span class="comment"># 先完成update_ops的相关操作(如BN的参数更新)，再完成后续的优化操作</span></span><br><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</span><br><span class="line">    optimizer_d = tf.train.AdamOptimizer(learning_rate=<span class="number">0.0002</span>， beta1=<span class="number">0.5</span>).minimize(loss_d， var_list=vars_d)</span><br><span class="line">    optimizer_g = tf.train.AdamOptimizer(learning_rate=<span class="number">0.0002</span>， beta1=<span class="number">0.5</span>).minimize(loss_g， var_list=vars_g)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 辅助函数，用于将多张图片以网格状拼接在一起</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">montage</span><span class="params">(images)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(images， list):</span><br><span class="line">        images = np.array(images)</span><br><span class="line">    img_h = images.shape[<span class="number">1</span>]</span><br><span class="line">    img_w = images.shape[<span class="number">2</span>]</span><br><span class="line">    n_plots = int(np.ceil(np.sqrt(images.shape[<span class="number">0</span>])))</span><br><span class="line">    m = np.ones((images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>， images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_plots):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n_plots):</span><br><span class="line">            this_filter = i * n_plots + j</span><br><span class="line">            <span class="keyword">if</span> this_filter &lt; images.shape[<span class="number">0</span>]:</span><br><span class="line">                this_img = images[this_filter]</span><br><span class="line">                m[<span class="number">1</span> + i + i * img_h:<span class="number">1</span> + i + (i + <span class="number">1</span>) * img_h，</span><br><span class="line">                  <span class="number">1</span> + j + j * img_w:<span class="number">1</span> + j + (j + <span class="number">1</span>) * img_w] = this_img</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练(需要交替训练，如每次迭代训练G两次)</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">z_samples = np.random.uniform(<span class="number">-1.0</span>， <span class="number">1.0</span>， [batch_size， z_dim]).astype(np.float32)</span><br><span class="line">samples = []</span><br><span class="line">loss = &#123;<span class="string">'d'</span>: []， <span class="string">'g'</span>: []&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">60000</span>):</span><br><span class="line">    <span class="comment"># 产生随机noise</span></span><br><span class="line">    n = np.random.uniform(<span class="number">-1.0</span>， <span class="number">1.0</span>， [batch_size， z_dim]).astype(np.float32)</span><br><span class="line">    <span class="comment"># 依次取数据</span></span><br><span class="line">    batch = mnist.train.next_batch(batch_size=batch_size)[<span class="number">0</span>]</span><br><span class="line">    batch = np.reshape(batch， [<span class="number">-1</span>， <span class="number">28</span>， <span class="number">28</span>， <span class="number">1</span>])</span><br><span class="line">    <span class="comment"># batch是0~1(relu)，我们要将它映射到-1~1(tanh的取值范围)</span></span><br><span class="line">    batch = (batch - <span class="number">0.5</span>) * <span class="number">2</span> </span><br><span class="line">    </span><br><span class="line">    d_ls， g_ls = sess.run([loss_d， loss_g]， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">    loss[<span class="string">'d'</span>].append(d_ls)</span><br><span class="line">    loss[<span class="string">'g'</span>].append(g_ls)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#依次训练D-G-G(判别器训练1次，生成器训练2次)</span></span><br><span class="line">    sess.run(optimizer_d， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">    sess.run(optimizer_g， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">    sess.run(optimizer_g， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 每迭代1000轮，打印样本</span></span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">        print(i， d_ls， g_ls)</span><br><span class="line">        gen_imgs = sess.run(g， feed_dict=&#123;noise: z_samples， is_training: <span class="literal">False</span>&#125;)</span><br><span class="line">        <span class="comment"># -1~1转0~1</span></span><br><span class="line">        gen_imgs = (gen_imgs + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">        imgs = [img[:， :， <span class="number">0</span>] <span class="keyword">for</span> img <span class="keyword">in</span> gen_imgs]</span><br><span class="line">        gen_imgs = montage(imgs)</span><br><span class="line">        plt.axis(<span class="string">'off'</span>)</span><br><span class="line">        plt.imshow(gen_imgs， cmap=<span class="string">'gray'</span>)</span><br><span class="line">        plt.savefig(os.path.join(OUTPUT_DIR， <span class="string">'sample_%d.jpg'</span> % i))</span><br><span class="line">        plt.show()</span><br><span class="line">        samples.append(gen_imgs)</span><br><span class="line"></span><br><span class="line">plt.plot(loss[<span class="string">'d'</span>]， label=<span class="string">'Discriminator'</span>)</span><br><span class="line">plt.plot(loss[<span class="string">'g'</span>]， label=<span class="string">'Generator'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper right'</span>)</span><br><span class="line">plt.savefig(<span class="string">'Loss.png'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">imageio.mimsave(os.path.join(OUTPUT_DIR， <span class="string">'samples.gif'</span>)， samples， fps=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.save(sess， <span class="string">'./mnist_dcgan'</span>， global_step=<span class="number">60000</span>)</span><br></pre></td></tr></table></figure>

<p>图片经过卷积的基本结构变化如下:<br><img alt="GAN1" src="https://i.loli.net/2019/12/06/o1SbOdCWfzRrM5P.png" width="80%"><br>生成的手写数字图片的动图效果为:<br><img alt="GAN2" src="https://i.loli.net/2019/12/06/HorfvGPthVemqK1.gif" width="40%"></p>
<p>训练好模型后，可直接加载模型，自动生成类似图片:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">z_dim = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">montage</span><span class="params">(images)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(images， list):</span><br><span class="line">        images = np.array(images)</span><br><span class="line">    img_h = images.shape[<span class="number">1</span>]</span><br><span class="line">    img_w = images.shape[<span class="number">2</span>]</span><br><span class="line">    n_plots = int(np.ceil(np.sqrt(images.shape[<span class="number">0</span>])))</span><br><span class="line">    m = np.ones((images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>， images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_plots):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n_plots):</span><br><span class="line">            this_filter = i * n_plots + j</span><br><span class="line">            <span class="keyword">if</span> this_filter &lt; images.shape[<span class="number">0</span>]:</span><br><span class="line">                this_img = images[this_filter]</span><br><span class="line">                m[<span class="number">1</span> + i + i * img_h:<span class="number">1</span> + i + (i + <span class="number">1</span>) * img_h，</span><br><span class="line">                  <span class="number">1</span> + j + j * img_w:<span class="number">1</span> + j + (j + <span class="number">1</span>) * img_w] = this_img</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">saver = tf.train.import_meta_graph(<span class="string">'./mnist_dcgan-60000.meta'</span>)</span><br><span class="line">saver.restore(sess， tf.train.latest_checkpoint(<span class="string">'./'</span>))</span><br><span class="line"></span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">g = graph.get_tensor_by_name(<span class="string">'generator/g/Tanh:0'</span>)</span><br><span class="line">noise = graph.get_tensor_by_name(<span class="string">'noise:0'</span>)</span><br><span class="line">is_training = graph.get_tensor_by_name(<span class="string">'is_training:0'</span>)</span><br><span class="line"></span><br><span class="line">n = np.random.uniform(<span class="number">-1.0</span>， <span class="number">1.0</span>， [batch_size， z_dim]).astype(np.float32)</span><br><span class="line">gen_imgs = sess.run(g， feed_dict=&#123;noise: n， is_training: <span class="literal">False</span>&#125;)</span><br><span class="line">gen_imgs = (gen_imgs + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">imgs = [img[:， :， <span class="number">0</span>] <span class="keyword">for</span> img <span class="keyword">in</span> gen_imgs]</span><br><span class="line">gen_imgs = montage(imgs)</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.imshow(gen_imgs， cmap=<span class="string">'gray'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="人脸图片生成DCGAN"><a href="#人脸图片生成DCGAN" class="headerlink" title="人脸图片生成DCGAN"></a>人脸图片生成DCGAN</h4><p>在人脸数据上训练DCGAN，并生成一些人脸图片 (使用两个数据集:LFW和CelebA)</p>
<p>和GAN的训练过程类似，代码几乎都一样，只是要处理的是彩色图片，注意图片通道</p>
<p>训练模型:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> tarfile</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">from</span> imageio <span class="keyword">import</span> imread， imsave， mimsave</span><br><span class="line"><span class="keyword">from</span> scipy.misc <span class="keyword">import</span> imresize</span><br><span class="line"><span class="keyword">import</span> glob <span class="comment"># 读取图片路径</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载和处理LFW数据</span></span><br><span class="line"><span class="comment"># 因为下载的文件夹中含有各个人名子文件夹，我们现在的任务是将它们全部转移保存到同一文件夹中</span></span><br><span class="line">url = <span class="string">'http://vis-www.cs.umass.edu/lfw/lfw.tgz'</span></span><br><span class="line">filename = <span class="string">'lfw.tgz'</span></span><br><span class="line">directory = <span class="string">'lfw_imgs'</span></span><br><span class="line">new_dir = <span class="string">'lfw_new_imgs'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(new_dir):</span><br><span class="line">    os.mkdir(new_dir)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(directory):</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(filename):</span><br><span class="line">            urllib.request.urlretrieve(url， filename)</span><br><span class="line">        tar = tarfile.open(filename， <span class="string">'r:gz'</span>)</span><br><span class="line">        tar.extractall(path=directory)</span><br><span class="line">        tar.close()</span><br><span class="line">    </span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> dir_， _， files <span class="keyword">in</span> os.walk(directory):</span><br><span class="line">        <span class="keyword">for</span> file_ <span class="keyword">in</span> files:</span><br><span class="line">            img = imread(os.path.join(dir_， file_))</span><br><span class="line">            imsave(os.path.join(new_dir， <span class="string">'%d.png'</span> % count)， img)</span><br><span class="line">            count += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定要用哪个数据集</span></span><br><span class="line"><span class="comment"># dataset = 'lfw_new_imgs' # LFW</span></span><br><span class="line">dataset = <span class="string">'celeba'</span> <span class="comment"># CelebA</span></span><br><span class="line">images = glob.glob(os.path.join(dataset， <span class="string">'*.*'</span>)) </span><br><span class="line"><span class="comment"># print(len(images))</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">z_dim = <span class="number">100</span></span><br><span class="line">WIDTH = <span class="number">64</span></span><br><span class="line">HEIGHT = <span class="number">64</span></span><br><span class="line"></span><br><span class="line">OUTPUT_DIR = <span class="string">'samples_'</span> + dataset</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(OUTPUT_DIR):</span><br><span class="line">    os.mkdir(OUTPUT_DIR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 彩色图，3通道</span></span><br><span class="line">X = tf.placeholder(dtype=tf.float32， shape=[<span class="literal">None</span>， HEIGHT， WIDTH， <span class="number">3</span>]， name=<span class="string">'X'</span>)</span><br><span class="line">noise = tf.placeholder(dtype=tf.float32， shape=[<span class="literal">None</span>， z_dim]， name=<span class="string">'noise'</span>)</span><br><span class="line">is_training = tf.placeholder(dtype=tf.bool， name=<span class="string">'is_training'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lrelu</span><span class="params">(x， leak=<span class="number">0.2</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.maximum(x， leak * x)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid_cross_entropy_with_logits</span><span class="params">(x， y)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.sigmoid_cross_entropy_with_logits(logits=x， labels=y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 判别器(和GAN相同)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">discriminator</span><span class="params">(image， reuse=None， is_training=is_training)</span>:</span></span><br><span class="line">    momentum = <span class="number">0.9</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'discriminator'</span>， reuse=reuse):</span><br><span class="line">        h0 = lrelu(tf.layers.conv2d(image， kernel_size=<span class="number">5</span>， filters=<span class="number">64</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>))</span><br><span class="line">        </span><br><span class="line">        h1 = tf.layers.conv2d(h0， kernel_size=<span class="number">5</span>， filters=<span class="number">128</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h1 = lrelu(tf.contrib.layers.batch_norm(h1， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h2 = tf.layers.conv2d(h1， kernel_size=<span class="number">5</span>， filters=<span class="number">256</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h2 = lrelu(tf.contrib.layers.batch_norm(h2， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h3 = tf.layers.conv2d(h2， kernel_size=<span class="number">5</span>， filters=<span class="number">512</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h3 = lrelu(tf.contrib.layers.batch_norm(h3， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h4 = tf.contrib.layers.flatten(h3)</span><br><span class="line">        h4 = tf.layers.dense(h4， units=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(h4)， h4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成器(d改为4，GAN的d是3)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generator</span><span class="params">(z， is_training=is_training)</span>:</span></span><br><span class="line">    momentum = <span class="number">0.9</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'generator'</span>， reuse=<span class="literal">None</span>):</span><br><span class="line">        d = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># h0: -1，4，4，512</span></span><br><span class="line">        <span class="comment"># h1: -1，8，8，256</span></span><br><span class="line">        <span class="comment"># h2: -1，16，16，128</span></span><br><span class="line">        <span class="comment"># h3: -1，32，32，64</span></span><br><span class="line">        <span class="comment"># h4: -1，64，64，3</span></span><br><span class="line">        <span class="comment"># h4作为判别器输出</span></span><br><span class="line"></span><br><span class="line">        h0 = tf.layers.dense(z， units=d * d * <span class="number">512</span>)</span><br><span class="line">        h0 = tf.reshape(h0， shape=[<span class="number">-1</span>， d， d， <span class="number">512</span>])</span><br><span class="line">        h0 = tf.nn.relu(tf.contrib.layers.batch_norm(h0， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h1 = tf.layers.conv2d_transpose(h0， kernel_size=<span class="number">5</span>， filters=<span class="number">256</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h1 = tf.nn.relu(tf.contrib.layers.batch_norm(h1， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h2 = tf.layers.conv2d_transpose(h1， kernel_size=<span class="number">5</span>， filters=<span class="number">128</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h2 = tf.nn.relu(tf.contrib.layers.batch_norm(h2， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h3 = tf.layers.conv2d_transpose(h2， kernel_size=<span class="number">5</span>， filters=<span class="number">64</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>)</span><br><span class="line">        h3 = tf.nn.relu(tf.contrib.layers.batch_norm(h3， is_training=is_training， decay=momentum))</span><br><span class="line">        </span><br><span class="line">        h4 = tf.layers.conv2d_transpose(h3， kernel_size=<span class="number">5</span>， filters=<span class="number">3</span>， strides=<span class="number">2</span>， padding=<span class="string">'same'</span>， activation=tf.nn.tanh， name=<span class="string">'g'</span>)</span><br><span class="line">        <span class="keyword">return</span> h4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">g = generator(noise)</span><br><span class="line">d_real， d_real_logits = discriminator(X)</span><br><span class="line">d_fake， d_fake_logits = discriminator(g， reuse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">vars_g = [var <span class="keyword">for</span> var <span class="keyword">in</span> tf.trainable_variables() <span class="keyword">if</span> var.name.startswith(<span class="string">'generator'</span>)]</span><br><span class="line">vars_d = [var <span class="keyword">for</span> var <span class="keyword">in</span> tf.trainable_variables() <span class="keyword">if</span> var.name.startswith(<span class="string">'discriminator'</span>)]</span><br><span class="line"></span><br><span class="line">loss_d_real = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_real_logits， tf.ones_like(d_real)))</span><br><span class="line">loss_d_fake = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_fake_logits， tf.zeros_like(d_fake)))</span><br><span class="line">loss_g = tf.reduce_mean(sigmoid_cross_entropy_with_logits(d_fake_logits， tf.ones_like(d_fake)))</span><br><span class="line">loss_d = loss_d_real + loss_d_fake</span><br><span class="line"></span><br><span class="line">update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies(update_ops):</span><br><span class="line">    optimizer_d = tf.train.AdamOptimizer(learning_rate=<span class="number">0.0002</span>， beta1=<span class="number">0.5</span>).minimize(loss_d， var_list=vars_d)</span><br><span class="line">    optimizer_g = tf.train.AdamOptimizer(learning_rate=<span class="number">0.0002</span>， beta1=<span class="number">0.5</span>).minimize(loss_g， var_list=vars_g)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> <span class="comment"># 读取图片的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_image</span><span class="params">(path， height， width)</span>:</span></span><br><span class="line">    image = imread(path)</span><br><span class="line">    h = image.shape[<span class="number">0</span>]</span><br><span class="line">    w = image.shape[<span class="number">1</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> h &gt; w:</span><br><span class="line">        image = image[h // <span class="number">2</span> - w // <span class="number">2</span>: h // <span class="number">2</span> + w // <span class="number">2</span>， :， :]</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        image = image[:， w // <span class="number">2</span> - h // <span class="number">2</span>: w // <span class="number">2</span> + h // <span class="number">2</span>， :]    </span><br><span class="line">    </span><br><span class="line">    image = imresize(image， (height， width))</span><br><span class="line">    <span class="comment"># image是1-255</span></span><br><span class="line">    <span class="keyword">return</span> image / <span class="number">255.</span> <span class="comment"># 0-1之间   </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 合成图片的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">montage</span><span class="params">(images)</span>:</span>    </span><br><span class="line">    <span class="keyword">if</span> isinstance(images， list):</span><br><span class="line">        images = np.array(images)</span><br><span class="line">    img_h = images.shape[<span class="number">1</span>]</span><br><span class="line">    img_w = images.shape[<span class="number">2</span>]</span><br><span class="line">    n_plots = int(np.ceil(np.sqrt(images.shape[<span class="number">0</span>])))</span><br><span class="line">    <span class="keyword">if</span> len(images.shape) == <span class="number">4</span> <span class="keyword">and</span> images.shape[<span class="number">3</span>] == <span class="number">3</span>:</span><br><span class="line">        m = np.ones(</span><br><span class="line">            (images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>，</span><br><span class="line">             images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>， <span class="number">3</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">elif</span> len(images.shape) == <span class="number">4</span> <span class="keyword">and</span> images.shape[<span class="number">3</span>] == <span class="number">1</span>:</span><br><span class="line">        m = np.ones(</span><br><span class="line">            (images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>，</span><br><span class="line">             images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>， <span class="number">1</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">elif</span> len(images.shape) == <span class="number">3</span>:</span><br><span class="line">        m = np.ones(</span><br><span class="line">            (images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>，</span><br><span class="line">             images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Could not parse image shape of &#123;&#125;'</span>.format(images.shape))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_plots):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n_plots):</span><br><span class="line">            this_filter = i * n_plots + j</span><br><span class="line">            <span class="keyword">if</span> this_filter &lt; images.shape[<span class="number">0</span>]:</span><br><span class="line">                this_img = images[this_filter]</span><br><span class="line">                m[<span class="number">1</span> + i + i * img_h:<span class="number">1</span> + i + (i + <span class="number">1</span>) * img_h，</span><br><span class="line">                  <span class="number">1</span> + j + j * img_w:<span class="number">1</span> + j + (j + <span class="number">1</span>) * img_w] = this_img</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line">z_samples = np.random.uniform(<span class="number">-1.0</span>， <span class="number">1.0</span>， [batch_size， z_dim]).astype(np.float32)</span><br><span class="line">samples = []</span><br><span class="line">loss = &#123;<span class="string">'d'</span>: []， <span class="string">'g'</span>: []&#125;</span><br><span class="line"></span><br><span class="line">offset = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">60000</span>):</span><br><span class="line">    n = np.random.uniform(<span class="number">-1.0</span>， <span class="number">1.0</span>， [batch_size， z_dim]).astype(np.float32)</span><br><span class="line">    </span><br><span class="line">    offset = (offset + batch_size) % len(images)</span><br><span class="line">    batch = np.array([read_image(img， HEIGHT， WIDTH) <span class="keyword">for</span> img <span class="keyword">in</span> images[offset: offset + batch_size]])</span><br><span class="line">    batch = (batch - <span class="number">0.5</span>) * <span class="number">2</span></span><br><span class="line">    </span><br><span class="line">    d_ls， g_ls = sess.run([loss_d， loss_g]， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">    loss[<span class="string">'d'</span>].append(d_ls)</span><br><span class="line">    loss[<span class="string">'g'</span>].append(g_ls)</span><br><span class="line">    </span><br><span class="line">    sess.run(optimizer_d， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">    sess.run(optimizer_g， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">    sess.run(optimizer_g， feed_dict=&#123;X: batch， noise: n， is_training: <span class="literal">True</span>&#125;)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">        print(i， d_ls， g_ls)</span><br><span class="line">        gen_imgs = sess.run(g， feed_dict=&#123;noise: z_samples， is_training: <span class="literal">False</span>&#125;)</span><br><span class="line">        gen_imgs = (gen_imgs + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">        imgs = [img[:， :， :] <span class="keyword">for</span> img <span class="keyword">in</span> gen_imgs]</span><br><span class="line">        gen_imgs = montage(imgs)</span><br><span class="line">        plt.axis(<span class="string">'off'</span>)</span><br><span class="line">        plt.imshow(gen_imgs)</span><br><span class="line">        imsave(os.path.join(OUTPUT_DIR， <span class="string">'sample_%d.jpg'</span> % i)， gen_imgs)</span><br><span class="line">        plt.show()</span><br><span class="line">        samples.append(gen_imgs)</span><br><span class="line"></span><br><span class="line">plt.plot(loss[<span class="string">'d'</span>]， label=<span class="string">'Discriminator'</span>)</span><br><span class="line">plt.plot(loss[<span class="string">'g'</span>]， label=<span class="string">'Generator'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'upper right'</span>)</span><br><span class="line">plt.savefig(os.path.join(OUTPUT_DIR， <span class="string">'Loss.png'</span>))</span><br><span class="line">plt.show()</span><br><span class="line">mimsave(os.path.join(OUTPUT_DIR， <span class="string">'samples.gif'</span>)， samples， fps=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">saver = tf.train.Saver()</span><br><span class="line">saver.save(sess， os.path.join(OUTPUT_DIR， <span class="string">'dcgan_'</span> + dataset)， global_step=<span class="number">60000</span>)</span><br></pre></td></tr></table></figure>

<p>加载已训练好的模型，自动生成人脸图片:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">z_dim = <span class="number">100</span></span><br><span class="line"><span class="comment"># dataset = 'lfw_new_imgs'</span></span><br><span class="line">dataset = <span class="string">'celeba'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">montage</span><span class="params">(images)</span>:</span>    </span><br><span class="line">    <span class="keyword">if</span> isinstance(images， list):</span><br><span class="line">        images = np.array(images)</span><br><span class="line">    img_h = images.shape[<span class="number">1</span>]</span><br><span class="line">    img_w = images.shape[<span class="number">2</span>]</span><br><span class="line">    n_plots = int(np.ceil(np.sqrt(images.shape[<span class="number">0</span>])))</span><br><span class="line">    <span class="keyword">if</span> len(images.shape) == <span class="number">4</span> <span class="keyword">and</span> images.shape[<span class="number">3</span>] == <span class="number">3</span>:</span><br><span class="line">        m = np.ones(</span><br><span class="line">            (images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>，</span><br><span class="line">             images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>， <span class="number">3</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">elif</span> len(images.shape) == <span class="number">4</span> <span class="keyword">and</span> images.shape[<span class="number">3</span>] == <span class="number">1</span>:</span><br><span class="line">        m = np.ones(</span><br><span class="line">            (images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>，</span><br><span class="line">             images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>， <span class="number">1</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">elif</span> len(images.shape) == <span class="number">3</span>:</span><br><span class="line">        m = np.ones(</span><br><span class="line">            (images.shape[<span class="number">1</span>] * n_plots + n_plots + <span class="number">1</span>，</span><br><span class="line">             images.shape[<span class="number">2</span>] * n_plots + n_plots + <span class="number">1</span>)) * <span class="number">0.5</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">'Could not parse image shape of &#123;&#125;'</span>.format(images.shape))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n_plots):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(n_plots):</span><br><span class="line">            this_filter = i * n_plots + j</span><br><span class="line">            <span class="keyword">if</span> this_filter &lt; images.shape[<span class="number">0</span>]:</span><br><span class="line">                this_img = images[this_filter]</span><br><span class="line">                m[<span class="number">1</span> + i + i * img_h:<span class="number">1</span> + i + (i + <span class="number">1</span>) * img_h，</span><br><span class="line">                  <span class="number">1</span> + j + j * img_w:<span class="number">1</span> + j + (j + <span class="number">1</span>) * img_w] = this_img</span><br><span class="line">    <span class="keyword">return</span> m</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"></span><br><span class="line">saver = tf.train.import_meta_graph(os.path.join(<span class="string">'samples_'</span> + dataset， <span class="string">'dcgan_'</span> + dataset + <span class="string">'-60000.meta'</span>))</span><br><span class="line">saver.restore(sess， tf.train.latest_checkpoint(<span class="string">'samples_'</span> + dataset))</span><br><span class="line">graph = tf.get_default_graph()</span><br><span class="line">g = graph.get_tensor_by_name(<span class="string">'generator/g/Tanh:0'</span>)</span><br><span class="line">noise = graph.get_tensor_by_name(<span class="string">'noise:0'</span>)</span><br><span class="line">is_training = graph.get_tensor_by_name(<span class="string">'is_training:0'</span>)</span><br><span class="line"></span><br><span class="line">n = np.random.uniform(<span class="number">-1.0</span>， <span class="number">1.0</span>， [batch_size， z_dim]).astype(np.float32)</span><br><span class="line">gen_imgs = sess.run(g， feed_dict=&#123;noise: n， is_training: <span class="literal">False</span>&#125;)</span><br><span class="line">gen_imgs = (gen_imgs + <span class="number">1</span>) / <span class="number">2</span></span><br><span class="line">imgs = [img[:， :， :] <span class="keyword">for</span> img <span class="keyword">in</span> gen_imgs]</span><br><span class="line">gen_imgs = montage(imgs)</span><br><span class="line">gen_imgs = np.clip(gen_imgs， <span class="number">0</span>， <span class="number">1</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>， <span class="number">8</span>))</span><br><span class="line">plt.axis(<span class="string">'off'</span>)</span><br><span class="line">plt.imshow(gen_imgs)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h4 id="Inception-v3图片分类"><a href="#Inception-v3图片分类" class="headerlink" title="Inception-v3图片分类"></a>Inception-v3图片分类</h4><p>Inception-v3是由Google提出，用于实现ImageNet大规模视觉识别任务的一种神经网络</p>
<p>Inception-v3反复使用了Inception Block，涉及大量的卷积和池化. 这里我们选择加载pre-trained的Inception-v3模型，来完成一些图片分类任务.</p>
<p>Inception-v3的模型结构:<br><img alt="Inception-v3" src="https://i.loli.net/2019/12/06/o2V9uhQRzCvDOj7.png" width="80%"></p>
<p><strong>训练好的模型包括3个部分:</strong></p>
<ol>
<li>classify_image_graph_def.pb: Inception-v3模型结构和参数</li>
<li>imagenet_2012_challenge_label_map_proto.pbtxt: 从类别编码到类别字符串的对应关系</li>
<li>imagenet_synset_to_human_label_map.txt: 从类别字符串到类别名的对应关系</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 字符串id到name的映射字典</span></span><br><span class="line"><span class="comment"># n00004475	organism， being</span></span><br><span class="line"><span class="comment"># n00005787	benthos</span></span><br><span class="line"><span class="comment"># n00006024	heterotroph</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line">uid_to_human = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> tf.gfile.GFile(<span class="string">'imagenet_synset_to_human_label_map.txt'</span>).readlines():</span><br><span class="line">	items = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">	uid_to_human[items[<span class="number">0</span>]] = items[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># node到字符串id的映射字典</span></span><br><span class="line"><span class="comment"># entry &#123;</span></span><br><span class="line"><span class="comment">#   target_class: 449</span></span><br><span class="line"><span class="comment">#   target_class_string: "n01440764"</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line"><span class="comment"># entry &#123;</span></span><br><span class="line"><span class="comment">#   target_class: 450</span></span><br><span class="line"><span class="comment">#   target_class_string: "n01443537"</span></span><br><span class="line"><span class="comment"># &#125;</span></span><br><span class="line">node_id_to_uid = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> tf.gfile.GFile(<span class="string">'imagenet_2012_challenge_label_map_proto.pbtxt'</span>).readlines():</span><br><span class="line">	<span class="keyword">if</span> line.startswith(<span class="string">'  target_class:'</span>):</span><br><span class="line">		target_class = int(line.split(<span class="string">': '</span>)[<span class="number">1</span>])</span><br><span class="line">	<span class="keyword">if</span> line.startswith(<span class="string">'  target_class_string:'</span>):</span><br><span class="line">		target_class_string = line.split(<span class="string">': '</span>)[<span class="number">1</span>].strip(<span class="string">'\n'</span>).strip(<span class="string">'\"'</span>)</span><br><span class="line">		node_id_to_uid[target_class] = target_class_string</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># node到name的映射字典（很具上述得到的node_id_to_uid和uid_to_human生成）</span></span><br><span class="line">node_id_to_name = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> key， value <span class="keyword">in</span> node_id_to_uid.items():</span><br><span class="line">	node_id_to_name[key] = uid_to_human[value]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_graph</span><span class="params">()</span>:</span></span><br><span class="line">	<span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'classify_image_graph_def.pb'</span>， <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">		graph_def = tf.GraphDef()</span><br><span class="line">		graph_def.ParseFromString(f.read())</span><br><span class="line">		_ = tf.import_graph_def(graph_def， name=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分类图片的函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classify_image</span><span class="params">(image， top_k=<span class="number">1</span>)</span>:</span></span><br><span class="line">	image_data = tf.gfile.FastGFile(image， <span class="string">'rb'</span>).read()</span><br><span class="line"></span><br><span class="line">	create_graph()</span><br><span class="line"></span><br><span class="line">	<span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">		<span class="comment"># 'softmax:0': A tensor containing the normalized prediction across 1000 labels</span></span><br><span class="line">		<span class="comment"># 'pool_3:0': A tensor containing the next-to-last layer containing 2048 float description of the image</span></span><br><span class="line">		<span class="comment"># 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG encoding of the image</span></span><br><span class="line">		softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">'softmax:0'</span>)</span><br><span class="line">		predictions = sess.run(softmax_tensor， feed_dict=&#123;<span class="string">'DecodeJpeg/contents:0'</span>: image_data&#125;)</span><br><span class="line">		predictions = np.squeeze(predictions)</span><br><span class="line"></span><br><span class="line">		top_k = predictions.argsort()[-top_k:]</span><br><span class="line">		<span class="keyword">for</span> node_id <span class="keyword">in</span> top_k:</span><br><span class="line">			human_string = node_id_to_name[node_id]</span><br><span class="line">			score = predictions[node_id]</span><br><span class="line">			print(<span class="string">'%s (score = %.5f)'</span> % (human_string， score))</span><br><span class="line"></span><br><span class="line">classify_image(<span class="string">'./img/test3.png'</span>)</span><br></pre></td></tr></table></figure>

<p><strong>定制分类任务</strong></p>
<p>Inception-v3是针对ImageNet图片分类设计的，因此最后一层全连接层的神经元个数和分类标签的个数相同。如果需要特别定制分类任务的话，只需要使用自己的标注数据，然后替换掉最后一层全连接层即可。</p>
<p>最后一层全连接层的神经元个数等于定制分类任务的标签个数，模型只训练最后一层的参数，其他参数保持不变。这样的话保留了Inception-v3对于图像的理解和抽象能力，同时满足了定制的分类任务，属于迁移学习的一种典型应用场景。</p>

                                        
                </div>
                <footer class="article-footer">
                    
                        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://localhost:4000/2020/01/30/ML-07/&title=《ML系列7：tensorflow项目实战》 — blog&pic=/images/banner.jpg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://localhost:4000/2020/01/30/ML-07/&title=《ML系列7：tensorflow项目实战》 — blog&source=利用tensorflow框架写一些小项目，多多熟悉一下吧~github项目地址" data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2020/01/30/ML-07/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《ML系列7：tensorflow项目实战》 — blog&url=http://localhost:4000/2020/01/30/ML-07/&via=http://localhost:4000" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://localhost:4000/2020/01/30/ML-07/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://localhost:4000/2020/01/30/ML-07/" alt="微信分享二维码">
</div>

<div class="mask"></div>

                            
                                <ul class="article-footer-menu">
                                    
                                            
                                </ul>
                                
                </footer>
    </div>
</article>

    
    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#房价预测线性回归"><span class="post-toc-text">房价预测线性回归</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#手写数字识别"><span class="post-toc-text">手写数字识别</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#验证码识别"><span class="post-toc-text">验证码识别</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#实现词云"><span class="post-toc-text">实现词云</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#自编码器图像去噪AE"><span class="post-toc-text">自编码器图像去噪AE</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#变分自编码器VAE"><span class="post-toc-text">变分自编码器VAE</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#生成式对抗网络GAN"><span class="post-toc-text">生成式对抗网络GAN</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#人脸图片生成DCGAN"><span class="post-toc-text">人脸图片生成DCGAN</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Inception-v3图片分类"><span class="post-toc-text">Inception-v3图片分类</span></a></li></ol>
        </nav>
    </aside>
    
        
<nav id="article-nav">
  
    <a href="/2020/02/16/CV-01/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          CV系列1：计算机视觉基础知识
        
      </span>
    </a>
  
  
    <a href="/2020/01/10/ML-06/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">ML系列6：tensorflow入门-2</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>

            
                
                    
                                                    </section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2020 Yang Pei<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    var mihoConfig = {
        root: "http://localhost:4000",
        animate: "false" ,
        isHome: "false" ,
        share: "true"
    }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/AI/">AI</a><a class="category-link" href="/categories/前端/">前端</a><a class="category-link" href="/categories/计算机/">计算机</a><a class="category-link" href="/categories/语言/">语言</a>
        </div>
        <div id="sidebar-menu-box-tags">
            
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            
        </div>
    </div>
</div>
    <div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
    <script src="/js/search.js"></script>
        <script src="/js/main.js"></script>

            
                <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
                <div id="particles"></div>
                <script src="/js/particles.js"></script>
                    

                        

                                

                                                
                                                                
                                                                    <script src="/js/pop-img.js"></script>
                                                                        <script>
                                                                            $(".article-entry p img").popImg();
                                                                        </script>
                                                                        
  </div>
</body>
</html>