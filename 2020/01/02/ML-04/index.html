<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>ML系列4：tensorflow入门-1 | blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="YP's Blog">
  
  <meta name="description" content="核心内容：以下介绍tensorflow的基础概念和使用(以tensorflow v1.3为例)">
<meta name="keywords" content="web">
<meta property="og:type" content="article">
<meta property="og:title" content="ML系列4：tensorflow入门-1">
<meta property="og:url" content="http://localhost:4000/2020/01/02/ML-04/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="核心内容：以下介绍tensorflow的基础概念和使用(以tensorflow v1.3为例)">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://i.loli.net/2020/04/03/LMWRuPwGUpKTx8B.jpg">
<meta property="og:image" content="https://i.loli.net/2020/04/03/SKXhFBveYbE24wx.jpg">
<meta property="og:image" content="https://i.loli.net/2020/04/03/RJitKcPol4dhOnI.jpg">
<meta property="og:updated_time" content="2020-07-30T07:11:29.422Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="ML系列4：tensorflow入门-1">
<meta name="twitter:description" content="核心内容：以下介绍tensorflow的基础概念和使用(以tensorflow v1.3为例)">
<meta name="twitter:image" content="https://i.loli.net/2020/04/03/LMWRuPwGUpKTx8B.jpg">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>
</html>
<body>
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">YP&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>主页</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>全部</span>
                    </a>
                    
                    <a  href="/categories/AI/">
                        <i class="fa fa-AI"></i>
                        <span>AI</span>
                    </a>
                    
                    <a  href="/categories/前端/">
                        <i class="fa fa-前端"></i>
                        <span>前端</span>
                    </a>
                    
                    <a  href="/categories/计算机/">
                        <i class="fa fa-计算机"></i>
                        <span>计算机</span>
                    </a>
                    
                    <a  href="/categories/语言/">
                        <i class="fa fa-语言"></i>
                        <span>语言</span>
                    </a>
                    
                    <a  href="/categories/专题/">
                        <i class="fa fa-专题"></i>
                        <span>专题</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        YP&#39;s Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        一个专注前端智能化开发的技术博客
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="Blog" target="_blank" href="https://iloveyou11.github.io/">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="https://github.com/iloveyou11">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-ML-04" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="post-title" itemprop="name">
      ML系列4：tensorflow入门-1
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/AI/">AI</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2020-01-02
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

                    
            </header>
            
                <div class="article-entry post-content" itemprop="articleBody">
                    
                            
                                
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#一、tensorflow基础"><span class="toc-text">一、tensorflow基础</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#基础语法"><span class="toc-text">基础语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tensorboard"><span class="toc-text">tensorboard</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#二、tensorflow举例"><span class="toc-text">二、tensorflow举例</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#变量、常量"><span class="toc-text">变量、常量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#线性回归"><span class="toc-text">线性回归</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#梯度下降"><span class="toc-text">梯度下降</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#聚类"><span class="toc-text">聚类</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#卷积神经网络CNN"><span class="toc-text">卷积神经网络CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#保存与读取"><span class="toc-text">保存与读取</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#三、tensorflow实战"><span class="toc-text">三、tensorflow实战</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#房价预测模型（线性回归）"><span class="toc-text">房价预测模型（线性回归）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#手写数字识别"><span class="toc-text">手写数字识别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#验证码识别"><span class="toc-text">验证码识别</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#人脸识别"><span class="toc-text">人脸识别</span></a></li></ol></li></ol>
    </div>
    
                                    <p>核心内容：以下介绍tensorflow的基础概念和使用(以tensorflow v1.3为例)</p>
<a id="more"></a>

<p><a href="https://iloveyou11.github.io/2019/12/04/ML-01/" target="_blank" rel="noopener">ML系列1：AI学习资源与知识点</a><br><a href="https://iloveyou11.github.io/2019/12/10/ML-02/" target="_blank" rel="noopener">ML系列2：机器学习必会算法</a><br><a href="https://iloveyou11.github.io/2019/12/29/ML-04/" target="_blank" rel="noopener">ML系列3：深度学习中的问题解答</a><br><a href="https://iloveyou11.github.io/2020/01/02/ML-05/" target="_blank" rel="noopener">ML系列4：tensorflow入门-1</a><br><a href="https://iloveyou11.github.io/2020/01/10/ML-06/" target="_blank" rel="noopener">ML系列5：tensorflow入门-2</a><br><a href="https://iloveyou11.github.io/2020/01/30/ML-07/" target="_blank" rel="noopener">ML系列6：tensorflow项目实战</a></p>
<h3 id="一、tensorflow基础"><a href="#一、tensorflow基础" class="headerlink" title="一、tensorflow基础"></a>一、tensorflow基础</h3><h4 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h4><p>计算单元有常量<code>c = tf.constant(2)</code>，变量<code>v = tf.Variable(2)</code>，占位符<code>p = tf.placeholder(tf.float32)</code>。常见四则运算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">add = tf.add(a, b)</span><br><span class="line">sub = tf.subtract(a, b)</span><br><span class="line">mul = tf.multiply(a, b)</span><br><span class="line">div = tf.divide(a, b)</span><br></pre></td></tr></table></figure>

<p><strong>session</strong><br>有两种方式：</p>
<ol>
<li>sess = tf.Session()直接创建sess，但记得要sess.close()，避免内存泄漏</li>
<li>使用with tf.Session() as sess，利用with关闭会话，意外关闭也会释放资源</li>
</ol>
<p>注意事项：打印值一定要用sess.run()，否则无法正确打印值</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">const1 = tf.constant([[<span class="number">2</span>, <span class="number">3</span>], [<span class="number">1</span>, <span class="number">1</span>]])</span><br><span class="line">const2 = tf.constant([[<span class="number">4</span>, <span class="number">5</span>], [<span class="number">3</span>, <span class="number">4</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># matmul 矩阵乘法</span></span><br><span class="line">mul = tf.matmul(const1, const2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> const1.graph <span class="keyword">is</span> tf.compat.v1.get_default_graph():</span><br><span class="line">    print(<span class="string">'const1所在的图是当前上下文默认的图'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一种方法 sess.close()关闭会话</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">ret = sess.run(mul)</span><br><span class="line">print(ret)</span><br><span class="line">sess.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方法 利用with关闭会话，意外关闭也会释放资源</span></span><br><span class="line"><span class="comment"># with tf.Session() as sess:</span></span><br><span class="line"><span class="comment">#     ret2 = sess.run(mul)</span></span><br><span class="line"><span class="comment">#     print(ret2)</span></span><br></pre></td></tr></table></figure>

<p><strong>下面总结下计算过程：</strong></p>
<ul>
<li>创建数据：可以创建常量、变量和占位符。</li>
<li>构建图：通过前面的数据构建一张图。</li>
<li>初始化：把变量初始化。</li>
<li>计算：必须通过开启一个 Session 来计算图</li>
</ul>
<h4 id="tensorboard"><a href="#tensorboard" class="headerlink" title="tensorboard"></a>tensorboard</h4><img width="60%" src="https://i.loli.net/2020/04/03/LMWRuPwGUpKTx8B.jpg" alt="tensorboard">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">w = tf.compat.v1.Variable(<span class="number">2.0</span>, dtype=tf.float32, name=<span class="string">"weight"</span>)</span><br><span class="line">b = tf.compat.v1.Variable(<span class="number">1.0</span>, dtype=tf.float32, name=<span class="string">"bias"</span>)</span><br><span class="line">x = tf.placeholder(dtype=tf.float32, name=<span class="string">"input"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.name_scope(<span class="string">'output'</span>):</span><br><span class="line">    y = w*x+b</span><br><span class="line"></span><br><span class="line">path = <span class="string">'./log'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建用于初始化变量的操作</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    writer = tf.compat.v1.summary.FileWriter(path, sess.graph)</span><br><span class="line">    result = sess.run(y, &#123;x: <span class="number">3.0</span>&#125;)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>

<p>命令：<code>tensorboard --logdir=log</code>,访问<a href="http://localhost:6006/即可。">http://localhost:6006/即可。</a></p>
<h3 id="二、tensorflow举例"><a href="#二、tensorflow举例" class="headerlink" title="二、tensorflow举例"></a>二、tensorflow举例</h3><h4 id="变量、常量"><a href="#变量、常量" class="headerlink" title="变量、常量"></a>变量、常量</h4><p><strong>constant、Variable、placeholder、Parse</strong><br>hello world</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">hw = tf.constant(<span class="string">'hello world!'</span>)</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(hw))</span><br><span class="line"></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>

<p>变量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">state = tf.Variable(<span class="number">0</span>, name=<span class="string">'counter'</span>)</span><br><span class="line">one = tf.constant(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">value = tf.add(state, one)</span><br><span class="line">update = tf.assign(state, value)</span><br><span class="line"></span><br><span class="line">init = tf.compat.v1.global_variables_initializer()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        sess.run(update)</span><br><span class="line">        print(sess.run(state))</span><br></pre></td></tr></table></figure>

<p>placeholder</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line">output = tf.multiply(input1, input2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(output, feed_dict=&#123;input1: [<span class="number">7.</span>], input2: [<span class="number">2.</span>]&#125;))</span><br></pre></td></tr></table></figure>

<h4 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>).astype(np.float32)</span><br><span class="line">y_data = x_data*<span class="number">0.1</span>+<span class="number">0.3</span></span><br><span class="line"></span><br><span class="line">Weigths = tf.Variable(tf.random.uniform([<span class="number">1</span>], <span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">biases = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line"></span><br><span class="line">y = Weigths*x_data+biases</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-y_data))</span><br><span class="line">optimizer = tf.compat.v1.train.GradientDescentOptimizer(<span class="number">0.5</span>)  <span class="comment"># 学习率</span></span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.compat.v1.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话，激活init</span></span><br><span class="line">sess = tf.compat.v1.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">200</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        print(step, sess.run(Weigths), sess.run(biases))</span><br><span class="line"></span><br><span class="line"><span class="comment"># result：</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 0 [0.85750043] [-0.13565287]</span></span><br><span class="line"><span class="comment"># 20 [0.319864] [0.1856415]</span></span><br><span class="line"><span class="comment"># 40 [0.1624105] [0.26753825]</span></span><br><span class="line"><span class="comment"># 60 [0.11771582] [0.29078543]</span></span><br><span class="line"><span class="comment"># 80 [0.1050288] [0.29738435]</span></span><br><span class="line"><span class="comment"># 100 [0.10142749] [0.29925755]</span></span><br><span class="line"><span class="comment"># 120 [0.10040522] [0.29978925]</span></span><br><span class="line"><span class="comment"># 140 [0.10011502] [0.2999402]</span></span><br><span class="line"><span class="comment"># 160 [0.10003265] [0.29998302]</span></span><br><span class="line"><span class="comment"># 180 [0.10000926] [0.29999518]</span></span><br></pre></td></tr></table></figure>

<p>激活函数模拟</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x = np.linspace(<span class="number">-10</span>, <span class="number">10</span>, <span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 常见激活函数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(inputs)</span>:</span></span><br><span class="line">    y = [<span class="number">1</span>/float(<span class="number">1</span>+np.exp(-x)) <span class="keyword">for</span> x <span class="keyword">in</span> inputs]</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(inputs)</span>:</span></span><br><span class="line">    y = [x*(x &gt; <span class="number">0</span>) <span class="keyword">for</span> x <span class="keyword">in</span> inputs]</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tanh</span><span class="params">(inputs)</span>:</span></span><br><span class="line">    y = [(np.exp(x)-np.exp(-x))/float(np.exp(x)+np.exp(-x)) <span class="keyword">for</span> x <span class="keyword">in</span> inputs]</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">softplus</span><span class="params">(inputs)</span>:</span></span><br><span class="line">    y = [np.log(<span class="number">1</span>+np.exp(x)) <span class="keyword">for</span> x <span class="keyword">in</span> inputs]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 经过激活函数处理后的y</span></span><br><span class="line">y_sigmoid = tf.nn.sigmoid(x)</span><br><span class="line">y_relu = tf.nn.relu(x)</span><br><span class="line">y_tanh = tf.nn.tanh(x)</span><br><span class="line">y_softplus = tf.nn.softplus(x)</span><br><span class="line"></span><br><span class="line">sess = tf.Session()</span><br><span class="line">y_sigmoid, y_relu, y_tanh, y_softplus = sess.run(</span><br><span class="line">    [y_sigmoid, y_relu, y_tanh, y_softplus])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建图像</span></span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.plot(x, y_sigmoid, c=<span class="string">'red'</span>, label=<span class="string">'sigmoid'</span>)</span><br><span class="line">plt.ylim(<span class="number">-0.2</span>, <span class="number">1.2</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(x, y_relu, c=<span class="string">'red'</span>, label=<span class="string">'relu'</span>)</span><br><span class="line">plt.ylim(<span class="number">-1</span>, <span class="number">6</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(x, y_tanh, c=<span class="string">'red'</span>, label=<span class="string">'tanh'</span>)</span><br><span class="line">plt.ylim(<span class="number">-1.3</span>, <span class="number">1.3</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(x, y_softplus, c=<span class="string">'red'</span>, label=<span class="string">'softplus'</span>)</span><br><span class="line">plt.ylim(<span class="number">-1</span>, <span class="number">6</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>

<h4 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造数据</span></span><br><span class="line">num = <span class="number">100</span></span><br><span class="line">vectors = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正态随机分布函数生成100个点</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(num):</span><br><span class="line">    x1 = np.random.normal(<span class="number">0</span>, <span class="number">0.6</span>)</span><br><span class="line">    y1 = <span class="number">0.1</span>*x1+<span class="number">0.2</span>+np.random.normal(<span class="number">0</span>, <span class="number">0.04</span>)</span><br><span class="line">    vectors.append([x1, y1])</span><br><span class="line"></span><br><span class="line">x_data = [v[<span class="number">0</span>] <span class="keyword">for</span> v <span class="keyword">in</span> vectors]</span><br><span class="line">y_data = [v[<span class="number">1</span>] <span class="keyword">for</span> v <span class="keyword">in</span> vectors]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 展示所有随机点</span></span><br><span class="line"><span class="comment"># plt.plot(x_data, y_data, 'r*')</span></span><br><span class="line"><span class="comment"># plt.title = 'linear regression using GD'</span></span><br><span class="line"><span class="comment"># plt.legend()</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建线性回归模型</span></span><br><span class="line">w = tf.Variable(tf.random_uniform([<span class="number">1</span>], <span class="number">-1</span>, <span class="number">1</span>))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">1</span>]))</span><br><span class="line">y = w*x_data+b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-y_data))</span><br><span class="line"><span class="comment"># 梯度下降优化器来优化loss function</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)  <span class="comment"># 学习率0.5</span></span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话，并初始化变量</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">init = tf.compat.v1.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练20步</span></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">    sess.run(train)</span><br><span class="line">    <span class="comment"># 打印每一步损失，w、b</span></span><br><span class="line">    print(<span class="string">"step:%d,loss:%f,weight:%f,bias:%f"</span> %</span><br><span class="line">          (step, sess.run(loss), sess.run(w), sess.run(b)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制最佳拟合曲线</span></span><br><span class="line">plt.plot(x_data, y_data, <span class="string">'r*'</span>, label=<span class="string">'original line'</span>)</span><br><span class="line">plt.title = <span class="string">'linear regression using GD'</span></span><br><span class="line">plt.plot(x_data, sess.run(w)*x_data+sess.run(b), label=<span class="string">'fitted line'</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.xlabel(<span class="string">'x'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'y'</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>

<h4 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'mnist_data'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size, out_size]), name=<span class="string">'W'</span>)</span><br><span class="line">    baises = tf.Variable(tf.zeros([<span class="number">1</span>, out_size])+<span class="number">0.1</span>, name=<span class="string">'b'</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights)+baises</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_accuracy</span><span class="params">(v_xs, v_ys)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> prediction</span><br><span class="line">    y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs&#125;)</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y_pre, <span class="number">1</span>), tf.argmax(v_ys, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入</span></span><br><span class="line">xs = tf.compat.v1.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>], name=<span class="string">'x_input'</span>)</span><br><span class="line">ys = tf.compat.v1.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">'y_input'</span>)</span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">prediction = add_layer(xs, <span class="number">784</span>, <span class="number">10</span>, activation_function=tf.nn.softmax)</span><br><span class="line"><span class="comment"># 交叉熵损失</span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys *</span><br><span class="line">                                              tf.log(prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.5</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会话</span></span><br><span class="line">init = tf.compat.v1.global_variables_initializer()</span><br><span class="line">sess = tf.compat.v1.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># 100个100个学习</span></span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;</span><br><span class="line">        xs: batch_xs,</span><br><span class="line">        ys: batch_ys</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(compute_accuracy(mnist.test.images, mnist.test.labels))</span><br></pre></td></tr></table></figure>

<h4 id="卷积神经网络CNN"><a href="#卷积神经网络CNN" class="headerlink" title="卷积神经网络CNN"></a>卷积神经网络CNN</h4><p><strong>示例1： 输入1个神经元，隐藏层10个神经元，输出1个神经元，并且动态模拟曲线生成过程</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size, out_size]))</span><br><span class="line">    baises = tf.Variable(tf.zeros([<span class="number">1</span>, out_size])+<span class="number">0.1</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights)+baises</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构造数据</span></span><br><span class="line">x_data = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">300</span>)[:, np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.05</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data)<span class="number">-0.5</span>+noise</span><br><span class="line"></span><br><span class="line">xs = tf.compat.v1.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">ys = tf.compat.v1.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建神经网络</span></span><br><span class="line">layer1 = add_layer(xs, <span class="number">1</span>, <span class="number">10</span>, activation_function=tf.nn.relu)</span><br><span class="line">prediction = add_layer(layer1, <span class="number">10</span>, <span class="number">1</span>, activation_function=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数</span></span><br><span class="line">loss = tf.reduce_mean(tf.reduce_sum(</span><br><span class="line">    tf.square(ys-prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">init = tf.compat.v1.global_variables_initializer()</span><br><span class="line">sess = tf.compat.v1.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始数据散点分布图</span></span><br><span class="line">fig = plt.figure()</span><br><span class="line">ax = fig.add_subplot(<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">ax.scatter(x_data, y_data)</span><br><span class="line">plt.ion()  <span class="comment"># 该程序plt.show()后不暂停，继续往下走</span></span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    sess.run(train, feed_dict=&#123;xs: x_data, ys: y_data&#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># print(sess.run(loss, feed_dict=&#123;xs: x_data, ys: y_data&#125;))</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 先抹除这条线</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            ax.lines.remove(lines[<span class="number">0</span>])</span><br><span class="line">        <span class="keyword">except</span> Exception:</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">        prediction_value = sess.run(prediction, feed_dict=&#123;</span><br><span class="line">                                    xs: x_data, ys: y_data&#125;)</span><br><span class="line">        lines = ax.plot(x_data, prediction_value, <span class="string">'r-'</span>, lw=<span class="number">5</span>)</span><br><span class="line">        plt.pause(<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>

<p><strong>示例2： 整个流程： 卷积——池化——卷积——池化——全连接——全连接</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 卷积神经网络</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'mnist_data'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">add_layer</span><span class="params">(inputs, in_size, out_size, activation_function=None)</span>:</span></span><br><span class="line">    Weights = tf.Variable(tf.random.normal([in_size, out_size]), name=<span class="string">'W'</span>)</span><br><span class="line">    baises = tf.Variable(tf.zeros([<span class="number">1</span>, out_size])+<span class="number">0.1</span>, name=<span class="string">'b'</span>)</span><br><span class="line">    Wx_plus_b = tf.matmul(inputs, Weights)+baises</span><br><span class="line">    <span class="keyword">if</span> activation_function <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        outputs = Wx_plus_b</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        outputs = activation_function(Wx_plus_b)</span><br><span class="line">    <span class="keyword">return</span> outputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_accuracy</span><span class="params">(v_xs, v_ys)</span>:</span></span><br><span class="line">    <span class="keyword">global</span> prediction</span><br><span class="line">    y_pre = sess.run(prediction, feed_dict=&#123;xs: v_xs&#125;)</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y_pre, <span class="number">1</span>), tf.argmax(v_ys, <span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    result = sess.run(accuracy, feed_dict=&#123;xs: v_xs, ys: v_ys&#125;)</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variables</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variables</span><span class="params">(shape)</span>:</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 卷积层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, W)</span>:</span></span><br><span class="line">    <span class="comment"># strides格式 [1,x_movement,y_movement,1]</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 池化层</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">'SAME'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入</span></span><br><span class="line">xs = tf.compat.v1.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>], name=<span class="string">'x_input'</span>)</span><br><span class="line">ys = tf.compat.v1.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>], name=<span class="string">'y_input'</span>)</span><br><span class="line">keep_prob = tf.compat.v1.placeholder(tf.float32)</span><br><span class="line">x_image = tf.reshape(xs, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 整个流程：</span></span><br><span class="line"><span class="comment"># 卷积——池化——卷积——池化——全连接——全连接</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># conv1 layer</span></span><br><span class="line">W_conv1 = weight_variables([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])  <span class="comment"># 5*5 in_size=1 out_size=32</span></span><br><span class="line">b_conv1 = bias_variables([<span class="number">32</span>])</span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1)+b_conv1)  <span class="comment"># output 28*28*32</span></span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)  <span class="comment"># output 14*14*32</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># conv2 layer</span></span><br><span class="line">W_conv2 = weight_variables([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])  <span class="comment"># 5*5 in_size=32 out_size=64</span></span><br><span class="line">b_conv2 = bias_variables([<span class="number">32</span>])</span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2)+b_conv2)  <span class="comment"># output 14*14*64</span></span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)  <span class="comment"># output 7*7*64</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># func1 layer</span></span><br><span class="line">W_f1 = weight_variables([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>, <span class="number">1024</span>])</span><br><span class="line">b_f1 = bias_variables([<span class="number">1024</span>])</span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">h_f1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_f1)+b_f1)</span><br><span class="line">h_f1_drop = tf.nn.dropout(h_f1, keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># func2 layer</span></span><br><span class="line">W_f2 = weight_variables([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_f2 = bias_variables([<span class="number">10</span>])</span><br><span class="line">prediction = tf.nn.softmax(tf.matmul(h_f1_drop, W_f2)+b_f2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出</span></span><br><span class="line">prediction = add_layer(xs, <span class="number">784</span>, <span class="number">10</span>, activation_function=tf.nn.softmax)</span><br><span class="line"><span class="comment"># 交叉熵损失</span></span><br><span class="line">cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys *</span><br><span class="line">                                              tf.log(prediction), reduction_indices=[<span class="number">1</span>]))</span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 会话</span></span><br><span class="line">init = tf.compat.v1.global_variables_initializer()</span><br><span class="line">sess = tf.compat.v1.Session()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    <span class="comment"># 100个100个学习</span></span><br><span class="line">    batch_xs, batch_ys = mnist.train.next_batch(<span class="number">100</span>)</span><br><span class="line">    sess.run(train_step, feed_dict=&#123;</span><br><span class="line">        xs: batch_xs,</span><br><span class="line">        ys: batch_ys</span><br><span class="line">    &#125;)</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        print(compute_accuracy(mnist.test.images, mnist.test.labels))</span><br></pre></td></tr></table></figure>

<p><strong>示例3： 完整的CNN示例，包括输出层、池化层、卷积层、dropout层、全连接层等</strong></p>
<img width="60%" src="https://i.loli.net/2020/04/03/SKXhFBveYbE24wx.jpg" alt="CNN示例3">

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入手写数字库(55000*28*28)</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># one_hot 独热吗的编码形式</span></span><br><span class="line"><span class="comment"># 0：100000000</span></span><br><span class="line"><span class="comment"># 1：010000000</span></span><br><span class="line"><span class="comment"># 2：001000000</span></span><br><span class="line"><span class="comment"># ……</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">'mnist_data'</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># None表示张量的第一个维度</span></span><br><span class="line">input_x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>])/<span class="number">255</span></span><br><span class="line">output_y = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line">input_x_images = tf.reshape(input_x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从测试数据集中选取3000个图片和标签</span></span><br><span class="line">test_x = mnist.test.images[:<span class="number">3000</span>]</span><br><span class="line">test_y = mnist.test.labels[:<span class="number">3000</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建卷积神经网络</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一层卷积，输入28*28*1，卷积5*5*32，输出28*28*32</span></span><br><span class="line">conv1 = tf.keras.layers.Conv2D(</span><br><span class="line">    inputs=input_x_images,  <span class="comment"># 输入</span></span><br><span class="line">    filters=<span class="number">32</span>,  <span class="comment"># 过滤器，输出深度</span></span><br><span class="line">    kernel_size=<span class="number">5</span>,  <span class="comment"># 卷积大小</span></span><br><span class="line">    strides=<span class="number">1</span>,  <span class="comment"># 步长</span></span><br><span class="line">    padding=<span class="string">'same'</span>,  <span class="comment"># padding,same表示输出大小不变，因此需要补两圈,</span></span><br><span class="line">    activation=tf.nn.relu</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一层池化（亚采样），输入28*28*32，输出14*14*32</span></span><br><span class="line">pool1 = tf.keras.layers.MaxPooling2D(</span><br><span class="line">    inputs=conv1,  <span class="comment"># 输入</span></span><br><span class="line">    pool_size=[<span class="number">2</span>, <span class="number">2</span>],  <span class="comment"># 过滤器大小</span></span><br><span class="line">    strides=<span class="number">2</span>,  <span class="comment"># 步长</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层卷积，输入14*14*32，卷积5*5*64，输出14*14*64</span></span><br><span class="line">conv2 = tf.keras.layers.Conv2D(</span><br><span class="line">    inputs=pool1,  <span class="comment"># 输入</span></span><br><span class="line">    filters=<span class="number">64</span>,  <span class="comment"># 过滤器，输出深度</span></span><br><span class="line">    kernel_size=<span class="number">5</span>,  <span class="comment"># 卷积大小</span></span><br><span class="line">    strides=<span class="number">1</span>,  <span class="comment"># 步长</span></span><br><span class="line">    padding=<span class="string">'same'</span>,  <span class="comment"># padding,same表示输出大小不变，因此需要补两圈,</span></span><br><span class="line">    activation=tf.nn.relu</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二层池化，输入14*14*64，输出7*7*64</span></span><br><span class="line">pool2 = tf.keras.layers.MaxPooling2D(</span><br><span class="line">    inputs=conv2,  <span class="comment"># 输入</span></span><br><span class="line">    pool_size=[<span class="number">2</span>, <span class="number">2</span>],  <span class="comment"># 过滤器大小</span></span><br><span class="line">    strides=<span class="number">2</span>,  <span class="comment"># 步长</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 平坦化</span></span><br><span class="line">flat = tf.reshape(pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line"><span class="comment"># 全连接层</span></span><br><span class="line">dense = tf.keras.layers.Dense(</span><br><span class="line">    inputs=flat,</span><br><span class="line">    units=<span class="number">1024</span>,</span><br><span class="line">    activation=tf.nn.relu</span><br><span class="line">)</span><br><span class="line"><span class="comment"># dropouts</span></span><br><span class="line">dropout = tf.keras.layers.Dropout(inputs=dense, rate=<span class="number">0.5</span>, training=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 10个神经元全连接层，不用激活函数做非线性化，输出1*1*10</span></span><br><span class="line">logits = tf.keras.layers.Dense(inputs=dropout, units=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算误差(计算交叉熵，再用softmax计算概率)</span></span><br><span class="line">loss = tf.losses.softmax_cross_entropy(onehot_labels=output_y, logits=logits)</span><br><span class="line"><span class="comment"># 用Adam优化器最小化误差，学习率0.001</span></span><br><span class="line">train_op = tf.compat.v1.train.AdamOptimizer(learning_rate=<span class="number">0.001</span>).minimize(loss)</span><br><span class="line"><span class="comment"># 精度，计算预测值和实际标签的匹配程度</span></span><br><span class="line">accuracy = tf.compat.v1.metrics.accuracy(</span><br><span class="line">    labels=tf.argmax(output_y, axis=<span class="number">1</span>),</span><br><span class="line">    predictions=tf.argmax(logits, axis=<span class="number">1</span>)[<span class="number">1</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建会话</span></span><br><span class="line">sess = tf.compat.v1.Session()</span><br><span class="line"><span class="comment"># 初始化变量：全局和局部</span></span><br><span class="line">init = tf.group(tf.compat.v1.global_variables_initializer,</span><br><span class="line">                tf.compat.v1.local_variables_initializer)</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">20000</span>):</span><br><span class="line">  <span class="comment"># 从train训练集中取下一50个样本</span></span><br><span class="line">    batch = mnist.train.next_batch(<span class="number">50</span>)</span><br><span class="line">    train_loss, train_op = sess.run([loss, train_op], &#123;</span><br><span class="line">        input_x: batch[<span class="number">0</span>],</span><br><span class="line">        output_y: batch[<span class="number">1</span>]&#125;</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        test_accuracy = sess.run(accuracy, &#123;</span><br><span class="line">            input_x: test_x,</span><br><span class="line">            output_y: test_y</span><br><span class="line">        &#125;)</span><br><span class="line">        print(<span class="string">'step:%d,loss=%.4f,test_accuracy:%.2f'</span> %</span><br><span class="line">              (i, train_loss, test_accuracy))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试：打印20个预测值和真实值比对</span></span><br><span class="line">test_output = sess.run(logits, &#123;input_x: test_x[:<span class="number">20</span>]&#125;)</span><br><span class="line">predict_y = np.argmax(test_output, <span class="number">1</span>)</span><br><span class="line">print(predict_y, <span class="string">'predict_y'</span>)</span><br><span class="line">print(np.argmax(test_y[:<span class="number">20</span>], <span class="number">1</span>), <span class="string">'real number'</span>)</span><br></pre></td></tr></table></figure>

<h4 id="保存与读取"><a href="#保存与读取" class="headerlink" title="保存与读取"></a>保存与读取</h4><p>tensorflow目前只能保存Variable，不能保存整个神经框架，需要重新定义一下框架，再把Variable放进来重新学习 </p>
<img width="60%" src="https://i.loli.net/2020/04/03/RJitKcPol4dhOnI.jpg" alt="CNN示例3">

<p><strong>存入文件：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># save to file</span></span><br><span class="line"><span class="comment"># remember to define the same dtype and shape where restore</span></span><br><span class="line">W = tf.Variable([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]], dtype=tf.float32)</span><br><span class="line">b = tf.Variable([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]], dtype=tf.float32)</span><br><span class="line"></span><br><span class="line">init = tf.compat.v1.global_variables_initializer()</span><br><span class="line"></span><br><span class="line">saver = tf.compat.v1.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.compat.v1.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="comment"># 这里tensorflow推荐使用ckpt后缀名</span></span><br><span class="line">    saver_path = saver.save(sess, <span class="string">'net/save_net.ckpt'</span>)</span><br></pre></td></tr></table></figure>

<p><strong>读取文件：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># restore variables</span></span><br><span class="line"><span class="comment"># redefine same dtype and shape for your variables</span></span><br><span class="line"><span class="comment"># define empty framework</span></span><br><span class="line"></span><br><span class="line">W = tf.Variable(np.arange(<span class="number">6</span>).reshape((<span class="number">2</span>, <span class="number">3</span>)), dtype=tf.float32)</span><br><span class="line">b = tf.Variable(np.arange(<span class="number">3</span>).reshape((<span class="number">1</span>, <span class="number">3</span>)), dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># not need init step</span></span><br><span class="line"></span><br><span class="line">saver = tf.compat.v1.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.compat.v1.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    saver.restore(sess, <span class="string">'net/save_net.ckpt'</span>)</span><br><span class="line">    print(<span class="string">'weight:'</span>, sess.run(W))</span><br><span class="line">    print(<span class="string">'bias:'</span>, sess.run(b))</span><br></pre></td></tr></table></figure>

<h3 id="三、tensorflow实战"><a href="#三、tensorflow实战" class="headerlink" title="三、tensorflow实战"></a>三、tensorflow实战</h3><p>必须掌握的前置知识：</p>
<ul>
<li>线性回归</li>
<li>逻辑回归</li>
<li>决策树</li>
<li>随机森林</li>
<li>最近邻算法（KNN）</li>
<li>朴素贝叶斯</li>
<li>支持向量机（SVM）</li>
<li>感知机</li>
<li>深度神经网络<h4 id="房价预测模型（线性回归）"><a href="#房价预测模型（线性回归）" class="headerlink" title="房价预测模型（线性回归）"></a>房价预测模型（线性回归）</h4>掌握要点：</li>
<li>数据预处理（特征归一化）</li>
<li>tensorflow训练模型的工作流</li>
<li>数据可视化库matplotlib &amp; seaborn &amp; mplot3d<h4 id="手写数字识别"><a href="#手写数字识别" class="headerlink" title="手写数字识别"></a>手写数字识别</h4><h4 id="验证码识别"><a href="#验证码识别" class="headerlink" title="验证码识别"></a>验证码识别</h4><h4 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h4></li>
</ul>

                                        
                </div>
                <footer class="article-footer">
                    
                        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://localhost:4000/2020/01/02/ML-04/&title=《ML系列4：tensorflow入门-1》 — blog&pic=/images/banner.jpg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://localhost:4000/2020/01/02/ML-04/&title=《ML系列4：tensorflow入门-1》 — blog&source=核心内容：以下介绍tensorflow的基础概念和使用(以tensorflow v1.3为例)" data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2020/01/02/ML-04/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《ML系列4：tensorflow入门-1》 — blog&url=http://localhost:4000/2020/01/02/ML-04/&via=http://localhost:4000" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://localhost:4000/2020/01/02/ML-04/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://localhost:4000/2020/01/02/ML-04/" alt="微信分享二维码">
</div>

<div class="mask"></div>

                            
                                <ul class="article-footer-menu">
                                    
                                            
                                </ul>
                                
                </footer>
    </div>
</article>

    
    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#一、tensorflow基础"><span class="post-toc-text">一、tensorflow基础</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#基础语法"><span class="post-toc-text">基础语法</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#tensorboard"><span class="post-toc-text">tensorboard</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#二、tensorflow举例"><span class="post-toc-text">二、tensorflow举例</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#变量、常量"><span class="post-toc-text">变量、常量</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#线性回归"><span class="post-toc-text">线性回归</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#梯度下降"><span class="post-toc-text">梯度下降</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#聚类"><span class="post-toc-text">聚类</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#卷积神经网络CNN"><span class="post-toc-text">卷积神经网络CNN</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#保存与读取"><span class="post-toc-text">保存与读取</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#三、tensorflow实战"><span class="post-toc-text">三、tensorflow实战</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#房价预测模型（线性回归）"><span class="post-toc-text">房价预测模型（线性回归）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#手写数字识别"><span class="post-toc-text">手写数字识别</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#验证码识别"><span class="post-toc-text">验证码识别</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#人脸识别"><span class="post-toc-text">人脸识别</span></a></li></ol></li></ol>
        </nav>
    </aside>
    
        
<nav id="article-nav">
  
    <a href="/2020/01/10/ML-05/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          ML系列5：tensorflow入门-2
        
      </span>
    </a>
  
  
    <a href="/2019/12/29/ML-03/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">ML系列3：深度学习中的问题解答</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>

            
                
                    
                                                    </section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2020 Yang Pei<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    var mihoConfig = {
        root: "http://localhost:4000",
        animate: "false" ,
        isHome: "false" ,
        share: "true"
    }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/AI/">AI</a><a class="category-link" href="/categories/专题/">专题</a><a class="category-link" href="/categories/前端/">前端</a><a class="category-link" href="/categories/计算机/">计算机</a><a class="category-link" href="/categories/语言/">语言</a>
        </div>
        <div id="sidebar-menu-box-tags">
            
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>ß

<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>主页</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>全部</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/AI/">
                    <i class="fa fa-AI"></i><span>AI</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/前端/">
                    <i class="fa fa-前端"></i><span>前端</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/计算机/">
                    <i class="fa fa-计算机"></i><span>计算机</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/语言/">
                    <i class="fa fa-语言"></i><span>语言</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/专题/">
                    <i class="fa fa-专题"></i><span>专题</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            
        </div>
    </div>
</div>
    <div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
    <script src="/js/search.js"></script>
        <script src="/js/main.js"></script>

            
                <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
                <div id="particles"></div>
                <script src="/js/particles.js"></script>
                    

                        

                                

                                                
                                                                
                                                                    <script src="/js/pop-img.js"></script>
                                                                        <script>
                                                                            $(".article-entry p img").popImg();
                                                                        </script>
                                                                        
  </div>
</body>
</html>