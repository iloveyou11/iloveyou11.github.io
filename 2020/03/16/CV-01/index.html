<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>CV系列1：卷积神经网络的演变 | blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="YP's Blog">
  
  <meta name="description" content="本文主要介绍深度学习种卷积神经网络的发展历史，以及典型的卷积神经网络。">
<meta name="keywords" content="web">
<meta property="og:type" content="article">
<meta property="og:title" content="CV系列1：卷积神经网络的演变">
<meta property="og:url" content="http://localhost:4000/2020/03/16/CV-01/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="本文主要介绍深度学习种卷积神经网络的发展历史，以及典型的卷积神经网络。">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://i.loli.net/2020/04/06/HaqK5wDLAsPTEzC.jpg">
<meta property="og:image" content="https://i.loli.net/2020/04/06/isyzG24B3f5HYeA.jpg">
<meta property="og:image" content="https://i.loli.net/2020/04/06/4jDPpI5Ub2o7Tne.jpg">
<meta property="og:image" content="https://i.loli.net/2020/04/06/ybJ71TREC8AloNU.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/PDkzl9BehuEnZ54.png">
<meta property="og:image" content="https://i.loli.net/2020/03/23/EP24GoBwSs8jNlx.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/A5ougkDGOqzniVy.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/EB9vHFjotcremDW.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/tjsBuCpIH5xzlea.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/Qf9OoUcmvXJWTxj.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/wbM3USkNtuOjHqm.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/hKbTYGAp715dlNJ.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/eSWywOImAvVGDMn.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/mqFH2SLMc1J7XZg.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/GXiz8tcIZmHfRaM.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/YzK3WBeIwZROaVy.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/8MEfPrFHmaWiUO9.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/Vg3MxciEzeQCDqU.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/jpGdJlD7NWFH5o8.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/tisQ4Tep2mVohjI.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/mU91kI2sqeA3hga.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/BKoIu2OG649eLWZ.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/2l54TnfwRahcM67.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/1DHYvwhOuKnNcaC.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/cI3ALbZ9adwymjU.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/cyR4uFf5DiOr6Pj.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/aYZt7g2bEomSreN.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/TzXD2xKCI3Fpwqv.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/INtbYW4eXKJcuAr.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/FagjoMOD3JS78VU.jpg">
<meta property="og:image" content="https://i.loli.net/2020/03/23/5rClbMTnG3XhHq9.jpg">
<meta property="og:updated_time" content="2020-07-07T09:55:00.702Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CV系列1：卷积神经网络的演变">
<meta name="twitter:description" content="本文主要介绍深度学习种卷积神经网络的发展历史，以及典型的卷积神经网络。">
<meta name="twitter:image" content="https://i.loli.net/2020/04/06/HaqK5wDLAsPTEzC.jpg">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>
</html>
<body>
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">YP Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>Home</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>Archives</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        YP Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        一个专注 WEB 开发的技术博客
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="Blog" target="_blank" href="https://iloveyou11.github.io/">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="https://github.com/iloveyou11">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-CV-01" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="post-title" itemprop="name">
      CV系列1：卷积神经网络的演变
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/AI/">AI</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2020-03-16
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

                    
            </header>
            
                <div class="article-entry post-content" itemprop="articleBody">
                    
                            
                                
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#基础介绍"><span class="toc-text">基础介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#什么是深度学习"><span class="toc-text">什么是深度学习</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1x1卷积"><span class="toc-text">1x1卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#空洞卷积"><span class="toc-text">空洞卷积</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#转置卷积（反卷积）"><span class="toc-text">转置卷积（反卷积）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#什么是卷积神经网"><span class="toc-text">什么是卷积神经网</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#深度学习模型"><span class="toc-text">深度学习模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#相关知识"><span class="toc-text">相关知识</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#激活函数"><span class="toc-text">激活函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#优化器（梯度下降算法）"><span class="toc-text">优化器（梯度下降算法）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#权值-w-偏置-b-初始化"><span class="toc-text">权值(w)偏置(b)初始化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#过拟合和欠拟合"><span class="toc-text">过拟合和欠拟合</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#常见问题"><span class="toc-text">常见问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#为什么需要激活函数？"><span class="toc-text">为什么需要激活函数？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#网络加深就一定好吗？"><span class="toc-text">网络加深就一定好吗？</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#卷积神经网络演变"><span class="toc-text">卷积神经网络演变</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LeNet——雏形网络"><span class="toc-text">LeNet——雏形网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AlexLet"><span class="toc-text">AlexLet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SPPNet——空间金字塔"><span class="toc-text">SPPNet——空间金字塔</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#VGGNet"><span class="toc-text">VGGNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#GoogLeNet"><span class="toc-text">GoogLeNet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ResNet——残差网络"><span class="toc-text">ResNet——残差网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DenseNet——密连网络"><span class="toc-text">DenseNet——密连网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CatNet——拼接网络"><span class="toc-text">CatNet——拼接网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#R-CNN——区域卷积网络"><span class="toc-text">R-CNN——区域卷积网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Fast-R-CNN"><span class="toc-text">Fast R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Faster-R-CNN"><span class="toc-text">Faster R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Mask-R-CNN"><span class="toc-text">Mask R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#YOLO"><span class="toc-text">YOLO</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SSD"><span class="toc-text">SSD</span></a></li></ol></li></ol>
    </div>
    
                                    <p>本文主要介绍深度学习种卷积神经网络的发展历史，以及典型的卷积神经网络。</p>
<a id="more"></a>
<p><a href="https://iloveyou11.github.io/2020/03/16/CV-01/" target="_blank" rel="noopener">CV系列1：卷积神经网络的演变</a><br><a href="https://iloveyou11.github.io/2020/03/19/CV-02/" target="_blank" rel="noopener">CV系列2：目标检测算法</a><br><a href="https://iloveyou11.github.io/2020/03/21/CV-03/" target="_blank" rel="noopener">CV系列3：目标检测精华版本</a></p>
<h3 id="基础介绍"><a href="#基础介绍" class="headerlink" title="基础介绍"></a>基础介绍</h3><h4 id="什么是深度学习"><a href="#什么是深度学习" class="headerlink" title="什么是深度学习"></a>什么是深度学习</h4><p>深度学习是指一类对具有深层结构的神经网络进行有效训练的方法。神经网络是一种由许多非线性计算单元（神经元）组成的分层系统，网络深度是不包括输入层的层数。</p>
<h4 id="1x1卷积"><a href="#1x1卷积" class="headerlink" title="1x1卷积"></a>1x1卷积</h4><p>作用：</p>
<ol>
<li>可以增加模型的非线性性（相当于在不改变特征尺寸的基础上，额外引入了一个非线性层，使用非线性激活函数）</li>
<li>进行特征降维，可以将多通道的特征图压缩到更小的channel（主要目的）</li>
</ol>
<p>其中，1x1卷积的主要作用是为了特征降维，能极大地减少计算量，在GoogLeNet的Inception架构中，引入了1x1卷积来简化计算。</p>
<img width="60%" src="https://i.loli.net/2020/04/06/HaqK5wDLAsPTEzC.jpg" alt="1x1卷积">

<p>以下是GoogLeNet的Inception结构，其中就应用到了1x1的卷积，极大地简化了计算量：</p>
<img width="60%" src="https://i.loli.net/2020/04/06/isyzG24B3f5HYeA.jpg" alt="1x1卷积减少计算量">

<h4 id="空洞卷积"><a href="#空洞卷积" class="headerlink" title="空洞卷积"></a>空洞卷积</h4><img width="60%" src="https://i.loli.net/2020/04/06/4jDPpI5Ub2o7Tne.jpg" alt="空洞卷积">

<h4 id="转置卷积（反卷积）"><a href="#转置卷积（反卷积）" class="headerlink" title="转置卷积（反卷积）"></a>转置卷积（反卷积）</h4><img width="60%" src="https://i.loli.net/2020/04/06/ybJ71TREC8AloNU.jpg" alt="转置卷积">

<h4 id="什么是卷积神经网"><a href="#什么是卷积神经网" class="headerlink" title="什么是卷积神经网"></a>什么是卷积神经网</h4><p>卷积神经网络是一种特殊的多层感知机或前馈神经网络，具有局部连接、权值共享的特点，其中大量神经元按照一定方式组织起来对视野中的交叠区域产生反应。</p>
<p>卷积神经网络是深度学习中最为重要的模型。在2012年，提出了著名的AlexNet，在ImageNet（大规模图片分类竞赛）上取得了优异成绩，为深度学习奠定了基础。之后，卷积神经网络相继出现，如VGGNet、GoogLeNet、ResNet、SPPNet、DenseNet、Faster RCNN、YOLO、SSD、FCN、Mask RCNN、DCGAN等等，极大地推进了图片分类、识别和理解技术的发展。</p>
<h4 id="深度学习模型"><a href="#深度学习模型" class="headerlink" title="深度学习模型"></a>深度学习模型</h4><ul>
<li>卷积神经网络（CNN）</li>
<li>循环神经网络（RNN）</li>
<li>长短期记忆网络（LSTM）</li>
<li>深层自编码器（AE）</li>
<li>深层信念网络</li>
<li>强化学习网络（RLN）</li>
<li>生成式对抗网络（GAN）</li>
<li>受限玻尔兹曼机（RBM）</li>
<li>深层玻尔兹曼机（DSN）<br>……</li>
</ul>
<h3 id="相关知识"><a href="#相关知识" class="headerlink" title="相关知识"></a>相关知识</h3><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>常见激活函数有sigmoid、tanh、relu、leaky relu、maxout等等，它们的函数图像如下：<br><img width="50%" alt="激活函数" src="https://i.loli.net/2020/03/23/PDkzl9BehuEnZ54.png"></p>
<p><strong>特点及问题：</strong><br><strong>1. Sigmoid</strong></p>
<ul>
<li>Sigmoid函数饱和使梯度消失。当神经元的激活在接近0或1处时会饱和，在这些区域梯度几乎为0，这就会导致梯度消失，几乎就有没有信号通过神经传回上一层。</li>
<li>Sigmoid函数的输出不是零中心的。因为如果输入神经元的数据总是正数，那么关于w的梯度在反向传播的过程中，将会要么全部是正数，要么全部是负数，这将会导致梯度下降权重更新时出现z字型的下降。</li>
</ul>
<p><strong>2. tanh</strong></p>
<ul>
<li>Tanh解决了Sigmoid的输出是不是零中心的问题，但仍然存在饱和问题。</li>
<li>为了防止饱和，现在主流的做法会在激活函数前多做一步batch normalization，尽可能保证每一层网络的输入具有均值较小的、零中心的分布。</li>
</ul>
<p><strong>3. ReLU</strong></p>
<ul>
<li>ReLU单元比较脆弱并且可能“死掉”，而且是不可逆的，因此导致了数据多样化的丢失。通过合理设置学习率，会降低神经元“死掉”的概率。</li>
</ul>
<p><strong>4. Leaky ReLU</strong></p>
<ul>
<li>能解决了ReLU神经元“死掉”的问题</li>
</ul>
<p><strong>5. Maxout</strong></p>
<ul>
<li>Maxout是对ReLU和leaky ReLU的一般化归纳。Maxout具有ReLU的优点，如计算简单，不会 saturation，同时又没有ReLU的一些缺点，如容易go die。问题就是每个神经元的参数double（翻倍），这就导致整体参数的数量激增。</li>
</ul>
<p><strong>6. Softmax</strong></p>
<ul>
<li>Softmax用于多分类神经网络输出，目的是让大的更大。</li>
</ul>
<h4 id="优化器（梯度下降算法）"><a href="#优化器（梯度下降算法）" class="headerlink" title="优化器（梯度下降算法）"></a>优化器（梯度下降算法）</h4><ul>
<li><strong>随机梯度下降（SGD）</strong><br>分为两种模式：整体梯度下降、mini梯度下降。<strong>整体梯度下降</strong>是先把所有样本随机洗牌，再逐一计算每个样本对梯度的贡献去更新权值。缺点是梯度下降的过程不太稳定、波动较大。<strong>mini梯度下降</strong>是将所有样本随机洗牌后分为若干大小为m的块，再逐一计算每块对梯度的贡献去更新权值。</li>
<li><strong>Momentum动量</strong><br>加一个动量（借助物理学的惯性原理）</li>
</ul>
<img width="50%" src="https://i.loli.net/2020/03/23/EP24GoBwSs8jNlx.jpg" alt="Momentum动量">

<ul>
<li><strong>Adagrad</strong><br>在不同方向上的学习率是可以变化的，计算时除了这个方向上所有之前梯度的平均值。</li>
</ul>
<img width="50%" src="https://i.loli.net/2020/03/23/A5ougkDGOqzniVy.jpg" alt="Adagrad">

<ul>
<li><strong>RMSProp</strong><br>在不同方向上的学习率是可以变化的，计算时除了这个方向上所有之前梯度的加权平均值（最近的gradient权重大，过去的gradient权重小）</li>
</ul>
<img width="50%" src="https://i.loli.net/2020/03/23/EB9vHFjotcremDW.jpg" alt="RMSProp">

<ul>
<li><p><strong>Adam</strong><br>记录过去一段时间的梯度平方和（类似Adagrad和RMSProp）以及梯度的和（类似Momentum动量），把优化看作是铁球滚下山坡，定义了一个带动量和摩擦的铁球。Adam是目前最好的算法，在不知道如何选择时就选择它。</p>
</li>
<li><p>……</p>
</li>
</ul>
<h4 id="权值-w-偏置-b-初始化"><a href="#权值-w-偏置-b-初始化" class="headerlink" title="权值(w)偏置(b)初始化"></a>权值(w)偏置(b)初始化</h4><p>在训练神经网络之前，必须对其权值和偏置进行初始化，常用的初始化方法有3种：高斯初始化、Xavier初始化和MSRA初始化。它们一般都是把偏置初始化为0，对权值进行随机初始化。</p>
<h4 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h4><p><strong>1. 如何防止过拟合</strong></p>
<ul>
<li>获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法</li>
<li>采用合适的模型（控制模型的复杂度）</li>
<li>降低特征的数量</li>
<li>使用正则化项（常见的L0、L1、L2正则化项，L1可以稀疏神经元，L2可以降低神经元权重，从而降低了过拟合的风险）</li>
<li>dropout（在网络训练过程中让网络某些节点不工作，不过度依赖某些神经元）</li>
<li>early stopping（如果发现随着训练迭代次数的增多，测试集并没有出现损失减少反而上升的现象，则可能是发生了过拟合，导致了泛化能力降低，应提前停止训练）</li>
</ul>
<p><strong>2. 如何防止欠拟合</strong></p>
<ul>
<li>增加网络复杂度</li>
<li>在模型中增加特征</li>
</ul>
<h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><h4 id="为什么需要激活函数？"><a href="#为什么需要激活函数？" class="headerlink" title="为什么需要激活函数？"></a>为什么需要激活函数？</h4><p>如果不适用激活函数，那么就算层数再深，表达的也只是线性函数，和使用一层网络表达的效果相同。</p>
<h4 id="网络加深就一定好吗？"><a href="#网络加深就一定好吗？" class="headerlink" title="网络加深就一定好吗？"></a>网络加深就一定好吗？</h4><p>加深在一定程度上可以提升模型性能，但是未必就是网络越深越越好。深层网络带来的梯度不稳定，网络退化的问题始终都是存在的，可以缓解，没法消除。这就有可能出现网络加深，性能反而开始下降。深层网络的训练很少能突破30层，VGGNet19层，GoogleNet22层，MobileNet28层，经典的网络超过30层的也就是ResNet系列常见的ResNet50，ResNet152了。ResNet网络使用跳连结构，有效地解决了梯度消失问题。</p>
<p>模型加深还可能出现的一些问题是导致某些浅层的学习能力下降，限制了深层网络的学习，这也是跳层连接等结构能够发挥作用的很重要的因素。</p>
<h3 id="卷积神经网络演变"><a href="#卷积神经网络演变" class="headerlink" title="卷积神经网络演变"></a>卷积神经网络演变</h3><img width="60%" alt="卷积神经网络演变历史" src="https://i.loli.net/2020/03/23/tjsBuCpIH5xzlea.jpg">

<p><strong>图像识别系列</strong></p>
<h4 id="LeNet——雏形网络"><a href="#LeNet——雏形网络" class="headerlink" title="LeNet——雏形网络"></a>LeNet——雏形网络</h4><p>第一个真正的卷积神经网络在1998年提出，称为LeNet。模型共有8层（不计输入层），包括3个卷积层、2个下采样层、1个全连接层、1个输出层。模型结构如下：</p>
<img width="60%" alt="LeNet" src="https://i.loli.net/2020/03/23/Qf9OoUcmvXJWTxj.jpg">

<img width="60%" alt="LeNet2" src="https://i.loli.net/2020/03/23/wbM3USkNtuOjHqm.jpg">

<h4 id="AlexLet"><a href="#AlexLet" class="headerlink" title="AlexLet"></a>AlexLet</h4><p>AlexLet包含5个卷积层（进行了3次最大池化）、3个全连接层。模型结构如下：</p>
<img width="60%" src="https://i.loli.net/2020/03/23/hKbTYGAp715dlNJ.jpg" alt="AlexLet">

<p>AlexLet与LeNet相比，有了很多的改进：</p>
<ol>
<li>使用了ReLU激活函数，提高训练速度（ReLU是一种非饱和函数，在训练时间上比饱和函数sigmoid、tanh快，而且ReLU利用了分片线性结构实现了非线性的表达能力，梯度消失现象较弱，有助于训练更深的网络）</li>
<li>使用GPU训练（可以提供数十倍乃至于上百倍于CPU的性能）</li>
<li>使用重叠池化（传统池化窗口没有重叠，不同窗口池化过程分别独立计算，有助于缓解过拟合）</li>
<li>局部响应归一化（不过后来验证没效果，采用的是BN？）</li>
<li>数据扩充——图像平移和反转、丢失输出——随即丢弃节点（减少了过拟合）</li>
</ol>
<h4 id="SPPNet——空间金字塔"><a href="#SPPNet——空间金字塔" class="headerlink" title="SPPNet——空间金字塔"></a>SPPNet——空间金字塔</h4><p>空间金字塔池化网络，在最后一个卷积层和第一个全连接层之间插入了一个空间金字塔池化层，用来池化特征并产生固定长度的输出。无需对输入图像进行裁剪和变形，就可以处理输入图像大小不同的情况。</p>
<img width="60%" alt="SPPNet" src="https://i.loli.net/2020/03/23/eSWywOImAvVGDMn.jpg">

<p>SPP有几个引人注目的特征：</p>
<ol>
<li>SPP对于任意输入大小都能产生一个固定长度的输出，而滑动窗口池化不能</li>
<li>SPP使用多级大小空间窗口，而滑动窗口池化只使用一个窗口大小</li>
<li>SPP可以在不同尺度上提取特征并进行池化</li>
</ol>
<img width="60%" alt="SPPNet2" src="https://i.loli.net/2020/03/23/mqFH2SLMc1J7XZg.jpg">

<h4 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h4><p>有两种基本类型：VGGNet-16、VGGNet-19。VGGNet全部使用3X3的卷积核和2X2的池化核。VGG 块的组成规律是：连续使用若干个相同的填充为 1 、窗口形状为3X3的卷积层后接上一个步幅为 2 、窗口形状为2X2的最大池化层。</p>
<p>对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核优于采用大的卷积核，因为可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。</p>
<p>常见的VGG网络有：VGG-11、VGG-13、VGG-16、VGG-19</p>
<img width="50%" alt="VGGNet" src="https://i.loli.net/2020/03/23/GXiz8tcIZmHfRaM.jpg">

<h4 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h4><p>GoogLeNet专注于如何建立更深的网络结构，通视引入新型的基本结构——Inception模块，以加深网络宽度。GoogLeNet包括V1、V2、V3、V4版本。</p>
<p><strong>Inception的作用：</strong> 代替人工确定卷积层中的过滤器类型或者确定是否需要创建卷积层和池化层，即：不需要人为的决定使用哪个过滤器，是否需要池化层等，由网络自行决定这些参数，可以给网络添加所有可能值，将输出连接起来，网络自己学习它需要什么样的参数。</p>
<p><strong>1. Inception V1结构</strong></p>
<img width="50%" alt="Inception v1" src="https://i.loli.net/2020/03/23/YzK3WBeIwZROaVy.jpg">

<p>由上图可以看出，Inception 块里有4条并行的线路，它通过不同窗口形状的卷积层和最大池化层来并行抽取信息，并使用1X1卷积层减少通道数从而降低模型复杂度。</p>
<p><strong>2. Inception V2结构</strong></p>
<img width="40%" alt="Inception v2" src="https://i.loli.net/2020/03/23/8MEfPrFHmaWiUO9.jpg">

<p>用2个连续的3x3卷积层(stride=1)组成的小网络来代替单个的5x5卷积层，这便是Inception V2结构，保持感受野范围的同时又减少了参数量</p>
<p><strong>3. Inception V3结构</strong></p>
<p>考虑了 nx1 卷积核，如下图所示的取代3x3卷积：于是，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。</p>
<img width="60%" alt="Inception v3" src="https://i.loli.net/2020/03/23/Vg3MxciEzeQCDqU.jpg">

<img width="60%" alt="Inception v3-2" src="https://i.loli.net/2020/03/23/jpGdJlD7NWFH5o8.jpg">

<p><strong>4. Inception V4结构</strong><br>它结合了残差神经网络ResNet。</p>
<h4 id="ResNet——残差网络"><a href="#ResNet——残差网络" class="headerlink" title="ResNet——残差网络"></a>ResNet——残差网络</h4><p>随着网络结构的加深， 梯度消失或梯度爆炸问题会越来越严重，可能导致神经网络学习和训练变得越来越困难。通过初始化、随机丢弃、归一化等技巧可以得到一定程度的缓和，而ResNet使用了在网络中增加信息传递快速通道的方法，信息可以无障碍地跨越多层直接传递到后面的层。</p>
<p>残差网络引入了跨层连接，构造了残差模块。基于残差模块，深层残差网络可以具有非常深的结构，深度甚至可以达到1000层以上。</p>
<img width="30%" alt="ResNet" src="https://i.loli.net/2020/03/23/tisQ4Tep2mVohjI.jpg">

<h4 id="DenseNet——密连网络"><a href="#DenseNet——密连网络" class="headerlink" title="DenseNet——密连网络"></a>DenseNet——密连网络</h4><p>残差网络在层间加入跨层连接，使得即使成百上千层的网络，也可以得到精准地训练。不过，残差网络一般只采用2~3层的跨层连接形成残差模块，密连卷积网络（DenseNet）通过引入密连模块代替残差模块进一步扩展了残差网络的结构。与残差模块的区别在于，密连模块内部允许任意两个非相邻层之间进行跨层连接。</p>
<img width="50%" alt="DenseNet" src="https://i.loli.net/2020/03/23/mU91kI2sqeA3hga.jpg">

<img width="50%" alt="DenseNet2" src="https://i.loli.net/2020/03/23/BKoIu2OG649eLWZ.jpg">

<h4 id="CatNet——拼接网络"><a href="#CatNet——拼接网络" class="headerlink" title="CatNet——拼接网络"></a>CatNet——拼接网络</h4><p>CatNet包含了r个交错的卷积层和池化层，再跟一个全连接层和输出层。其中，全连接层是所有卷积层和池化层通过跨层连接拼接的得到的。</p>
<img width="50%" alt="CatNet" src="https://i.loli.net/2020/03/23/2l54TnfwRahcM67.jpg">

<hr>
<p><strong>目标检测系列</strong></p>
<h4 id="R-CNN——区域卷积网络"><a href="#R-CNN——区域卷积网络" class="headerlink" title="R-CNN——区域卷积网络"></a>R-CNN——区域卷积网络</h4><p>R-CNN是一种目标检测模型，目标检测要求在图像中确定多个可能目标的位置。R-CNN采用了华东窗口的策略进行定位，包括3大模块：区域推荐、特征提取、区域分类。</p>
<ol>
<li>区域推荐<br>给输入图像生成约2000个类别无关的区域推荐构成候选检测集。R-CNN采用的区域推荐方法是选择性搜索（selective search），其他推荐方法包括目标够成度、类别无关目标推荐、受限参数最小割等。</li>
<li>特征提取<br>利用卷积网络计算每个推荐的特征，要求先将推荐转变为卷积网络的输入大小，并且做减均值处理。</li>
<li>区域分类<br>对每个区域进行打分和筛选。R-CNN先采用支持向量机SCM对所提取的特征打分，再根据分支高低，通过贪婪非最大抑制策略进行筛选，保留高分推荐。</li>
</ol>
<img width="60%" alt="RCNN" src="https://i.loli.net/2020/03/23/1DHYvwhOuKnNcaC.jpg">

<h4 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h4><p>R-CNN利用深层卷积网络对目标区域推荐进行分类，可以得到较高的检测精度，但也有明显不足：</p>
<ol>
<li>训练过程阶段多。先区域推荐、再求特征、再区域分类</li>
<li>训练时空费用大。支持向量机和边框回归都需要从每幅图像的每个区域推荐提取特征写入硬盘，过程非常耗时。</li>
<li>目标检测速度慢。</li>
</ol>
<p>于是有人提出Fast R-CNN网络，优点在于1）检测质量更高 2）训练过程统一 3）网络圈层更新 4）无需磁盘存储</p>
<p>Fast R-CNN的结构如下：</p>
<img width="60%" alt="Fast R-CNN0" src="https://i.loli.net/2020/03/23/cI3ALbZ9adwymjU.jpg">

<p>输入一幅完整图像和多个感兴趣区域（RoI）,京埚几个卷积和最大池化层的处理，产生一个共享卷积特征图，用来为每个区域推荐的RoI通过最大池化提取一个固定长度的特征向量。这些特征向量的输入到一系列全连接层后，又分化为两个并列输出层：一个输出类别softmax概率，一个输出目标惊喜边框位置。</p>
<img width="60%" alt="Fast R-CNN" src="https://i.loli.net/2020/03/23/cyR4uFf5DiOr6Pj.jpg">

<img width="60%" alt="Fast R-CNN2" src="https://i.loli.net/2020/03/23/aYZt7g2bEomSreN.jpg">

<p>Fast R-CNN做了以下改变：</p>
<ol>
<li>把最后的最大池化层替换为一个RoI池化层</li>
<li>把最后的全连接层和softmax层替换为两个兄弟层，分别用来估计每个类别的概率和边框</li>
<li>把网络改为接收两种数据输入，一是图像列表，二是RoooI列表</li>
</ol>
<h4 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a>Faster R-CNN</h4><p>Faster R-CNN采用了区域推荐网络（RPN），可以检测网络共享整幅图像的卷积特征，从而产生几乎无代价的区域推荐。</p>
<img width="30%" alt="Faseter RCNN" src="https://i.loli.net/2020/03/23/TzXD2xKCI3Fpwqv.jpg">

<p>Faster R-CNN有两个模块：一是用来产生区域推荐的RPN，二是使用推荐于去的Fast R-CNN检测器。整个系统是一个统一的目标检测网络，其中RPN采用了attention机制，告诉Fast R-CNN模块应该看什么地方。</p>
<h4 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a>Mask R-CNN</h4><img width="60%" src="https://i.loli.net/2020/03/23/INtbYW4eXKJcuAr.jpg" alt="Mask R-CNN">

<p><strong>RCNN系列算法对比：</strong></p>
<img width="60%" src="https://i.loli.net/2020/03/23/FagjoMOD3JS78VU.jpg" alt="RCNN系列算法对比">

<h4 id="YOLO"><a href="#YOLO" class="headerlink" title="YOLO"></a>YOLO</h4><img width="50%" alt="YOLO" src="https://i.loli.net/2020/03/23/5rClbMTnG3XhHq9.jpg">

<h4 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h4><p>单次检测器（SSD）是一种新型的深度神经网络目标检测器，不用对边框假设重采像素或特征，也不会损失精度，但速度比Faster R-CNN、YOLO都要快。SSD提高速度的根本改进措施是消除边框推荐和随后的像素或特征重采样阶段，还包括使用小卷积核在变量位置预测对象的类别和偏移，使用独立预测器负责不同高度比的检测，并用这些滤波器在网络后期的多个特征图种执行多尺度检测。</p>

                                        
                </div>
                <footer class="article-footer">
                    
                        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://localhost:4000/2020/03/16/CV-01/&title=《CV系列1：卷积神经网络的演变》 — blog&pic=/images/banner.jpg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://localhost:4000/2020/03/16/CV-01/&title=《CV系列1：卷积神经网络的演变》 — blog&source=本文主要介绍深度学习种卷积神经网络的发展历史，以及典型的卷积神经网络。" data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2020/03/16/CV-01/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《CV系列1：卷积神经网络的演变》 — blog&url=http://localhost:4000/2020/03/16/CV-01/&via=http://localhost:4000" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://localhost:4000/2020/03/16/CV-01/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://localhost:4000/2020/03/16/CV-01/" alt="微信分享二维码">
</div>

<div class="mask"></div>

                            
                                <ul class="article-footer-menu">
                                    
                                            
                                </ul>
                                
                </footer>
    </div>
</article>

    
    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#基础介绍"><span class="post-toc-text">基础介绍</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#什么是深度学习"><span class="post-toc-text">什么是深度学习</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#1x1卷积"><span class="post-toc-text">1x1卷积</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#空洞卷积"><span class="post-toc-text">空洞卷积</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#转置卷积（反卷积）"><span class="post-toc-text">转置卷积（反卷积）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#什么是卷积神经网"><span class="post-toc-text">什么是卷积神经网</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#深度学习模型"><span class="post-toc-text">深度学习模型</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#相关知识"><span class="post-toc-text">相关知识</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#激活函数"><span class="post-toc-text">激活函数</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#优化器（梯度下降算法）"><span class="post-toc-text">优化器（梯度下降算法）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#权值-w-偏置-b-初始化"><span class="post-toc-text">权值(w)偏置(b)初始化</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#过拟合和欠拟合"><span class="post-toc-text">过拟合和欠拟合</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#常见问题"><span class="post-toc-text">常见问题</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#为什么需要激活函数？"><span class="post-toc-text">为什么需要激活函数？</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#网络加深就一定好吗？"><span class="post-toc-text">网络加深就一定好吗？</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#卷积神经网络演变"><span class="post-toc-text">卷积神经网络演变</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#LeNet——雏形网络"><span class="post-toc-text">LeNet——雏形网络</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#AlexLet"><span class="post-toc-text">AlexLet</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#SPPNet——空间金字塔"><span class="post-toc-text">SPPNet——空间金字塔</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#VGGNet"><span class="post-toc-text">VGGNet</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#GoogLeNet"><span class="post-toc-text">GoogLeNet</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#ResNet——残差网络"><span class="post-toc-text">ResNet——残差网络</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#DenseNet——密连网络"><span class="post-toc-text">DenseNet——密连网络</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#CatNet——拼接网络"><span class="post-toc-text">CatNet——拼接网络</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#R-CNN——区域卷积网络"><span class="post-toc-text">R-CNN——区域卷积网络</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Fast-R-CNN"><span class="post-toc-text">Fast R-CNN</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Faster-R-CNN"><span class="post-toc-text">Faster R-CNN</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#Mask-R-CNN"><span class="post-toc-text">Mask R-CNN</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#YOLO"><span class="post-toc-text">YOLO</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#SSD"><span class="post-toc-text">SSD</span></a></li></ol></li></ol>
        </nav>
    </aside>
    
        
<nav id="article-nav">
  
    <a href="/2020/03/19/CV-02/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          CV系列2：目标检测算法
        
      </span>
    </a>
  
  
    <a href="/2020/01/30/ML-07/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">ML系列7：tensorflow项目实战</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>

            
                
                    
                                                    </section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2020 Yang Pei<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    var mihoConfig = {
        root: "http://localhost:4000",
        animate: "false" ,
        isHome: "false" ,
        share: "true"
    }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/AI/">AI</a><a class="category-link" href="/categories/前端/">前端</a><a class="category-link" href="/categories/计算机/">计算机</a><a class="category-link" href="/categories/语言/">语言</a>
        </div>
        <div id="sidebar-menu-box-tags">
            
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>
<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>Home</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>Archives</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            
        </div>
    </div>
</div>
    <div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
    <script src="/js/search.js"></script>
        <script src="/js/main.js"></script>

            
                <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
                <div id="particles"></div>
                <script src="/js/particles.js"></script>
                    

                        

                                

                                                
                                                                
                                                                    <script src="/js/pop-img.js"></script>
                                                                        <script>
                                                                            $(".article-entry p img").popImg();
                                                                        </script>
                                                                        
  </div>
</body>
</html>