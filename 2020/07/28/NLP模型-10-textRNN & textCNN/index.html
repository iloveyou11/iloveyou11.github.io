<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>NLP模型-10-textRNN&amp;textCNN | blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="YP's Blog">
  
  <meta name="description" content="NLP模型-01-预训练语言模型NLP模型-02-HMMNLP模型-03-GMMNLP模型-04-CRFNLP模型-05-transformerNLP模型-06-BertNLP模型-07-LDANLP模型-08-fastTextNLP模型-09-GloveNLP模型-10-textRNN &amp;amp; textCNNNLP模型-11-seq2seqNLP模型-12-attentionNLP模型-13">
<meta name="keywords" content="web">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP模型-10-textRNN&amp;textCNN">
<meta property="og:url" content="http://localhost:4000/2020/07/28/NLP模型-10-textRNN & textCNN/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="NLP模型-01-预训练语言模型NLP模型-02-HMMNLP模型-03-GMMNLP模型-04-CRFNLP模型-05-transformerNLP模型-06-BertNLP模型-07-LDANLP模型-08-fastTextNLP模型-09-GloveNLP模型-10-textRNN &amp;amp; textCNNNLP模型-11-seq2seqNLP模型-12-attentionNLP模型-13">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://i.loli.net/2020/07/28/vwRmjkPyd9n2rCc.png">
<meta property="og:image" content="https://i.loli.net/2020/07/28/kH46Et2SXnhgyKC.png">
<meta property="og:image" content="https://i.loli.net/2020/07/28/4zd5ngprFLqZoSO.png">
<meta property="og:updated_time" content="2020-07-28T12:20:18.737Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP模型-10-textRNN&amp;textCNN">
<meta name="twitter:description" content="NLP模型-01-预训练语言模型NLP模型-02-HMMNLP模型-03-GMMNLP模型-04-CRFNLP模型-05-transformerNLP模型-06-BertNLP模型-07-LDANLP模型-08-fastTextNLP模型-09-GloveNLP模型-10-textRNN &amp;amp; textCNNNLP模型-11-seq2seqNLP模型-12-attentionNLP模型-13">
<meta name="twitter:image" content="https://i.loli.net/2020/07/28/vwRmjkPyd9n2rCc.png">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>
</html>
<body>
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">YP&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>主页</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>全部</span>
                    </a>
                    
                    <a  href="/categories/AI/">
                        <i class="fa fa-AI"></i>
                        <span>AI</span>
                    </a>
                    
                    <a  href="/categories/前端/">
                        <i class="fa fa-前端"></i>
                        <span>前端</span>
                    </a>
                    
                    <a  href="/categories/计算机/">
                        <i class="fa fa-计算机"></i>
                        <span>计算机</span>
                    </a>
                    
                    <a  href="/categories/语言/">
                        <i class="fa fa-语言"></i>
                        <span>语言</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        YP&#39;s Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        一个专注前端智能化开发的技术博客
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="Blog" target="_blank" href="https://iloveyou11.github.io/">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="https://github.com/iloveyou11">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-NLP模型-10-textRNN &amp; textCNN" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="post-title" itemprop="name">
      NLP模型-10-textRNN&amp;textCNN
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/AI/">AI</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2020-07-28
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

                    
            </header>
            
                <div class="article-entry post-content" itemprop="articleBody">
                    
                            
                                
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#TextRNN"><span class="toc-text">TextRNN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#模型结构"><span class="toc-text">模型结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代码实战"><span class="toc-text">代码实战</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#数据集下载"><span class="toc-text">数据集下载</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#textRNN模型和可配置的参数"><span class="toc-text">textRNN模型和可配置的参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#开始训练"><span class="toc-text">开始训练</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#模型测试"><span class="toc-text">模型测试</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TextCNN"><span class="toc-text">TextCNN</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#模型结构-1"><span class="toc-text">模型结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#代码实战-1"><span class="toc-text">代码实战</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#数据集下载-1"><span class="toc-text">数据集下载</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#textCNN的模型和可配置的参数"><span class="toc-text">textCNN的模型和可配置的参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#开始训练-1"><span class="toc-text">开始训练</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#模型测试-1"><span class="toc-text">模型测试</span></a></li></ol></li></ol></li></ol>
    </div>
    
                                    <p><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-01-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" target="_blank" rel="noopener">NLP模型-01-预训练语言模型</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-02-HMM/" target="_blank" rel="noopener">NLP模型-02-HMM</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-03-GMM/" target="_blank" rel="noopener">NLP模型-03-GMM</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-04-CRF/" target="_blank" rel="noopener">NLP模型-04-CRF</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-05-transformer/" target="_blank" rel="noopener">NLP模型-05-transformer</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-06-Bert/" target="_blank" rel="noopener">NLP模型-06-Bert</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-07-LDA/" target="_blank" rel="noopener">NLP模型-07-LDA</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-08-fastText/" target="_blank" rel="noopener">NLP模型-08-fastText</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-09-Glove/" target="_blank" rel="noopener">NLP模型-09-Glove</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-10-textRNN%20&%20textCNN/" target="_blank" rel="noopener">NLP模型-10-textRNN &amp; textCNN</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-11-seq2seq/" target="_blank" rel="noopener">NLP模型-11-seq2seq</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-12-attention/" target="_blank" rel="noopener">NLP模型-12-attention</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-13-XLnet/" target="_blank" rel="noopener">NLP模型-13-XLnet</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-14-%E6%A0%B8%E6%96%B9%E6%B3%95/" target="_blank" rel="noopener">NLP模型-14-核方法</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-15-%E6%B7%B1%E5%BA%A6%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA/" target="_blank" rel="noopener">NLP模型-15-深度玻尔兹曼机</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-16-%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA/" target="_blank" rel="noopener">NLP模型-16-受限玻尔兹曼机</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-17-%E6%B7%B1%E5%BA%A6%E4%BF%A1%E5%BF%B5%E7%BD%91%E7%BB%9C/" target="_blank" rel="noopener">NLP模型-17-深度信念网络</a></p>
<h3 id="TextRNN"><a href="#TextRNN" class="headerlink" title="TextRNN"></a>TextRNN</h3><h4 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h4><p>TextRNN是利用RNN网络来解决文本分类问题，当然，也可以采用RNN的变种LSTM、GRU来实现……</p>
<p>文本分类的任务有：</p>
<ul>
<li>垃圾邮件分类</li>
<li>情感分析</li>
<li>新闻/报道主题分析</li>
<li>问答系统中的问句分类</li>
<li>……</li>
</ul>
<ol>
<li>结构1<br>流程：embedding—&gt;BiLSTM—&gt;concat final output/average all output—–&gt;softmax layer</li>
</ol>
<img src="https://i.loli.net/2020/07/28/vwRmjkPyd9n2rCc.png" alt="TextRNN1" width="60%">

<p>取前向/反向LSTM在最后一步的隐藏状态进行拼接，经过softmax层进行多分类；或者是取前向/反向LSTM在每一步上的隐藏状态，对每一步的两个隐藏状态进行拼接，然后对所有步拼接后的隐藏状态取平均值，然后再经过softmax层进行多分类，</p>
<ol start="2">
<li>结构2<br>流程：embedding–&gt;BiLSTM—-&gt;(dropout)–&gt;concat ouput—&gt;UniLSTM—&gt;(droput)–&gt;softmax layer</li>
</ol>
<img src="https://i.loli.net/2020/07/28/kH46Et2SXnhgyKC.png" alt="TextRNN2" width="80%">

<p>与结构1不同，结构2是在双向LSTM的基础上又叠加了一个单向的LSTM，把双向LSTM在每一步上的两个隐藏状态进行拼接，再进行dropout操作，作为上层单向LSTM每一步长上的一个输入，最后取上层单向LSTM最后一步上的隐藏状态，再进行dropout操作，最后经过一个softmax层进行一个多分类。</p>
<p><a href="https://www.cnblogs.com/Luv-GEM/p/10836454.html" target="_blank" rel="noopener">中文文本分类之TextRNN</a></p>
<p>【总结】<br>textRNN的结构十分灵活，可以任意改变。如：</p>
<ul>
<li>把LSTM改为GRU</li>
<li>把双向改为单向</li>
<li>添加dropout/BN或者堆叠多层</li>
</ul>
<p>textRNN在文本分类任务上可以取得很好的效果。</p>
<h4 id="代码实战"><a href="#代码实战" class="headerlink" title="代码实战"></a>代码实战</h4><h5 id="数据集下载"><a href="#数据集下载" class="headerlink" title="数据集下载"></a>数据集下载</h5><p>使用THUCNews的一个<a href="https://www.lanzous.com/i5t0lsd" target="_blank" rel="noopener">子集</a>进行训练与测试，本次训练使用了其中的10个分类，每个分类6500条数据。类别分别为——体育, 财经, 房产, 家居, 教育, 科技, 时尚, 时政, 游戏, 娱乐。</p>
<p><strong>cnews_loader.py为数据的预处理文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">read_file(): 读取文件数据;</span><br><span class="line">build_vocab(): 构建词汇表，使用字符级的表示，这一函数会将词汇表存储下来，避免每一次重复处理;</span><br><span class="line">read_vocab(): 读取上一步存储的词汇表，转换为&#123;词：id&#125;表示;</span><br><span class="line">read_category(): 将分类目录固定，转换为&#123;类别: id&#125;表示;</span><br><span class="line">to_words(): 将一条由id表示的数据重新转换为文字;</span><br><span class="line">process_file(): 将数据集从文字转换为固定长度的id序列表示;</span><br><span class="line">batch_iter(): 为神经网络的训练准备经过shuffle的批次的数据。</span><br></pre></td></tr></table></figure>

<h5 id="textRNN模型和可配置的参数"><a href="#textRNN模型和可配置的参数" class="headerlink" title="textRNN模型和可配置的参数"></a>textRNN模型和可配置的参数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> rnn_model <span class="keyword">import</span> TRNNConfig, TextRNN</span><br><span class="line"><span class="keyword">from</span> cnews_loader <span class="keyword">import</span> read_vocab, read_category, batch_iter, process_file, build_vocab</span><br><span class="line"></span><br><span class="line">base_dir = <span class="string">'cnews'</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'cnews.train.txt'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'cnews.test.txt'</span>)</span><br><span class="line">val_dir = os.path.join(base_dir, <span class="string">'cnews.val.txt'</span>)</span><br><span class="line">vocab_dir = os.path.join(base_dir, <span class="string">'cnews.vocab.txt'</span>)</span><br><span class="line"></span><br><span class="line">save_dir = <span class="string">'checkpoints/textrnn'</span></span><br><span class="line">save_path = os.path.join(save_dir, <span class="string">'best_validation'</span>)  <span class="comment"># 最佳验证结果保存路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_time_dif</span><span class="params">(start_time)</span>:</span></span><br><span class="line">    <span class="string">"""获取已使用时间"""</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    time_dif = end_time - start_time</span><br><span class="line">    <span class="keyword">return</span> timedelta(seconds=int(round(time_dif)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_data</span><span class="params">(x_batch, y_batch, keep_prob)</span>:</span></span><br><span class="line">    feed_dict = &#123;</span><br><span class="line">        model.input_x: x_batch,</span><br><span class="line">        model.input_y: y_batch,</span><br><span class="line">        model.keep_prob: keep_prob</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> feed_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(sess, x_, y_)</span>:</span></span><br><span class="line">    <span class="string">"""评估在某一数据上的准确率和损失"""</span></span><br><span class="line">    data_len = len(x_)</span><br><span class="line">    batch_eval = batch_iter(x_, y_, <span class="number">128</span>)</span><br><span class="line">    total_loss = <span class="number">0.0</span></span><br><span class="line">    total_acc = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> batch_eval:</span><br><span class="line">        batch_len = len(x_batch)</span><br><span class="line">        feed_dict = feed_data(x_batch, y_batch, <span class="number">1.0</span>)</span><br><span class="line">        loss, acc = sess.run([model.loss, model.acc], feed_dict=feed_dict)</span><br><span class="line">        total_loss += loss * batch_len</span><br><span class="line">        total_acc += acc * batch_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_loss / data_len, total_acc / data_len</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Configuring TensorBoard and Saver..."</span>)</span><br><span class="line">    <span class="comment"># 配置 Tensorboard，重新训练时，请将tensorboard文件夹删除，不然图会覆盖</span></span><br><span class="line">    tensorboard_dir = <span class="string">'tensorboard/textrnn'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(tensorboard_dir):</span><br><span class="line">        os.makedirs(tensorboard_dir)</span><br><span class="line"></span><br><span class="line">    tf.summary.scalar(<span class="string">"loss"</span>, model.loss)</span><br><span class="line">    tf.summary.scalar(<span class="string">"accuracy"</span>, model.acc)</span><br><span class="line">    merged_summary = tf.summary.merge_all()</span><br><span class="line">    writer = tf.summary.FileWriter(tensorboard_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 配置 Saver</span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(save_dir):</span><br><span class="line">        os.makedirs(save_dir)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Loading training and validation data..."</span>)</span><br><span class="line">    <span class="comment"># 载入训练集与验证集</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    x_train, y_train = process_file(train_dir, word_to_id, cat_to_id, config.seq_length)</span><br><span class="line">    x_val, y_val = process_file(val_dir, word_to_id, cat_to_id, config.seq_length)</span><br><span class="line">    time_dif = get_time_dif(start_time)</span><br><span class="line">    print(<span class="string">"Time usage:"</span>, time_dif)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建session</span></span><br><span class="line">    session = tf.Session()</span><br><span class="line">    session.run(tf.global_variables_initializer())</span><br><span class="line">    writer.add_graph(session.graph)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Training and evaluating...'</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    total_batch = <span class="number">0</span>  <span class="comment"># 总批次</span></span><br><span class="line">    best_acc_val = <span class="number">0.0</span>  <span class="comment"># 最佳验证集准确率</span></span><br><span class="line">    last_improved = <span class="number">0</span>  <span class="comment"># 记录上一次提升批次</span></span><br><span class="line">    require_improvement = <span class="number">1000</span>  <span class="comment"># 如果超过1000轮未提升，提前结束训练</span></span><br><span class="line"></span><br><span class="line">    flag = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(config.num_epochs):</span><br><span class="line">        print(<span class="string">'Epoch:'</span>, epoch + <span class="number">1</span>)</span><br><span class="line">        batch_train = batch_iter(x_train, y_train, config.batch_size)</span><br><span class="line">        <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> batch_train:</span><br><span class="line">            feed_dict = feed_data(x_batch, y_batch, config.dropout_keep_prob)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_batch % config.save_per_batch == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 每多少轮次将训练结果写入tensorboard scalar</span></span><br><span class="line">                s = session.run(merged_summary, feed_dict=feed_dict)</span><br><span class="line">                writer.add_summary(s, total_batch)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_batch % config.print_per_batch == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 每多少轮次输出在训练集和验证集上的性能</span></span><br><span class="line">                feed_dict[model.keep_prob] = <span class="number">1.0</span></span><br><span class="line">                loss_train, acc_train = session.run([model.loss, model.acc], feed_dict=feed_dict)</span><br><span class="line">                loss_val, acc_val = evaluate(session, x_val, y_val)  <span class="comment"># todo</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> acc_val &gt; best_acc_val:</span><br><span class="line">                    <span class="comment"># 保存最好结果</span></span><br><span class="line">                    best_acc_val = acc_val</span><br><span class="line">                    last_improved = total_batch</span><br><span class="line">                    saver.save(sess=session, save_path=save_path)</span><br><span class="line">                    improved_str = <span class="string">'*'</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    improved_str = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">                time_dif = get_time_dif(start_time)</span><br><span class="line">                msg = <span class="string">'Iter: &#123;0:&gt;6&#125;, Train Loss: &#123;1:&gt;6.2&#125;, Train Acc: &#123;2:&gt;7.2%&#125;,'</span> \</span><br><span class="line">                      + <span class="string">' Val Loss: &#123;3:&gt;6.2&#125;, Val Acc: &#123;4:&gt;7.2%&#125;, Time: &#123;5&#125; &#123;6&#125;'</span></span><br><span class="line">                print(msg.format(total_batch, loss_train, acc_train, loss_val, acc_val, time_dif, improved_str))</span><br><span class="line">            </span><br><span class="line">            feed_dict[model.keep_prob] = config.dropout_keep_prob</span><br><span class="line">            session.run(model.optim, feed_dict=feed_dict)  <span class="comment"># 运行优化</span></span><br><span class="line">            total_batch += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_batch - last_improved &gt; require_improvement:</span><br><span class="line">                <span class="comment"># 验证集正确率长期不提升，提前结束训练</span></span><br><span class="line">                print(<span class="string">"No optimization for a long time, auto-stopping..."</span>)</span><br><span class="line">                flag = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span>  <span class="comment"># 跳出循环</span></span><br><span class="line">        <span class="keyword">if</span> flag:  <span class="comment"># 同上</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Loading test data..."</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    x_test, y_test = process_file(test_dir, word_to_id, cat_to_id, config.seq_length)</span><br><span class="line"></span><br><span class="line">    session = tf.Session()</span><br><span class="line">    session.run(tf.global_variables_initializer())</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess=session, save_path=save_path)  <span class="comment"># 读取保存的模型</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Testing...'</span>)</span><br><span class="line">    loss_test, acc_test = evaluate(session, x_test, y_test)</span><br><span class="line">    msg = <span class="string">'Test Loss: &#123;0:&gt;6.2&#125;, Test Acc: &#123;1:&gt;7.2%&#125;'</span></span><br><span class="line">    print(msg.format(loss_test, acc_test))</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">128</span></span><br><span class="line">    data_len = len(x_test)</span><br><span class="line">    num_batch = int((data_len - <span class="number">1</span>) / batch_size) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    y_test_cls = np.argmax(y_test, <span class="number">1</span>)</span><br><span class="line">    y_pred_cls = np.zeros(shape=len(x_test), dtype=np.int32)  <span class="comment"># 保存预测结果</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_batch):  <span class="comment"># 逐批次处理</span></span><br><span class="line">        start_id = i * batch_size</span><br><span class="line">        end_id = min((i + <span class="number">1</span>) * batch_size, data_len)</span><br><span class="line">        feed_dict = &#123;</span><br><span class="line">            model.input_x: x_test[start_id:end_id],</span><br><span class="line">            model.keep_prob: <span class="number">1.0</span></span><br><span class="line">        &#125;</span><br><span class="line">        y_pred_cls[start_id:end_id] = session.run(model.y_pred_cls, feed_dict=feed_dict)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 评估</span></span><br><span class="line">    print(<span class="string">"Precision, Recall and F1-Score..."</span>)</span><br><span class="line">    print(metrics.classification_report(y_test_cls, y_pred_cls, target_names=categories))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 混淆矩阵</span></span><br><span class="line">    print(<span class="string">"Confusion Matrix..."</span>)</span><br><span class="line">    cm = metrics.confusion_matrix(y_test_cls, y_pred_cls)</span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    time_dif = get_time_dif(start_time)</span><br><span class="line">    print(<span class="string">"Time usage:"</span>, time_dif)</span><br></pre></td></tr></table></figure>

<h5 id="开始训练"><a href="#开始训练" class="headerlink" title="开始训练"></a>开始训练</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">type_ = <span class="string">'train'</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Configuring RNN model...'</span>)</span><br><span class="line">config = TRNNConfig()</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(vocab_dir):  <span class="comment"># 如果不存在词汇表，重建</span></span><br><span class="line">    build_vocab(train_dir, vocab_dir, config.vocab_size)</span><br><span class="line">categories, cat_to_id = read_category()</span><br><span class="line">words, word_to_id = read_vocab(vocab_dir)</span><br><span class="line">config.vocab_size = len(words)</span><br><span class="line">model = TextRNN(config)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> type_ == <span class="string">'train'</span>:</span><br><span class="line">    train()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>

<h5 id="模型测试"><a href="#模型测试" class="headerlink" title="模型测试"></a>模型测试</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test()</span><br></pre></td></tr></table></figure>

<h3 id="TextCNN"><a href="#TextCNN" class="headerlink" title="TextCNN"></a>TextCNN</h3><h4 id="模型结构-1"><a href="#模型结构-1" class="headerlink" title="模型结构"></a>模型结构</h4><p>可以将⽂本当作⼀维图像，从而可以⽤⼀维卷积神经⽹络来捕捉临近词之间的关联。将卷积神经网络CNN应用到文本分类任务，利用多个不同size的kernel来提取句子中的关键信息（类似于多窗口大小的ngram），从而能够更好地捕捉局部相关性。</p>
<p>TextCNN的详细流程：</p>
<ul>
<li><code>Embedding</code>：第一层是图中最左边的7乘5的句子矩阵，每行是词向量，维度=5，这个可以类比为图像中的原始像素点。</li>
<li><code>Convolution</code>：然后经过 kernel_sizes=(2,3,4) 的一维卷积层，每个kernel_size 有两个输出 channel。</li>
<li><code>MaxPolling</code>：第三层是一个1-max pooling层，这样不同长度句子经过pooling层之后都能变成定长的表示。</li>
<li><code>FullConnection and Softmax</code>：最后接一层全连接的 softmax 层，输出每个类别的概率。</li>
</ul>
<p>TextCNN的模型结构如下：</p>
<img src="https://i.loli.net/2020/07/28/4zd5ngprFLqZoSO.png" alt="TextCNN" width="90%">

<h4 id="代码实战-1"><a href="#代码实战-1" class="headerlink" title="代码实战"></a>代码实战</h4><h5 id="数据集下载-1"><a href="#数据集下载-1" class="headerlink" title="数据集下载"></a>数据集下载</h5><p>使用THUCNews的一个<a href="https://www.lanzous.com/i5t0lsd" target="_blank" rel="noopener">子集</a>进行训练与测试，本次训练使用了其中的10个分类，每个分类6500条数据。类别分别为——体育, 财经, 房产, 家居, 教育, 科技, 时尚, 时政, 游戏, 娱乐。</p>
<p><strong>cnews_loader.py为数据的预处理文件</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">read_file(): 读取文件数据;</span><br><span class="line">build_vocab(): 构建词汇表，使用字符级的表示，这一函数会将词汇表存储下来，避免每一次重复处理;</span><br><span class="line">read_vocab(): 读取上一步存储的词汇表，转换为&#123;词：id&#125;表示;</span><br><span class="line">read_category(): 将分类目录固定，转换为&#123;类别: id&#125;表示;</span><br><span class="line">to_words(): 将一条由id表示的数据重新转换为文字;</span><br><span class="line">process_file(): 将数据集从文字转换为固定长度的id序列表示;</span><br><span class="line">batch_iter(): 为神经网络的训练准备经过shuffle的批次的数据。</span><br></pre></td></tr></table></figure>

<h5 id="textCNN的模型和可配置的参数"><a href="#textCNN的模型和可配置的参数" class="headerlink" title="textCNN的模型和可配置的参数"></a>textCNN的模型和可配置的参数</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> timedelta</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> cnn_model <span class="keyword">import</span> TCNNConfig, TextCNN</span><br><span class="line"><span class="keyword">from</span> cnews_loader <span class="keyword">import</span> read_vocab, read_category, batch_iter, process_file, build_vocab</span><br><span class="line"></span><br><span class="line">base_dir = <span class="string">'cnews'</span></span><br><span class="line">train_dir = os.path.join(base_dir, <span class="string">'cnews.train.txt'</span>)</span><br><span class="line">test_dir = os.path.join(base_dir, <span class="string">'cnews.test.txt'</span>)</span><br><span class="line">val_dir = os.path.join(base_dir, <span class="string">'cnews.val.txt'</span>)</span><br><span class="line">vocab_dir = os.path.join(base_dir, <span class="string">'cnews.vocab.txt'</span>)</span><br><span class="line"></span><br><span class="line">save_dir = <span class="string">'checkpoints/textcnn'</span></span><br><span class="line">save_path = os.path.join(save_dir, <span class="string">'best_validation'</span>)  <span class="comment"># 最佳验证结果保存路径</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_time_dif</span><span class="params">(start_time)</span>:</span></span><br><span class="line">    <span class="string">"""获取已使用时间"""</span></span><br><span class="line">    end_time = time.time()</span><br><span class="line">    time_dif = end_time - start_time</span><br><span class="line">    <span class="keyword">return</span> timedelta(seconds=int(round(time_dif)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">feed_data</span><span class="params">(x_batch, y_batch, keep_prob)</span>:</span></span><br><span class="line">    feed_dict = &#123;</span><br><span class="line">        model.input_x: x_batch,</span><br><span class="line">        model.input_y: y_batch,</span><br><span class="line">        model.keep_prob: keep_prob</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> feed_dict</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span><span class="params">(sess, x_, y_)</span>:</span></span><br><span class="line">    <span class="string">"""评估在某一数据上的准确率和损失"""</span></span><br><span class="line">    data_len = len(x_)</span><br><span class="line">    batch_eval = batch_iter(x_, y_, <span class="number">128</span>)</span><br><span class="line">    total_loss = <span class="number">0.0</span></span><br><span class="line">    total_acc = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> batch_eval:</span><br><span class="line">        batch_len = len(x_batch)</span><br><span class="line">        feed_dict = feed_data(x_batch, y_batch, <span class="number">1.0</span>)</span><br><span class="line">        loss, acc = sess.run([model.loss, model.acc], feed_dict=feed_dict)</span><br><span class="line">        total_loss += loss * batch_len</span><br><span class="line">        total_acc += acc * batch_len</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> total_loss / data_len, total_acc / data_len</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Configuring TensorBoard and Saver..."</span>)</span><br><span class="line">    <span class="comment"># 配置 Tensorboard，重新训练时，请将tensorboard文件夹删除，不然图会覆盖</span></span><br><span class="line">    tensorboard_dir = <span class="string">'tensorboard/textcnn'</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(tensorboard_dir):</span><br><span class="line">        os.makedirs(tensorboard_dir)</span><br><span class="line"></span><br><span class="line">    tf.summary.scalar(<span class="string">"loss"</span>, model.loss)</span><br><span class="line">    tf.summary.scalar(<span class="string">"accuracy"</span>, model.acc)</span><br><span class="line">    merged_summary = tf.summary.merge_all()</span><br><span class="line">    writer = tf.summary.FileWriter(tensorboard_dir)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 配置 Saver</span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(save_dir):</span><br><span class="line">        os.makedirs(save_dir)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"Loading training and validation data..."</span>)</span><br><span class="line">    <span class="comment"># 载入训练集与验证集</span></span><br><span class="line">    start_time = time.time()</span><br><span class="line">    x_train, y_train = process_file(train_dir, word_to_id, cat_to_id, config.seq_length)</span><br><span class="line">    x_val, y_val = process_file(val_dir, word_to_id, cat_to_id, config.seq_length)</span><br><span class="line">    time_dif = get_time_dif(start_time)</span><br><span class="line">    print(<span class="string">"Time usage:"</span>, time_dif)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建session</span></span><br><span class="line">    session = tf.Session()</span><br><span class="line">    session.run(tf.global_variables_initializer())</span><br><span class="line">    writer.add_graph(session.graph)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Training and evaluating...'</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    total_batch = <span class="number">0</span>  <span class="comment"># 总批次</span></span><br><span class="line">    best_acc_val = <span class="number">0.0</span>  <span class="comment"># 最佳验证集准确率</span></span><br><span class="line">    last_improved = <span class="number">0</span>  <span class="comment"># 记录上一次提升批次</span></span><br><span class="line">    require_improvement = <span class="number">1000</span>  <span class="comment"># 如果超过1000轮未提升，提前结束训练</span></span><br><span class="line"></span><br><span class="line">    flag = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(config.num_epochs):</span><br><span class="line">        print(<span class="string">'Epoch:'</span>, epoch + <span class="number">1</span>)</span><br><span class="line">        batch_train = batch_iter(x_train, y_train, config.batch_size)</span><br><span class="line">        <span class="keyword">for</span> x_batch, y_batch <span class="keyword">in</span> batch_train:</span><br><span class="line">            feed_dict = feed_data(x_batch, y_batch, config.dropout_keep_prob)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_batch % config.save_per_batch == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 每多少轮次将训练结果写入tensorboard scalar</span></span><br><span class="line">                s = session.run(merged_summary, feed_dict=feed_dict)</span><br><span class="line">                writer.add_summary(s, total_batch)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_batch % config.print_per_batch == <span class="number">0</span>:</span><br><span class="line">                <span class="comment"># 每多少轮次输出在训练集和验证集上的性能</span></span><br><span class="line">                feed_dict[model.keep_prob] = <span class="number">1.0</span></span><br><span class="line">                loss_train, acc_train = session.run([model.loss, model.acc], feed_dict=feed_dict)</span><br><span class="line">                loss_val, acc_val = evaluate(session, x_val, y_val)  <span class="comment"># todo</span></span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> acc_val &gt; best_acc_val:</span><br><span class="line">                    <span class="comment"># 保存最好结果</span></span><br><span class="line">                    best_acc_val = acc_val</span><br><span class="line">                    last_improved = total_batch</span><br><span class="line">                    saver.save(sess=session, save_path=save_path)</span><br><span class="line">                    improved_str = <span class="string">'*'</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    improved_str = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">                time_dif = get_time_dif(start_time)</span><br><span class="line">                msg = <span class="string">'Iter: &#123;0:&gt;6&#125;, Train Loss: &#123;1:&gt;6.2&#125;, Train Acc: &#123;2:&gt;7.2%&#125;,'</span> \</span><br><span class="line">                      + <span class="string">' Val Loss: &#123;3:&gt;6.2&#125;, Val Acc: &#123;4:&gt;7.2%&#125;, Time: &#123;5&#125; &#123;6&#125;'</span></span><br><span class="line">                print(msg.format(total_batch, loss_train, acc_train, loss_val, acc_val, time_dif, improved_str))</span><br><span class="line"></span><br><span class="line">            feed_dict[model.keep_prob] = config.dropout_keep_prob</span><br><span class="line">            session.run(model.optim, feed_dict=feed_dict)  <span class="comment"># 运行优化</span></span><br><span class="line">            total_batch += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> total_batch - last_improved &gt; require_improvement:</span><br><span class="line">                <span class="comment"># 验证集正确率长期不提升，提前结束训练</span></span><br><span class="line">                print(<span class="string">"No optimization for a long time, auto-stopping..."</span>)</span><br><span class="line">                flag = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span>  <span class="comment"># 跳出循环</span></span><br><span class="line">        <span class="keyword">if</span> flag:  <span class="comment"># 同上</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">    print(<span class="string">"Loading test data..."</span>)</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    x_test, y_test = process_file(test_dir, word_to_id, cat_to_id, config.seq_length)</span><br><span class="line"></span><br><span class="line">    session = tf.Session()</span><br><span class="line">    session.run(tf.global_variables_initializer())</span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    saver.restore(sess=session, save_path=save_path)  <span class="comment"># 读取保存的模型</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">'Testing...'</span>)</span><br><span class="line">    loss_test, acc_test = evaluate(session, x_test, y_test)</span><br><span class="line">    msg = <span class="string">'Test Loss: &#123;0:&gt;6.2&#125;, Test Acc: &#123;1:&gt;7.2%&#125;'</span></span><br><span class="line">    print(msg.format(loss_test, acc_test))</span><br><span class="line"></span><br><span class="line">    batch_size = <span class="number">128</span></span><br><span class="line">    data_len = len(x_test)</span><br><span class="line">    num_batch = int((data_len - <span class="number">1</span>) / batch_size) + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    y_test_cls = np.argmax(y_test, <span class="number">1</span>)</span><br><span class="line">    y_pred_cls = np.zeros(shape=len(x_test), dtype=np.int32)  <span class="comment"># 保存预测结果</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_batch):  <span class="comment"># 逐批次处理</span></span><br><span class="line">        start_id = i * batch_size</span><br><span class="line">        end_id = min((i + <span class="number">1</span>) * batch_size, data_len)</span><br><span class="line">        feed_dict = &#123;</span><br><span class="line">            model.input_x: x_test[start_id:end_id],</span><br><span class="line">            model.keep_prob: <span class="number">1.0</span></span><br><span class="line">        &#125;</span><br><span class="line">        y_pred_cls[start_id:end_id] = session.run(model.y_pred_cls, feed_dict=feed_dict)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 评估</span></span><br><span class="line">    print(<span class="string">"Precision, Recall and F1-Score..."</span>)</span><br><span class="line">    print(metrics.classification_report(y_test_cls, y_pred_cls, target_names=categories))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 混淆矩阵</span></span><br><span class="line">    print(<span class="string">"Confusion Matrix..."</span>)</span><br><span class="line">    cm = metrics.confusion_matrix(y_test_cls, y_pred_cls)</span><br><span class="line">    print(cm)</span><br><span class="line"></span><br><span class="line">    time_dif = get_time_dif(start_time)</span><br><span class="line">    print(<span class="string">"Time usage:"</span>, time_dif)</span><br></pre></td></tr></table></figure>

<h5 id="开始训练-1"><a href="#开始训练-1" class="headerlink" title="开始训练"></a>开始训练</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">type_ = <span class="string">'train'</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">'Configuring CNN model...'</span>)</span><br><span class="line">config = TCNNConfig()</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(vocab_dir):  <span class="comment"># 如果不存在词汇表，重建</span></span><br><span class="line">    build_vocab(train_dir, vocab_dir, config.vocab_size)</span><br><span class="line">categories, cat_to_id = read_category()</span><br><span class="line">words, word_to_id = read_vocab(vocab_dir)</span><br><span class="line">config.vocab_size = len(words)</span><br><span class="line">model = TextCNN(config)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> type_ == <span class="string">'train'</span>:</span><br><span class="line">    train()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    test()</span><br></pre></td></tr></table></figure>

<h5 id="模型测试-1"><a href="#模型测试-1" class="headerlink" title="模型测试"></a>模型测试</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test()</span><br></pre></td></tr></table></figure>
                                        
                </div>
                <footer class="article-footer">
                    
                        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://localhost:4000/2020/07/28/NLP模型-10-textRNN & textCNN/&title=《NLP模型-10-textRNN&textCNN》 — blog&pic=/images/banner.jpg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://localhost:4000/2020/07/28/NLP模型-10-textRNN & textCNN/&title=《NLP模型-10-textRNN&textCNN》 — blog&source=一个专注前端智能化开发技术的网站" data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2020/07/28/NLP模型-10-textRNN & textCNN/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《NLP模型-10-textRNN&textCNN》 — blog&url=http://localhost:4000/2020/07/28/NLP模型-10-textRNN & textCNN/&via=http://localhost:4000" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://localhost:4000/2020/07/28/NLP模型-10-textRNN & textCNN/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://localhost:4000/2020/07/28/NLP模型-10-textRNN & textCNN/" alt="微信分享二维码">
</div>

<div class="mask"></div>

                            
                                <ul class="article-footer-menu">
                                    
                                            
                                </ul>
                                
                </footer>
    </div>
</article>

    
    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#TextRNN"><span class="post-toc-text">TextRNN</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#模型结构"><span class="post-toc-text">模型结构</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#代码实战"><span class="post-toc-text">代码实战</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#数据集下载"><span class="post-toc-text">数据集下载</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#textRNN模型和可配置的参数"><span class="post-toc-text">textRNN模型和可配置的参数</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#开始训练"><span class="post-toc-text">开始训练</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#模型测试"><span class="post-toc-text">模型测试</span></a></li></ol></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#TextCNN"><span class="post-toc-text">TextCNN</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#模型结构-1"><span class="post-toc-text">模型结构</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#代码实战-1"><span class="post-toc-text">代码实战</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#数据集下载-1"><span class="post-toc-text">数据集下载</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#textCNN的模型和可配置的参数"><span class="post-toc-text">textCNN的模型和可配置的参数</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#开始训练-1"><span class="post-toc-text">开始训练</span></a></li><li class="post-toc-item post-toc-level-5"><a class="post-toc-link" href="#模型测试-1"><span class="post-toc-text">模型测试</span></a></li></ol></li></ol></li></ol>
        </nav>
    </aside>
    
        
<nav id="article-nav">
  
    <a href="/2020/07/28/NLP模型-11-seq2seq/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          NLP模型-11-seq2seq
        
      </span>
    </a>
  
  
    <a href="/2020/07/28/NLP模型-12-attention/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">NLP模型-12-attention</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>

            
                
                    
                                                    </section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2020 Yang Pei<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    var mihoConfig = {
        root: "http://localhost:4000",
        animate: "false" ,
        isHome: "false" ,
        share: "true"
    }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/AI/">AI</a><a class="category-link" href="/categories/前端/">前端</a><a class="category-link" href="/categories/计算机/">计算机</a><a class="category-link" href="/categories/语言/">语言</a>
        </div>
        <div id="sidebar-menu-box-tags">
            
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>ß

<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>主页</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>全部</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/AI/">
                    <i class="fa fa-AI"></i><span>AI</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/前端/">
                    <i class="fa fa-前端"></i><span>前端</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/计算机/">
                    <i class="fa fa-计算机"></i><span>计算机</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/语言/">
                    <i class="fa fa-语言"></i><span>语言</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            
        </div>
    </div>
</div>
    <div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
    <script src="/js/search.js"></script>
        <script src="/js/main.js"></script>

            
                <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
                <div id="particles"></div>
                <script src="/js/particles.js"></script>
                    

                        

                                

                                                
                                                                
                                                                    <script src="/js/pop-img.js"></script>
                                                                        <script>
                                                                            $(".article-entry p img").popImg();
                                                                        </script>
                                                                        
  </div>
</body>
</html>