<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>NLP模型-11-seq2seq | blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
    <meta name="keywords" content="YP's Blog">
  
  <meta name="description" content="NLP模型-01-预训练语言模型NLP模型-02-HMMNLP模型-03-GMMNLP模型-04-CRFNLP模型-05-transformerNLP模型-06-BertNLP模型-07-LDANLP模型-08-fastTextNLP模型-09-GloveNLP模型-10-textRNN &amp;amp; textCNNNLP模型-11-seq2seqNLP模型-12-attentionNLP模型-13">
<meta name="keywords" content="web">
<meta property="og:type" content="article">
<meta property="og:title" content="NLP模型-11-seq2seq">
<meta property="og:url" content="http://localhost:4000/2020/07/28/NLP模型-11-seq2seq/index.html">
<meta property="og:site_name" content="blog">
<meta property="og:description" content="NLP模型-01-预训练语言模型NLP模型-02-HMMNLP模型-03-GMMNLP模型-04-CRFNLP模型-05-transformerNLP模型-06-BertNLP模型-07-LDANLP模型-08-fastTextNLP模型-09-GloveNLP模型-10-textRNN &amp;amp; textCNNNLP模型-11-seq2seqNLP模型-12-attentionNLP模型-13">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2020-07-28T12:20:22.894Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="NLP模型-11-seq2seq">
<meta name="twitter:description" content="NLP模型-01-预训练语言模型NLP模型-02-HMMNLP模型-03-GMMNLP模型-04-CRFNLP模型-05-transformerNLP模型-06-BertNLP模型-07-LDANLP模型-08-fastTextNLP模型-09-GloveNLP模型-10-textRNN &amp;amp; textCNNNLP模型-11-seq2seqNLP模型-12-attentionNLP模型-13">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css">
  <script src="/js/pace.min.js"></script>
  

  
  

</head>
</html>
<body>
  <div id="container">
      <header id="header">
    <div id="banner"></div>
    <div id="header-outer">
        <div id="header-menu" class="header-menu-pos animated">
            <div class="header-menu-container">
                <a href="/" class="left">
                    <span class="site-title">YP&#39;s Blog</span>
                </a>
                <nav id="header-menu-nav" class="right">
                    
                    <a  href="/">
                        <i class="fa fa-home"></i>
                        <span>主页</span>
                    </a>
                    
                    <a  href="/archives">
                        <i class="fa fa-archive"></i>
                        <span>全部</span>
                    </a>
                    
                    <a  href="/categories/AI/">
                        <i class="fa fa-AI"></i>
                        <span>AI</span>
                    </a>
                    
                    <a  href="/categories/前端/">
                        <i class="fa fa-前端"></i>
                        <span>前端</span>
                    </a>
                    
                    <a  href="/categories/计算机/">
                        <i class="fa fa-计算机"></i>
                        <span>计算机</span>
                    </a>
                    
                    <a  href="/categories/语言/">
                        <i class="fa fa-语言"></i>
                        <span>语言</span>
                    </a>
                    
                    <a  href="/categories/专题/">
                        <i class="fa fa-专题"></i>
                        <span>专题</span>
                    </a>
                    
                </nav>
                <a class="mobile-header-menu-button">
                    <i class="fa fa-bars"></i>
                </a>
            </div>
        </div>
        <div id="header-row">
            <div id="logo">
                <a href="/">
                    <img src="/images/logo.png" alt="logo">
                </a>
            </div>
            <div class="header-info">
                <div id="header-title">
                    
                    <h2>
                        YP&#39;s Blog
                    </h2>
                    
                </div>
                <div id="header-description">
                    
                    <h3>
                        一个专注前端智能化开发的技术博客
                    </h3>
                    
                </div>
            </div>
            <nav class="header-nav">
                <div class="social">
                    
                        <a title="Blog" target="_blank" href="https://iloveyou11.github.io/">
                            <i class="fa fa-home fa-2x"></i></a>
                    
                        <a title="Github" target="_blank" href="https://github.com/iloveyou11">
                            <i class="fa fa-github fa-2x"></i></a>
                    
                </div>
            </nav>
        </div>
    </div>
</header>
      <div class="outer">
        <section id="main" class="body-wrap"><article id="post-NLP模型-11-seq2seq" class="article article-type-post" itemscope itemprop="blogPost">
    <div class="article-inner">
        
            <header class="article-header">
                
  
    <h1 class="post-title" itemprop="name">
      NLP模型-11-seq2seq
    </h1>
    <div class="post-title-bar">
      <ul>
          
              <li>
                  <i class="fa fa-book"></i>
                  
                      <a href="/categories/AI/">AI</a>
                  
              </li>
          
        <li>
          <i class="fa fa-calendar"></i>  2020-07-28
        </li>
        <li>
          <i class="fa fa-eye"></i>
          <span id="busuanzi_value_page_pv"></span>
        </li>
      </ul>
    </div>
  

                    
            </header>
            
                <div class="article-entry post-content" itemprop="articleBody">
                    
                            
                                
    <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#seq2seq初识"><span class="toc-text">seq2seq初识</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#编码器"><span class="toc-text">编码器</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#解码器"><span class="toc-text">解码器</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#seq2seq与VAE-AE的区别"><span class="toc-text">seq2seq与VAE/AE的区别</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#seq2seq"><span class="toc-text">seq2seq</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AE"><span class="toc-text">AE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#VAE"><span class="toc-text">VAE</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#实战演练"><span class="toc-text">实战演练</span></a></li></ol>
    </div>
    
                                    <p><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-01-%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/" target="_blank" rel="noopener">NLP模型-01-预训练语言模型</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-02-HMM/" target="_blank" rel="noopener">NLP模型-02-HMM</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-03-GMM/" target="_blank" rel="noopener">NLP模型-03-GMM</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-04-CRF/" target="_blank" rel="noopener">NLP模型-04-CRF</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-05-transformer/" target="_blank" rel="noopener">NLP模型-05-transformer</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-06-Bert/" target="_blank" rel="noopener">NLP模型-06-Bert</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-07-LDA/" target="_blank" rel="noopener">NLP模型-07-LDA</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-08-fastText/" target="_blank" rel="noopener">NLP模型-08-fastText</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-09-Glove/" target="_blank" rel="noopener">NLP模型-09-Glove</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-10-textRNN%20&%20textCNN/" target="_blank" rel="noopener">NLP模型-10-textRNN &amp; textCNN</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-11-seq2seq/" target="_blank" rel="noopener">NLP模型-11-seq2seq</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-12-attention/" target="_blank" rel="noopener">NLP模型-12-attention</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-13-XLnet/" target="_blank" rel="noopener">NLP模型-13-XLnet</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-14-%E6%A0%B8%E6%96%B9%E6%B3%95/" target="_blank" rel="noopener">NLP模型-14-核方法</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-15-%E6%B7%B1%E5%BA%A6%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA/" target="_blank" rel="noopener">NLP模型-15-深度玻尔兹曼机</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-16-%E5%8F%97%E9%99%90%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E6%9C%BA/" target="_blank" rel="noopener">NLP模型-16-受限玻尔兹曼机</a><br><a href="https://iloveyou11.github.io/2020/07/28/NLP%E6%A8%A1%E5%9E%8B-17-%E6%B7%B1%E5%BA%A6%E4%BF%A1%E5%BF%B5%E7%BD%91%E7%BB%9C/" target="_blank" rel="noopener">NLP模型-17-深度信念网络</a></p>
<h3 id="seq2seq初识"><a href="#seq2seq初识" class="headerlink" title="seq2seq初识"></a>seq2seq初识</h3><p>当输入和输出都是不定长序列时，则可以使用<code>编码器-解码器</code>或<code>seq2seq模型</code>解决。</p>
<p><code>seq2seq</code>属于<code>encoder-decoder</code>结构的一种，常见是<code>encoder-decoder</code>结构，基本思想就是利用两个RNN，一个RNN作为encoder，另一个RNN作为decoder，两个RNN网络是共同训练的。encoder负责将输入序列压缩成指定长度的向量，这个向量就可以看成是这个序列的语义，这个过程称为编码，获取语义向量最简单的方式就是直接将最后一个输入的隐状态作为语义向量C。也可以对最后一个隐含状态做一个变换得到语义向量，还可以将输入序列的所有隐含状态做一个变换得到语义变量。</p>
<p>而decoder则负责根据语义向量生成指定的序列，这个过程也称为解码，如下图，最简单的方式是将encoder得到的语义变量作为初始状态输入到decoder的RNN中，得到输出序列。可以看到上一时刻的输出会作为当前时刻的输入，而且其中语义向量C只作为初始状态参与运算，后面的运算都与语义向量C无关。</p>
<p>seq2seq的应用场景如下：</p>
<ol>
<li>机器翻译（当前最为著名的Google翻译，就是完全基于Seq2Seq+Attention机制开发出来的）。</li>
<li>聊天机器人（小爱，微软小冰等也使用了Seq2Seq的技术（不是全部））。</li>
<li>文本摘要自动生成（今日头条等使用了该技术）。</li>
<li>图片描述自动生成。</li>
<li>机器写诗歌、代码补全、生成 commit message、故事风格改写等。</li>
</ol>
<h4 id="编码器"><a href="#编码器" class="headerlink" title="编码器"></a>编码器</h4><p>编码器的作⽤是把⼀个不定⻓的输⼊序列变换成⼀个定⻓的背景变量<code>c</code>，并在该背景变量中编码输⼊序列信息，常用的编码器是RNN网络。</p>
<p>编码器可以使用单向的RNN，也可以使用双向的RNN，单向RNN的每个时间步的隐藏状态只取决于该时间步及之前的输⼊⼦序列，双向RNN的每个时间步的隐藏状态同时取决于该时间步之前和之后的⼦序列。</p>
<h4 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h4><p>将上⼀时间步的输出<code>Yt-1</code>以及背景<code>x</code>作为输⼊，将上一步的隐藏状态<code>St-1</code>转化为当前时间步的隐藏状态<code>St</code>。基于<code>St-1</code>、<code>St</code>、<code>c</code>，使⽤⾃定义的输出层和softmax运算来计算当前时间步输出<code>y</code>的概率分布。</p>
<h3 id="seq2seq与VAE-AE的区别"><a href="#seq2seq与VAE-AE的区别" class="headerlink" title="seq2seq与VAE/AE的区别"></a>seq2seq与VAE/AE的区别</h3><h4 id="seq2seq"><a href="#seq2seq" class="headerlink" title="seq2seq"></a>seq2seq</h4><p>主流的Seq2Seq都是基于Encoder-Decoder来实现的，Encoder-Decoder也不只是能用于Seq2Seq场景。s2s是具体的模型，encoder-decoder是模型设计“范式”。</p>
<h4 id="AE"><a href="#AE" class="headerlink" title="AE"></a>AE</h4><p>AE是AutoEncoder（自编码器）的简称，自动编码器是一种数据的压缩算法，<code>自编码器（Autoencoder）是神经网络的一种，经过训练后能尝试将输入复制到输出（先将输入转化为隐层，再将隐层转化为输出）。</code></p>
<p>自编码内部有一个隐藏层 h，可以产生编码（code）表示输入。该网络可以看作由两部分组成：一个由函数 h = f(x) 表示的编码器和一个生成重构的解码器 r = g(h)。如果一个自编码器只是简单地学会将处处设置为 g(f(x)) = x，那么这个自编码器就没什么特别的用处。</p>
<h4 id="VAE"><a href="#VAE" class="headerlink" title="VAE"></a>VAE</h4><p>VAE是变分自编码器，相比于自编码器，VAE更倾向于数据生成。只要训练好了decoder，我们就可以从标准正态分布生成数据作为解码器的输入，来生成类似但不同于训练数据的新样本，作用类似GAN。</p>
<p><code>VAE相当于针对隐层h加了noise，variance应用了noise的大小。</code></p>
<h3 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h3><p>通过sin与con进行叠加变形生成无规律的模拟曲线，使用Seq2Seq模式对其进行学习，拟合特征，从而达到可以预测下一时刻数据的效果。</p>
<p>定义两个曲线sin和con，通过随机值将其变形偏移，将两个曲线叠加：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line">        </span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf </span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">do_generate_x_y</span><span class="params">(isTrain, batch_size, seqlen)</span>:</span></span><br><span class="line">    batch_x = []</span><br><span class="line">    batch_y = []</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(batch_size):</span><br><span class="line">        offset_rand = random.random() * <span class="number">2</span> * math.pi</span><br><span class="line">        freq_rand = (random.random() - <span class="number">0.5</span>) / <span class="number">1.5</span> * <span class="number">15</span> + <span class="number">0.5</span></span><br><span class="line">        amp_rand = random.random() + <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">        sin_data = amp_rand * np.sin(np.linspace(</span><br><span class="line">            seqlen / <span class="number">15.0</span> * freq_rand * <span class="number">0.0</span> * math.pi + offset_rand,</span><br><span class="line">            seqlen / <span class="number">15.0</span> * freq_rand * <span class="number">3.0</span> * math.pi + offset_rand, seqlen * <span class="number">2</span>)  )</span><br><span class="line"></span><br><span class="line">        offset_rand = random.random() * <span class="number">2</span> * math.pi</span><br><span class="line">        freq_rand = (random.random() - <span class="number">0.5</span>) / <span class="number">1.5</span> * <span class="number">15</span> + <span class="number">0.5</span></span><br><span class="line">        amp_rand = random.random() * <span class="number">1.2</span></span><br><span class="line"></span><br><span class="line">        sig_data = amp_rand * np.cos(np.linspace(</span><br><span class="line">            seqlen / <span class="number">15.0</span> * freq_rand * <span class="number">0.0</span> * math.pi + offset_rand,</span><br><span class="line">            seqlen / <span class="number">15.0</span> * freq_rand * <span class="number">3.0</span> * math.pi + offset_rand, seqlen * <span class="number">2</span>)) + sin_data</span><br><span class="line"></span><br><span class="line">        batch_x.append(np.array([ sig_data[:seqlen] ]).T)</span><br><span class="line">        batch_y.append(np.array([ sig_data[seqlen:] ]).T)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># shape: (batch_size, seq_length, output_dim)</span></span><br><span class="line">    batch_x = np.array(batch_x).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">    batch_y = np.array(batch_y).transpose((<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>))</span><br><span class="line">    <span class="comment"># shape: (seq_length, batch_size, output_dim)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> batch_x, batch_y</span><br><span class="line"></span><br><span class="line"><span class="comment">#生成15个连续序列，将con和sin随机偏移变化后的值叠加起来</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_data</span><span class="params">(isTrain, batch_size)</span>:</span></span><br><span class="line">    seq_length =<span class="number">15</span></span><br><span class="line">    <span class="keyword">if</span> isTrain :</span><br><span class="line">        <span class="keyword">return</span> do_generate_x_y(isTrain, batch_size, seq_length)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> do_generate_x_y(isTrain, batch_size, seq_length*<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line">sample_now, sample_f = generate_data(isTrain=<span class="literal">True</span>, batch_size=<span class="number">3</span>)</span><br><span class="line">print(<span class="string">"training examples : "</span>)</span><br><span class="line">print(sample_now.shape)</span><br><span class="line">print(<span class="string">"(seq_length, batch_size, output_dim)"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">seq_length = sample_now.shape[<span class="number">0</span>]</span><br><span class="line">batch_size = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">output_dim = input_dim = sample_now.shape[<span class="number">-1</span>]</span><br><span class="line">hidden_dim = <span class="number">12</span>  </span><br><span class="line">layers_num = <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Optmizer:</span></span><br><span class="line">learning_rate =<span class="number">0.04</span></span><br><span class="line">nb_iters = <span class="number">100</span></span><br><span class="line"></span><br><span class="line">lambda_l2_reg = <span class="number">0.003</span>  <span class="comment"># L2 regularization of weights - avoids overfitting</span></span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">tf.reset_default_graph()</span><br><span class="line"></span><br><span class="line">encoder_input = []</span><br><span class="line">expected_output = []</span><br><span class="line">decode_input =[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(seq_length):</span><br><span class="line">    encoder_input.append( tf.placeholder(tf.float32, shape=( <span class="literal">None</span>, input_dim)) )</span><br><span class="line">    expected_output.append( tf.placeholder(tf.float32, shape=( <span class="literal">None</span>, output_dim)) )</span><br><span class="line">    decode_input.append( tf.placeholder(tf.float32, shape=( <span class="literal">None</span>, input_dim)) )</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">tcells = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(layers_num):</span><br><span class="line">    tcells.append(tf.contrib.rnn.GRUCell(hidden_dim))</span><br><span class="line">Mcell = tf.contrib.rnn.MultiRNNCell(tcells)</span><br><span class="line"></span><br><span class="line">dec_outputs, dec_memory = tf.contrib.legacy_seq2seq.basic_rnn_seq2seq(encoder_input,decode_input,Mcell)</span><br><span class="line"></span><br><span class="line">reshaped_outputs = []</span><br><span class="line"><span class="keyword">for</span> ii <span class="keyword">in</span> dec_outputs :</span><br><span class="line">    reshaped_outputs.append( tf.contrib.layers.fully_connected(ii,output_dim,activation_fn=<span class="literal">None</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># L2 loss</span></span><br><span class="line">output_loss = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> _y, _Y <span class="keyword">in</span> zip(reshaped_outputs, expected_output):</span><br><span class="line">    output_loss += tf.reduce_mean( tf.pow(_y - _Y, <span class="number">2</span>) )</span><br><span class="line">   </span><br><span class="line"><span class="comment"># generalization capacity)</span></span><br><span class="line">reg_loss = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> tf_var <span class="keyword">in</span> tf.trainable_variables():</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> (<span class="string">"fully_connected"</span> <span class="keyword">in</span> tf_var.name ):</span><br><span class="line">        <span class="comment">#print(tf_var.name)</span></span><br><span class="line">        reg_loss += tf.reduce_mean(tf.nn.l2_loss(tf_var))</span><br><span class="line"></span><br><span class="line">loss = output_loss + lambda_l2_reg * reg_loss</span><br><span class="line">train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)   </span><br><span class="line"></span><br><span class="line">sess = tf.InteractiveSession()</span><br><span class="line">        </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_batch</span><span class="params">(batch_size)</span>:</span></span><br><span class="line"></span><br><span class="line">    X, Y = generate_data(isTrain=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">    feed_dict = &#123;encoder_input[t]: X[t] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(encoder_input))&#125;</span><br><span class="line">    feed_dict.update(&#123;expected_output[t]: Y[t] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(expected_output))&#125;)</span><br><span class="line"></span><br><span class="line">    c =np.concatenate(( [np.zeros_like(Y[<span class="number">0</span>])],Y[:<span class="number">-1</span>]),axis = <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    feed_dict.update(&#123;decode_input[t]: c[t] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(c))&#125;)</span><br><span class="line"></span><br><span class="line">    _, loss_t = sess.run([train_op, loss], feed_dict)</span><br><span class="line">    <span class="keyword">return</span> loss_t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_batch</span><span class="params">(batch_size)</span>:</span></span><br><span class="line">    X, Y = generate_data(isTrain=<span class="literal">True</span>, batch_size=batch_size)</span><br><span class="line">    feed_dict = &#123;encoder_input[t]: X[t] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(encoder_input))&#125;</span><br><span class="line">    feed_dict.update(&#123;expected_output[t]: Y[t] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(expected_output))&#125;)</span><br><span class="line">    c =np.concatenate(( [np.zeros_like(Y[<span class="number">0</span>])],Y[:<span class="number">-1</span>]),axis = <span class="number">0</span>)<span class="comment">#来预测最后一个序列</span></span><br><span class="line">    feed_dict.update(&#123;decode_input[t]: c[t] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(c))&#125;)    </span><br><span class="line">    output_lossv,reg_lossv,loss_t = sess.run([output_loss,reg_loss,loss], feed_dict)</span><br><span class="line">    print(<span class="string">"-----------------"</span>)    </span><br><span class="line">    print(output_lossv,reg_lossv)</span><br><span class="line">    <span class="keyword">return</span> loss_t</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Training</span></span><br><span class="line">train_losses = []</span><br><span class="line">test_losses = []</span><br><span class="line"></span><br><span class="line">sess.run(tf.global_variables_initializer())</span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(nb_iters + <span class="number">1</span>):</span><br><span class="line">    train_loss = train_batch(batch_size)</span><br><span class="line">    train_losses.append(train_loss)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        test_loss = test_batch(batch_size)</span><br><span class="line">        test_losses.append(test_loss)</span><br><span class="line">        print(<span class="string">"Step &#123;&#125;/&#123;&#125;, train loss: &#123;&#125;, \tTEST loss: &#123;&#125;"</span>.format(t,nb_iters, train_loss, test_loss))</span><br><span class="line">print(<span class="string">"Fin. train loss: &#123;&#125;, \tTEST loss: &#123;&#125;"</span>.format(train_loss, test_loss))        </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment"># Plot loss over time:</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">plt.plot(np.array(range(<span class="number">0</span>, len(test_losses))) /</span><br><span class="line">    float(len(test_losses) - <span class="number">1</span>) * (len(train_losses) - <span class="number">1</span>),</span><br><span class="line">    np.log(test_losses),label=<span class="string">"Test loss"</span>)</span><br><span class="line">    </span><br><span class="line">plt.plot(np.log(train_losses),label=<span class="string">"Train loss"</span>)</span><br><span class="line">plt.title(<span class="string">"Training errors over time (on a logarithmic scale)"</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Iteration'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'log(Loss)'</span>)</span><br><span class="line">plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">plt.show()        </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line"><span class="comment"># Test</span></span><br><span class="line">nb_predictions = <span class="number">5</span></span><br><span class="line">print(<span class="string">"visualize &#123;&#125; predictions data:"</span>.format(nb_predictions))</span><br><span class="line"></span><br><span class="line">preout =[]</span><br><span class="line">X, Y = generate_data(isTrain=<span class="literal">False</span>, batch_size=nb_predictions)</span><br><span class="line">print(np.shape(X),np.shape(Y))</span><br><span class="line"><span class="keyword">for</span> tt <span class="keyword">in</span>  range(seq_length):</span><br><span class="line">    feed_dict = &#123;encoder_input[t]: X[t+tt] <span class="keyword">for</span> t <span class="keyword">in</span> range(seq_length)&#125;</span><br><span class="line">    feed_dict.update(&#123;expected_output[t]: Y[t+tt] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(expected_output))&#125;)</span><br><span class="line">    c =np.concatenate(( [np.zeros_like(Y[<span class="number">0</span>])],Y[tt:seq_length+tt<span class="number">-1</span>]),axis = <span class="number">0</span>)  <span class="comment">#从前15个的最后一个开始预测  </span></span><br><span class="line"></span><br><span class="line">    feed_dict.update(&#123;decode_input[t]: c[t] <span class="keyword">for</span> t <span class="keyword">in</span> range(len(c))&#125;)</span><br><span class="line">    outputs = np.array(sess.run([reshaped_outputs], feed_dict)[<span class="number">0</span>])</span><br><span class="line">    preout.append(outputs[<span class="number">-1</span>])</span><br><span class="line"></span><br><span class="line">print(np.shape(preout))<span class="comment">#将每个未知预测值收集起来准备显示出来。</span></span><br><span class="line">preout =np.reshape(preout,[seq_length,nb_predictions,output_dim])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(nb_predictions):</span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> range(output_dim):</span><br><span class="line">        past = X[:, j, k]</span><br><span class="line">        expected = Y[seq_length<span class="number">-1</span>:, j, k]<span class="comment">#对应预测值的打印</span></span><br><span class="line"></span><br><span class="line">        pred = preout[:, j, k]</span><br><span class="line"></span><br><span class="line">        label1 = <span class="string">"past"</span> <span class="keyword">if</span> k == <span class="number">0</span> <span class="keyword">else</span> <span class="string">"_nolegend_"</span></span><br><span class="line">        label2 = <span class="string">"future"</span> <span class="keyword">if</span> k == <span class="number">0</span> <span class="keyword">else</span> <span class="string">"_nolegend_"</span></span><br><span class="line">        label3 = <span class="string">"Pred"</span> <span class="keyword">if</span> k == <span class="number">0</span> <span class="keyword">else</span> <span class="string">"_nolegend_"</span></span><br><span class="line">        plt.plot(range(len(past)), past, <span class="string">"o--b"</span>, label=label1)</span><br><span class="line">        plt.plot(range(len(past), len(expected) + len(past)),</span><br><span class="line">                 expected, <span class="string">"x--b"</span>, label=label2)</span><br><span class="line">        plt.plot(range(len(past), len(pred) + len(past)),</span><br><span class="line">                 pred, <span class="string">"o--y"</span>, label=label3)</span><br><span class="line"></span><br><span class="line">    plt.legend(loc=<span class="string">'best'</span>)</span><br><span class="line">    plt.title(<span class="string">"Predictions vs. future"</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
                                        
                </div>
                <footer class="article-footer">
                    
                        
<div class="post-share">
    <a href="javascript:;" id="share-sub" class="post-share-fab">
        <i class="fa fa-share-alt"></i>
    </a>
    <div class="post-share-list" id="share-list">
        <ul class="share-icons">
          <li>
            <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://localhost:4000/2020/07/28/NLP模型-11-seq2seq/&title=《NLP模型-11-seq2seq》 — blog&pic=/images/banner.jpg" data-title="微博">
              <i class="fa fa-weibo"></i>
            </a>
          </li>
          <li>
            <a class="weixin share-sns" id="wxFab" href="javascript:;" data-title="微信">
              <i class="fa fa-weixin"></i>
            </a>
          </li>
          <li>
            <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://localhost:4000/2020/07/28/NLP模型-11-seq2seq/&title=《NLP模型-11-seq2seq》 — blog&source=一个专注前端智能化开发技术的网站" data-title="QQ">
              <i class="fa fa-qq"></i>
            </a>
          </li>
          <li>
            <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/2020/07/28/NLP模型-11-seq2seq/" data-title="Facebook">
              <i class="fa fa-facebook"></i>
            </a>
          </li>
          <li>
            <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《NLP模型-11-seq2seq》 — blog&url=http://localhost:4000/2020/07/28/NLP模型-11-seq2seq/&via=http://localhost:4000" data-title="Twitter">
              <i class="fa fa-twitter"></i>
            </a>
          </li>
          <li>
            <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://localhost:4000/2020/07/28/NLP模型-11-seq2seq/" data-title="Google+">
              <i class="fa fa-google-plus"></i>
            </a>
          </li>
        </ul>
     </div>
</div>
<div class="post-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;" id="wxShare-close">×</a>
    <p>扫一扫，分享到微信</p>
    <img src="//api.qrserver.com/v1/create-qr-code/?data=http://localhost:4000/2020/07/28/NLP模型-11-seq2seq/" alt="微信分享二维码">
</div>

<div class="mask"></div>

                            
                                <ul class="article-footer-menu">
                                    
                                            
                                </ul>
                                
                </footer>
    </div>
</article>

    
    <aside class="post-toc-pos post-toc-top" id="post-toc">
        <nav class="post-toc-wrap">
            <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#seq2seq初识"><span class="post-toc-text">seq2seq初识</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#编码器"><span class="post-toc-text">编码器</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#解码器"><span class="post-toc-text">解码器</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#seq2seq与VAE-AE的区别"><span class="post-toc-text">seq2seq与VAE/AE的区别</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#seq2seq"><span class="post-toc-text">seq2seq</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#AE"><span class="post-toc-text">AE</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#VAE"><span class="post-toc-text">VAE</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#实战演练"><span class="post-toc-text">实战演练</span></a></li></ol>
        </nav>
    </aside>
    
        
<nav id="article-nav">
  
    <a href="/2020/07/28/NLP模型-12-attention/" id="article-nav-newer" class="article-nav-link-wrap">

      <span class="article-nav-title">
        <i class="fa fa-hand-o-left" aria-hidden="true"></i>
        
          NLP模型-12-attention
        
      </span>
    </a>
  
  
    <a href="/2020/07/28/NLP模型-14-核方法/" id="article-nav-older" class="article-nav-link-wrap">
      <span class="article-nav-title">NLP模型-14-核方法</span>
      <i class="fa fa-hand-o-right" aria-hidden="true"></i>
    </a>
  
</nav>

            
                
                    
                                                    </section>
        
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info" class="inner">
      
<p>
    <span id="busuanzi_container_site_uv" style='display:none'>
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style='display:none'>
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


      <p>
        Powered by  <a href="http://hexo.io/" target="_blank">Hexo</a>
        Theme <a href="//github.com/wongminho/hexo-theme-miho" target="_blank">MiHo</a>
      &copy; 2020 Yang Pei<br>
      </p>
    </div>
  </div>
</footer>
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<script src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script>
<script>
    var mihoConfig = {
        root: "http://localhost:4000",
        animate: "false" ,
        isHome: "false" ,
        share: "true"
    }
</script>
<div class="sidebar">
    <div id="sidebar-search" title="Search">
        <i class="fa fa-search"></i>
    </div>
    <div id="sidebar-category" title="Categories">
        <i class="fa fa-book"></i>
    </div>
    <div id="sidebar-top">
        <span class="sidebar-top-icon"><i class="fa fa-angle-up"></i></span>
    </div>
</div>
<div class="sidebar-menu-box" id="sidebar-menu-box">
    <div class="sidebar-menu-box-container">
        <div id="sidebar-menu-box-categories">
            <a class="category-link" href="/categories/AI/">AI</a><a class="category-link" href="/categories/专题/">专题</a><a class="category-link" href="/categories/前端/">前端</a><a class="category-link" href="/categories/计算机/">计算机</a><a class="category-link" href="/categories/语言/">语言</a>
        </div>
        <div id="sidebar-menu-box-tags">
            
        </div>
    </div>
    <a href="javascript:;" class="sidebar-menu-box-close">&times;</a>
</div>ß

<div class="mobile-header-menu-nav" id="mobile-header-menu-nav">
    <div class="mobile-header-menu-container">
        <span class="title">Menus</span>
        <ul class="mobile-header-menu-navbar">
            
            <li>
                <a  href="/">
                    <i class="fa fa-home"></i><span>主页</span>
                </a>
            </li>
            
            <li>
                <a  href="/archives">
                    <i class="fa fa-archive"></i><span>全部</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/AI/">
                    <i class="fa fa-AI"></i><span>AI</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/前端/">
                    <i class="fa fa-前端"></i><span>前端</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/计算机/">
                    <i class="fa fa-计算机"></i><span>计算机</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/语言/">
                    <i class="fa fa-语言"></i><span>语言</span>
                </a>
            </li>
            
            <li>
                <a  href="/categories/专题/">
                    <i class="fa fa-专题"></i><span>专题</span>
                </a>
            </li>
            
        </ul>
    </div>
    <div class="mobile-header-tag-container">
        <span class="title">Tags</span>
        <div id="mobile-header-container-tags">
            
        </div>
    </div>
</div>
    <div class="search-wrap">
    <span class="search-close">&times;</span>
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
            <i class="icon icon-lg icon-chevron-left"></i>
        </a>
        <input class="search-field" placeholder="Search..." id="keywords">
        <a id="search-submit" href="javascript:;">
            <i class="fa fa-search"></i>
        </a>
    <div class="search-container" id="search-container">
        <ul class="search-result" id="search-result">
        </ul>
    </div>
</div>

<div id="search-tpl">
    <li class="search-result-item">
        <a href="{url}" class="search-item-li">
            <span class="search-item-li-title" title="{title}">{title}</span>
        </a>
    </li>
</div>
    <script src="/js/search.js"></script>
        <script src="/js/main.js"></script>

            
                <script src="//cdn.bootcss.com/particles.js/2.0.0/particles.min.js"></script>
                <div id="particles"></div>
                <script src="/js/particles.js"></script>
                    

                        

                                

                                                
                                                                
                                                                    <script src="/js/pop-img.js"></script>
                                                                        <script>
                                                                            $(".article-entry p img").popImg();
                                                                        </script>
                                                                        
  </div>
</body>
</html>